# t-тест {#ttest}
## Одновыборочный t-тест {#one_ttest}

Мы научились делать z-тест. Однако на практике он не используется, потому что предполагает, что мы откуда-то знаем стандартное отклонение в генеральной совокупности. На практике это обычно не так, поэтому мы *оцениваем* стандартное отклонение в генеральной совокупности на основе стандартного отклонения по выборке. Это приводит к тому, что тестовая статистика уже не распределена нормально, а распределена согласно t-распределению. Ну и статистика уже называется t-статистикой.

$$t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}} $$

> Иногда это t-распределение называют t-распределением Стьюдента, а соответствующий статистический тест - критерий Стьюдента. Дело в том, что его открыл сотрудник пивоварни Гиннесс Уильям Госсет. Сотрудникам Гиннесса было запрещено публиковать научные работы под своим именем, поэтому он написал свою знаменитую работу про t-распределение под псевдонимом "Ученик" (*Student*).

Форма этого распределения очень похожа на форму нормального распределения, но имеет более тяжелые "хвосты" распределения. При этом эта форма зависит от размера выборки: чем больше выборка, тем ближе распределение к нормальному. Этот параметр распределения называется **степенями свободы** *(degrees of freedom)* и вычисляется как $N - 1$, где $N$ - это размер выборки.

```{r}
t_normal_pdf_gg <- tibble(x = seq(-3, 3, .01),
       t_5 = dt(x, df = 3),
       t_15 = dt(x, df = 10),
       t_100 = dt(x, df = 100),
       normal = dnorm(x)) %>%
  pivot_longer(cols = -x, values_to = 'pdf', names_to = 'distribution') %>%
  ggplot(aes(x = x, y = pdf, colour = distribution))+
  geom_line()+
  theme_light()

t_normal_pdf_gg
```

Как видите, чем больше выборка (и количество степеней свободы соответственно), тем ближе t-распределение к стандартному нормальному распределению. При 100 степенях свободы они уже почти не различимы! Поэтому на больших выборках разница между t-тестом и z-тестом будет минимальна, тогда как на маленьких выборках разница может быть значительной.

Давайте посчитаем t-статистику на тех же симулированных данных:

```{r}
set.seed(42)
samp <- rnorm(100, 100, 15)
m <- mean(samp)
sem <- sd(samp)/sqrt(length(samp))
t <- (m - 100)/sem
t
```

Давайте для сравнения еще раз посчитаем z-статистику:

```{r}
(m - 100) / (15/sqrt(100))
```

Как видите, расчет довольно схожий, разница только в том, откуда мы берем стандартное отклонение. Для z-статистики у нас был заранее известный параметр генеральной совокупности (что обычно не так), для t-статистики мы оценивали стандартное отклонение по выборке.

Давайте теперь посчитаем p-value. Мы будем пользоваться не функцией `pnorm()`, а функцией `pt()`, а в качестве параметра распределения указать количество степеней свобод в `df = `

```{r}
pt(t, df = length(samp) - 1)
```

Функция `pt()` считает от минус бесконечности до $t$, а нам нужно от $t$ до плюс бесконечности, потому что $t$ больше 0:

```{r}
1 - pt(t, df = length(samp) - 1)
```

И не забываем умножать на 2, если мы хотим сделать двусторонний тест.

```{r}
(1 - pt(t, df = length(samp) - 1))*2
```

В отличие от z-теста, t-тест есть в базовом R.

```{r}
t.test(samp, mu = 100)
```

Да, конечно, мы могли сразу запустить эту функцию и получить результаты. Обычно именно так вы и будете делать. Зато теперь вы знаете, что стоит за всеми числами в результате выполнения функции `t.test()`. Здесь можно увидеть выборочное среднее как оценку среднего в генеральной совокупности, 95% доверительный интервал для оценки среднего в генеральной совокупности, t-статистику, степени свобод и p-value.

## Двухвыборочный t-тест {#two_ttest}

Одна из наиболее часто встречающихся задач при анализе данных - это сравнение средних двух выборок. Для этого нам тоже понадобится t-тест, но теперь $H_0$ нужно сформулировать по-другому: что две генеральные совокупности имеют одинаковое среднее: $$H_0: \mu_1 = \mu_2$$. Ну а альтернативная гипотеза, что эти две выборки друг другу не равны. $$H_1: \mu_1 \ne \mu_2$$

Есть две разновидности двухвыборочного t-теста: **зависимый t-тест** и **независимый t-тест**. Различие между зависимыми и независимыми тестами принципиальное, мы с ним еще будем сталкиваться.

Зависимые тесты предполагают, что каждому значению в одной выборке мы можем поставить соответствующее значение из другой выборки. Обычно это повторные измерения какого-либо признака в разные моменты времени. В независимых тестах нет возможности сопоставить одно значение с другим. Мы уже не можем напрямую соотнести значения в двух выборках друг с другом, более того, размер двух выборок может быть разным! 

Использование зависимых и независимых тестов связано с использованием **внутрииндивидуального** и **межиндивидуального** экспериментальных дизайнов в планировании научных экспериментов. Даже если вы не планируете в дальнейшем заниматься проведением экспериментов понимание различий между двумя видами дизайнов поможет вам понять разницу между зависимыми и независимыми тестами.

Например, мы хотим исследовать влияние кофеина на скорость реакции. Можно поступить по-разному:

1) Набрать выборку, каждому испытуемому дать либо кофеин (например, в виде раствора небольшого количества кофеина в воде), либо обычную воду. Что именно получит испытуемый получит определяется случайным образом. Испытуемый не должен знать, что ему дают (слепое тестирование), а в идеале этого должен не знать даже экспериментатор, который дает напиток и измеряет показатели (двойное слепое тестирование). Посчитать скорость выполнения выбранной задачи, отправить домой. Это межинидивидуальный экспериментальный дизайн, для анализа результатов которого нам понадобится независимый t-тест.

2) Набрать выборку, каждому испытуемому дать и обычную воду, и воду с кофеином, записывать скорость решения задач после употребления простой воды и после употребления воды с кофеином, соответственно. В данном случае будет случайным образом варьироваться порядок предъявления: одни испытуемые сначала получат обычную воду, а потом воду с кофеином, другие испытуемые --- наоборот. Для такого эксперимента понадобится меньше участников, но оно будет дольше для каждого участника. Более того, в этом случае мы учтем межиндивидуальные различия участников: одни участники в среднем решают задачи быстрее других. Это внутриинидивидуальный экспериментальный дизайн, для анализа результатов которого нам понадобится зависимый t-тест.

| Внутрииндивидуальный план 	| Межиндивидуальный план 	|
|---------------------------	|------------------------	|
| Зависимый t-тест          	| Независимый t-тест     	|

Итак, с тем, когда использовать зависимый, а когда независимый t-тест, более-менее разобрались, давайте опробуем их!

### Двухвыборочный зависимый t-тест {#dep_ttest}

Двухвыборочный зависимый t-тест --- это то же самое, что и одновыборочный t-тест, только для разницы между связанными значениями. Поскольку наша нулевая гипотеза звучит, что средние должны быть равны,

$$H_0: \mu_1 = \mu_2$$

то при верности нулевой гипотезы $$\mu_1 - \mu_2 = 0$$.

Тогда вместо $x$ подставим $d$ --- разницу (вектор разниц) между парами значений. Получаем вот что:

$$t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}} = \frac{\overline{d} - (\mu_1 - \mu_2)} {s_d / \sqrt{N}} = \frac{\overline{d} - 0} {s_d / \sqrt{N}}  = \frac{\overline{d}} {s_d / \sqrt{N}}$$

Мы будем использовать [данные с курса по статистике Университета Шеффилда про эффективность диет](https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv). Мы вытащим оттуда данные по диете номер 1 и посмотрим, действительно ли она помогает сбросить вес.

```{r}
diet <- readr::read_csv("https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv")
diet1 <- diet %>%
  filter(Diet == 1)
```

Провести двухвыборочный t-тест можно в R двумя базовыми способами. Первый вариант - это дать два вектора значений. Это удобно в случае широкого формата данных.

```{r}
t.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)
```

Второй вариант - используя формулы. Это удобно при длинном формате данных:

```{r}
diet1_long <- diet1 %>%
  pivot_longer(
  cols = c(pre.weight, weight6weeks),
  names_to = "when",
  values_to = "weight"
  )
  

t.test(weight ~ when, data = diet1_long, paired = TRUE)
t.test(diet1_long$weight ~ diet1_long$when, paired = TRUE)
```

В обоих вариантах мы использовали `paired = TRUE` , чтобы обозначить использование именно зависимого (т.е. парного) t-теста.

| Внутрииндивидуальный план 	  | Межиндивидуальный план 	      |
|------------------------------	|-----------------------------	|
| Зависимый t-тест          	  | Независимый t-тест     	      |
| `t.test(..., paired = TRUE)`  | `t.test(..., paired = FALSE)`	|

### Двухвыборочный независимый t-тест {#ind_ttest}

В случае независимого t-теста формула отличается. Однако гипотеза остается такой же и логика примерна та же.

У двух выборок могут различаться стандартные отклонения, поэтому для подсчет стандартной ошибки разницы средних для независимых выборок нужно сначала посчитать **объединенное стандартное отклонение (pooled standard deviation)**:

$$s^2_{pool} = \frac {(n_1-1)s^2_1 + (n_2-1)s^2_2} {(n_1 - 1) + (n_2 -1)}$$

Тогда стандартная ошибка разницы средних считается следующим образом:

$$se_{m_1 - m_2} = \sqrt {(s^2_{pool}) (\frac {1} {n_1} + \frac {1}{n_2} )}$$

Выглядит сложно, но по своей сути это что-то вроде усредненного стандартного отклонения (с учетом размеров выборок). Ну а t-статистика затем считается просто:

$$t = \frac {(m_1 - m_2) - (\mu_1 - \mu_2)} {se_{m_1 - m_2}} = \frac {(m_1 - m_2) - 0} {se_{m_1 - m_2}} = \frac {m_1 - m_2} {se_{m_1 - m_2}}$$ 

Давайте теперь опробуем независимый t-тест для сравнения веса испытуемых двух групп после диеты. Мы снова воспользуемся функцией `t.test()`, но теперь уже поставим `paired = FALSE`:

```{r}
diet12 <- diet %>%
  filter(Diet %in% 1:2)
t.test(weight6weeks ~ Diet, data = diet12, paired = FALSE)
```

Если присмотритесь, то увидите, что со степенями свободы что-то странное. Они дробные! Дело в том, что мы провели не совсем "настоящий" t-тест, а его очень близкую альтернативу под названием **тест Уэлча** *(Welch test)*, который иногда называют **поправкой Уэлча** к t-тесту. Эта поправка позволяет тесту лучше справляться с выборками с разной дисперсией. Даже если у нас нет проблем с разной дисперсией, то от поправки Уэлча хуже не будет, поэтому это вариант по умолчанию в R.

Но если его хочется отключить, то нужно поставить `var.equal = TRUE`.

```{r}
t.test(weight6weeks ~ Diet, data = diet12, paired = FALSE, var.equal = TRUE)
```

## Допущения t-теста {#assumptions_ttest}

## Непараметрические аналоги t-теста {#nonparam_ttest}

