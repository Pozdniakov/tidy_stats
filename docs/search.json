[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Анализ данных и статистика в R",
    "section": "",
    "text": "1 О курсе\nЗдесь будут материалы для курса “Анализ данных и статистика в R”. Эта онлайн-книжка написана с помощью quatro и пакета {bookdown}, здесь можно посмотреть код с материалами. Эта книга будет постоянно пополняться, поэтому следите за обновлениями!\nПо всем вопросам пишите на мне на почту ivanspozdniakov@gmail.com, VK или в Telegram:@pozdniakovivan.\nЭта книжка абсолютно бесплатна, ее можно скачивать, делиться ей с другими, я буду только рад этому!\nЕсли вы хотите поддержать мою работу, то может оформить подписку:\n\nна Патреоне (если вы находитесь за границей России)\nна Бусти (если вы находитесь в России)"
  },
  {
    "objectID": "005-whole_r_intro.html",
    "href": "005-whole_r_intro.html",
    "title": "Основы R и Rstudio",
    "section": "",
    "text": "В этом разделе книги мы разберемся с основами программирования в R. Мы обучимся всему необходимому для работы в R, в том числе довольно продвинутым инструментам.\n\nВ главе Глава 2 разбирается установка R и RStudio, как вводить команды и сохранять скрипты, создавать переменные, пользоваться операторами и функциями, разберем типы данных в R.\nГлава Глава 3 полностью посвящена векторам: их созданию, индексированию и работе с пропущенными значениями (NA).\nВ главе Глава 4 разобраны более сложные структуры: список, матрица, массив, датафрейм.\nВ Глава 5 мы научимся устанавливать и работать с дополнительными пакетами.\nГлава Глава 6 полностью посвящена импорту и экспорту данных, а так же работе с рабочей директорией и проектами RStudio.\nВ главе Глава 7 мы разберем структуры ветвления (if-else-else if) и их векторизованные аналоги. Кроме того, мы коротко коснемся работы с циклами for в R.\nГлава Глава 8 посвящена созданию пользовательских функций, анонимным функциям и функциям семейства apply()."
  },
  {
    "objectID": "010-intro.html#sec-install",
    "href": "010-intro.html#sec-install",
    "title": "2  Введение в R",
    "section": "2.1 Установка R и Rstudio",
    "text": "2.1 Установка R и Rstudio\nДля работы с R необходимо его сначала скачать и установить.\n\nR\n\nна Windows, найдите большую кнопку Download R (номер версии) for Windows.\nна Mac, если маку меньше, чем 5 лет, то смело ставьте *.pkg файл с последней версией. Если старше, то поищите на той же странице версию для вашей системы.\nна Linux, также можно добавить зеркало и установить из командной строки:\n\n\n\nsudo apt-get install r-cran-base\nВ данной книге используется следующая версия R:\n\nsessionInfo()$R.version$version.string\n\n[1] \"R version 4.2.2 (2022-10-31)\"\n\n\nПосле установки R необходимо скачать и установить RStudio:\n\nRStudio\n\nЕсли вдруг что-то установить не получается (или же вы просто не хотите устанавливать на компьютер лишние программы), то можно работать в облаке, делая все то же самое в веб-браузере:\n\nRStudio cloud\n\nПервый и вполне закономерный вопрос: зачем мы ставили R и отдельно еще какой-то RStudio? Если опустить незначительные детали, то R – это сам язык программирования, а RStudio – это среда (IDE), которая позволяет в этом языке очень удобно работать.\n\nRStudio – это не единственная среда для R, но, определенно, самая удобная на сегодняшний день. Почти все пользуются именно ею и не стоит тратить время на поиск чего-то более удобного и лучшего. Если же вы привыкли работать с Jupyter Notebook, то в R обычно вместо него используется великолепный RMarkdown – с помощью которого и написан этот онлайн-учебник, кстати говоря. И с RMarkdown мы тоже будем разбираться!"
  },
  {
    "objectID": "010-intro.html#sec-rstudio",
    "href": "010-intro.html#sec-rstudio",
    "title": "2  Введение в R",
    "section": "2.2 Знакомство с RStudio",
    "text": "2.2 Знакомство с RStudio\nТак, давайте взглянем на то, что нам тут открылось:\n\nВ первую очередь нас интересуют два окна: 1 - Code Editor (окно для написания скриптов) 1 и 2 - R Console (консоль). Здесь можно писать команды и запускать их. При этом работа в консоли и работа со скриптом немного различается.\nВ 2 - R Console вы пишите команду и запускаете ее нажиманием Enter. Иногда после запуска команды появляется какой-то результат. Если нажимать стрелку вверх на клавиатуре, то можно выводить в консоль предыдущие команды. Это очень удобно для запуска предыдущих команд с небольшими изменениями.\nВ 1 - Code Editor для запуска команды вы должны выделить ее и нажать Ctrl + Enter (Cmd + Enter на macOS). Если не нажать эту комбинацию клавиш, то команда не запустится. Можно выделить и запустить сразу несколько команд или даже все команды скрипта. Все команды скрипта можно выделить с помощью сочетания клавиш Ctrl + A на Windows и Linux, Cmd + A на macOS 2. Как только вы запустите команду (или несколько команд), соответствующие строчки кода появятся в 2 - R Console, как будто бы вы запускали их прямо там.\nОбычно в консоли удобно что-то писать, чтобы быстро что-то посчитать. Скрипты удобнее при работе с длинными командами и как способ сохранения написанного кода для дальнейшей работы. Для сохранения скрипта нажмите File - Save As.... R скрипты сохраняются с разрешением .R, но по своей сути это просто текстовые файлы, которые можно открыть и модифицировать в любом текстовом редакторе а-ля “Блокнот”.\n3 - Workspace and History – здесь можно увидеть переменные. Это поле будет автоматически обновляться по мере того, как Вы будете запускать строчки кода и создавать новые переменные. Еще там есть вкладка с историей всех команд, которые были запущены.\n4 - Plots and files. Здесь есть очень много всего. Во-первых, небольшой файловый менеджер, во-вторых, там будут появляться графики, когда вы будете их рисовать. Там же есть вкладка с вашими пакетами (Packages) и Help по функциям. Но об этом потом."
  },
  {
    "objectID": "010-intro.html#sec-calc",
    "href": "010-intro.html#sec-calc",
    "title": "2  Введение в R",
    "section": "2.3 R как калькулятор",
    "text": "2.3 R как калькулятор\nR – полноценный язык программирования, который позволяет решать широкий спектр задач. Но в первую очередь R используется для анализа данных и статистических вычислений. Тем не менее, многими R до сих пор воспринимается как просто продвинутый калькулятор. Ну что ж, калькулятор, так калькулятор.\nДавайте начнем с самого простого и попробуем использовать R как калькулятор с помощью арифметических операторов +, -, *, /, ^ (степень), () и т.д.\nПросто запускайте в консоли пока не надоест:\n\n40+2\n\n[1] 42\n\n3-2\n\n[1] 1\n\n5*6\n\n[1] 30\n\n99/9 #деление\n\n[1] 11\n\n2^3 #степень\n\n[1] 8\n\n13 %/% 3 #целочисленное деление\n\n[1] 4\n\n13 %% 3 #остаток от деления\n\n[1] 1\n\n\nПопробуйте самостоятельно посчитать что-нибудь с разными числами.\n\nНичего сложного, верно? Вводим выражение и получаем результат.\nВы могли заметить, что некоторые команды у меня заканчиваются знаком решетки (#). Все, что написано в строчке после # игнорируется R при выполнении команды. Написанные команды в скрипте рекомендуется сопровождать комментариями, которые будут объяснять вам же в будущем (или кому-то еще), что конкретно происходит в соответствующем куске кода 3. Кроме того, комментарии можно использовать в тех случаях, когда вы хотите написать кусок кода по-другому, не стирая полностью предыдущий код: достаточно “закомментить” нужные строчки - поставить # в начало каждой строки, которую вы хотите переписать. Для этого есть специальное сочетание горячих клавиш: Ctrl + Shift + C (Cmd + Shift + C на macOS) – во всех выделенных строчках будет написан # в начале.\nСогласно данным навязчивых рекламных баннеров в интернете, только 14% россиян могут справиться с этим примером:\n\n2 + 2 * 2\n\n[1] 6\n\n\nНа самом деле, разные языки программирования ведут себя по-разному в таких ситуациях, поэтому ответ 6 (сначала умножаем, потом складываем) не так очевиден.\nПорядок выполнения арифметических операций (т.е. приоритет операторов, operator precedence) в R как в математике, так что не забывайте про скобочки.\n\n(2+2)*2\n\n[1] 8\n\n\nЕсли Вы не уверены в том, какие операторы имеют приоритет, то используйте скобочки, чтобы точно обозначить, в каком порядке нужно производить операции. Или же смотрите на таблицу приоритета операторов с помощью команды ?Syntax."
  },
  {
    "objectID": "010-intro.html#sec-func",
    "href": "010-intro.html#sec-func",
    "title": "2  Введение в R",
    "section": "2.4 Функции",
    "text": "2.4 Функции\nДавайте теперь извлечем корень из какого-нибудь числа. В принципе, тем, кто помнит школьный курс математики, возведения в степень вполне достаточно:\n\n16 ^ 0.5\n\n[1] 4\n\n\nНу а если нет, то можете воспользоваться специальной функцией: это обычно какие-то буквенные символы с круглыми скобками сразу после названия функции. Мы подаем на вход (внутрь скобочек) какие-то данные, внутри этих функций происходят какие-то вычисления, которые выдает в ответ какие-то другие данные (или же функция записывает файл, рисует график и т.д.).\nВот, например, функция для корня:\n\nsqrt(16)\n\n[1] 4\n\n\n\nR – case-sensitive язык, т.е. регистр важен. SQRT(16) не будет работать.\n\nА вот так выглядит функция логарифма:\n\nlog(8)\n\n[1] 2.079442\n\n\nТак, вроде бы все нормально, но… Если Вы еще что-то помните из школьной математики, то должны понимать, что что-то здесь не так.\nЗдесь не хватает основания логарифма!\n\nЛогарифм – показатель степени, в которую надо возвести число, называемое основанием, чтобы получить данное число.\n\nТо есть у логарифма 8 по основанию 2 будет значение 3:\n\\(\\log_2 8 = 3\\)\nТо есть если возвести 2 в степень 3 у нас будет 8:\n\\(2^3 = 8\\)\nТолько наша функция считает все как-то не так.\nЧтобы понять, что происходит, нам нужно залезть в хэлп этой функции:\n\n?log\n\nСправа внизу в RStudio появится вот такое окно:\n\nДействительно, у этой функции есть еще аргумент base =. По умолчанию он равен числу Эйлера (2.7182818…), т.е. функция считает натуральный логарифм. В большинстве функций R есть какой-то основной инпут – данные в том или ином формате, а есть и дополнительные параметры, которые можно прописывать вручную, если параметры по умолчанию вас не устраивают.\n\nlog(x = 8, base = 2)\n\n[1] 3\n\n\n…или просто (если Вы уверены в порядке переменных):\n\nlog(8,2)\n\n[1] 3\n\n\nБолее того, Вы можете использовать результат выполнения одних функций в качестве аргумента для других:\n\nlog(8, sqrt(4))\n\n[1] 3\n\n\nЕсли эксплицитно писать имена аргументов, то их порядок в функции не важен:\n\nlog(base = 2, x = 8)\n\n[1] 3\n\n\nА еще можно писать имена аргументов не полностью, если они не совпадают с другими:\n\nlog(b = 2, x = 8)\n\n[1] 3\n\n\nМы еще много раз будем возвращаться к функциям. Вообще, функции – это одна из важнейших штук в R (примерно так же как и в Python). Мы будем создавать свои функции, использовать функции как аргументы для функций и многое-многое другое. В R очень крутые возможности работы с функциями. Поэтому подружитесь с функциями, они клевые.\n\nАрифметические знаки, которые мы использовали: +,-,/,^ и т.д. называются операторами и на самом деле тоже являются функциями:\n\n\n'+'(3,4)\n\n[1] 7"
  },
  {
    "objectID": "010-intro.html#sec-google",
    "href": "010-intro.html#sec-google",
    "title": "2  Введение в R",
    "section": "2.5 В любой непонятной ситуации – гуглите",
    "text": "2.5 В любой непонятной ситуации – гуглите\nЕсли вдруг вы не знаете, что искать в хэлпе, или хэлпа попросту недостаточно, то… гуглите!\n\nНет ничего постыдного в том, чтобы гуглить решения проблем. Это абсолютно нормально. Используйте силу интернета во благо и да помогут вам Stackoverflow4 и бесчисленные R-туториалы!\n\n\n\n\n\n\n\nГлавное, помните: загуглить работающий ответ всегда недостаточно. Надо понять, как и почему решение работает. Иначе что-то обязательно пойдет не так.\nКроме того, правильно загуглить проблему – не так уж и просто.\n\nКороче говоря:\n\nГуглить – хорошо, бездумно копировать чужие решения – плохо."
  },
  {
    "objectID": "010-intro.html#sec-variables",
    "href": "010-intro.html#sec-variables",
    "title": "2  Введение в R",
    "section": "2.6 Переменные",
    "text": "2.6 Переменные\nВажная штука в программировании на практически любом языке – возможность сохранять значения в переменных. В R это обычно делается с помощью вот этих символов: <- (но можно использовать и обычное =, хотя это не очень принято). Для этого есть удобное сочетание клавиш: нажмите одновременно Alt + - (или option + - на macOS).\n\nЗаметьте, при присвоении результат вычисления не выводится в консоль! Если опустить детали, то обычно результат выполнения команды либо выводится в консоль, либо записывается в переменную.\n\n\na <- 2\na\n\n[1] 2\n\n\nСправа от <- находится значение, которое вы хотите сохранить, или же какое-то выражение, результат которого вы хотите сохранить в эту переменную5:\nСлева от <- находится название будущей переменной. Название переменных может быть самым разным. Есть несколько ограничений для синтаксически валидных имен переменных: они должны включать в себя буквы, цифры, . или _, начинаться на букву (или точку, за которой не будет следовать цифра), не должны совпадать с коротким списком зарезервированных слов. Короче говоря, название не должно включать в себя пробелы и большинство других знаков.\nНельзя: - new variable - _new_variable - .1var - v-r\nМожно: - new_variable - .new.variable - var_2\nОбязательно делайте названия переменных осмысленными! Старайтесь делать при этом их понятными и короткими, это сохранит вам очень много времени, когда вы (или кто-то еще) будете пытаться разобраться в написанном ранее коде. Если название все-таки получается длинным и состоящим из нескольких слов, то лучше всего использовать нижнее подчеркивание в качестве разделителя: some_variable6.\nПосле присвоения переменная появляется во вкладке Environment в RStudio:\n\nТеперь использовать переменные в функциях и просто вычислениях:\n\nb <- a ^ a + a * a\nb\n\n[1] 8\n\nlog(b, a)\n\n[1] 3"
  },
  {
    "objectID": "010-intro.html#sec-logic",
    "href": "010-intro.html#sec-logic",
    "title": "2  Введение в R",
    "section": "2.7 Логические операторы",
    "text": "2.7 Логические операторы\nВы можете сравнивать разные переменные:\n\na == b\n\n[1] FALSE\n\n\nЗаметьте, что сравнивая две переменные мы используем два знака равно ==, а не один =. Иначе это будет означать присвоение.\n\na = b\na\n\n[1] 8\n\n\nТеперь Вы сможете понять комикс про восстание роботов на следующей странице (пусть он и совсем про другой язык программирования)\n\nЭтот комикс объясняет, как важно не путать присваивание и сравнение (хотя я иногда путаю до сих пор =( ).\nИногда нам нужно проверить на неравенство:\n\na <- 2\nb <- 3\n\na == b\n\n[1] FALSE\n\na != b\n\n[1] TRUE\n\n\nВосклицательный язык в программировании вообще и в R в частности стандартно означает отрицание.\nЕще мы можем сравнивать на больше/меньше:\n\na > b\n\n[1] FALSE\n\na < b\n\n[1] TRUE\n\na >= b\n\n[1] FALSE\n\na <= b\n\n[1] TRUE\n\n\nЭтим мы будем пользоваться в дальнейшем регулярно! Именно на таких простых логических операциях построено большинство операций с данными."
  },
  {
    "objectID": "010-intro.html#sec-data_types",
    "href": "010-intro.html#sec-data_types",
    "title": "2  Введение в R",
    "section": "2.8 Типы данных",
    "text": "2.8 Типы данных\n\n2.8.1 Числовые типы\nДо этого момента мы работали только с числами (numeric). На самом деле, в R три типа numeric: integer (целые), double (дробные), complex (комплексные числа)7. R сам будет конвертировать числа в нужный числовой тип при необходимости, поэтому этим можно не заморачиваться за исключением редких случаев.\nЕсли же все-таки нужно задать конкретный тип числа эксплицитно, то можно воспользоваться функциями as.integer(), as.double() и as.complex().\nЕсли число выглядит как целое, еще не факт, что это integer. Внутри оно может храниться как дробное, но, как я уже написал, это обычно не так важно. Но если очень нужно сделать именно integer, при создании числа можно поставить в конце L:\n\nis.integer(5)\n\n[1] FALSE\n\nis.integer(5L)\n\n[1] TRUE\n\n\nПро double есть еще один маленький секрет. Дело в том, что дробные числа хранятся в R как числа с плавающей запятой двойной точности (отсюда и название – “double”, т.е. “double precision”). Да-да, компьютеры неточные! Дробные числа в компьютере могут быть записаны только с определенной степенью точности, поэтому иногда встречаются вот такие вот ситуации:\n\nsqrt(2) ^ 2 == 2\n\n[1] FALSE\n\n\nКазалось бы, с обоих сторон – 2, почему же тогда FALSE? Дело в том, что в обоих случаях это дробное число, которое не может равняться ровно двум. Внутри это не два, а что-то вроде 2.0000….001 или 1.9999…999, число записано как степени двойки и отображено в десятичной системе. R не показывает все доступные цифры дробной части ради удобства, поэтому показывает округление, и мы видим просто число 2.\nПоэтому при сравнении двух чисел происходит не сравнение их разницы с чистым круглым нулем, а сопоставление с очень маленьким числом – машинной ошибкой или машинным эпсилоном (machine epsilon). Если разница между двумя дробными числами меньше этого эпсилона, то числа считаются равными. Если выходят за пределы этой ошибки, то нет. Размер машинного эпсилона можно посмотреть с помощью .Machine$double.eps.\nОбычно это все работает хорошо, но некоторые операции “выпрыгивают” за рамки этой ошибки, отсюда и такое “странное” поведение, которое иногда может возникать при сравнении двух чисел. Если хотите углубиться в этот вопрос, то можете почитать здесь.\nЭто довольно стандартная ситуация, характерная не только для R. Чтобы ее избежать, можно воспользоваться функцией all.equal():\n\nall.equal(sqrt(2) ^ 2, 2)\n\n[1] TRUE\n\n\nЕще один пример необычного поведения дробных чисел, связанный с их “неточностью”, можно наблюдать в ситуациях, где вы ожидаете ноль, а получаете что-то такое:\n\nsin(pi)\n\n[1] 1.224647e-16\n\n\nПо правилам тригонометрии, \\(sin(\\pi) = 0\\), тогда откуда у нас это странное число с e-16 в конце?\nЭто то, что называется экспоненциальной записью (scientific notation) числа, которую R использует автоматически, если нужно напечатать очень маленькое или очень большое число. Экспоненциальная запись часто используется как в компьютерах, так и во многих науках, так что читать ее полезно уметь.\nЕсли перед нами очень маленькое число, то вместо того, чтобы писать многочисленные нули, можно записать его как \\(m\\times 10^{n}\\) , где \\(m\\) – число от 1 до 10, а \\(n\\) – это отрицательная степень десяти: \\(10^{-1} = 0.1\\), \\(10^{-2} = 0.01\\), \\(10^{-3} = 0.001\\), … , \\(10^{-16} = 0.0000000000000001\\).\nе-16 в конце числа – это и есть $10^{-16}$, а 1.224647 – это множитель \\(m\\), на который полученное число с очень большим количеством нулей умножается (точнее, только его первые несколько цифр). Получается, что этот множитель не сильно меняет погоды, поэтому когда видите число с е-, нужно смотреть в первую очередь именно на степень. Вот так это число выглядит в родной для нас десятичной записи:\n\nformat(sin(pi), scientific = FALSE)\n\n[1] \"0.0000000000000001224647\"\n\n\nЭта маленькая дробная часть возникла из-за этой “неточности” хранения дробных чисел и самого числа \\(\\pi\\) в компьютере, которую мы обсуждали выше.\nАналогично маленьким числам, R использует экспоненциальную запись, когда нужно напечатать очень большое число:\n\n2 ^ 40\n\n[1] 1.099512e+12\n\n\nОбратите внимание, что здесь у нас e+12, а не e-12, что означает $10^{12}$, а не $10^{-12}$. То есть перед нами теперь \\(1.099512\\times 10^{12}\\):\n\nformat(2 ^ 40, scientific = FALSE)\n\n[1] \"1099511627776\"\n\n\nОпять же, 1.099512 – это только первые цифры, в экспоненциальной записи R не показывает их все. Смотреть нужно сначала на степень (e+12), только потом – на множитель впереди.\n\n\n2.8.2 Строковый тип\nСтроковые (character) данные – это набор букв, цифр и символов. Чтобы создать строковую переменную, нужные знаки обособляются кавычками.\n\ns <- \"Всем привет!\"\ns\n\n[1] \"Всем привет!\"\n\nclass(s)\n\n[1] \"character\"\n\n\nКак и в Python, можно использовать как \", так и ' (что удобно, когда строчка внутри уже содержит какие-то кавычки).\n\n\"Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn\"\n\n[1] \"Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn\"\n\n\nГлавное, открывать и закрывать кавычки одинаковыми кавычками ( \" или ')\nЧтобы соединить несколько строковых переменных вместе, можно воспользоваться функцией paste()8:\n\npaste(\"I\", \"love\", \"R\")\n\n[1] \"I love R\"\n\n\nПо умолчанию функция paste() соединяет строки пробелами, но разделитель можно настроить параметром sep =:\n\npaste(\"I\", \"love\", \"R\", sep = \"_<3_\")\n\n[1] \"I_<3_love_<3_R\"\n\n\nЧтобы соединять строки, так сказать, “без ничего”, нужно поставить sep = \"\" или же воспользоваться функцией paste0() специально для этого конкретного случая:\n\npaste(\"I\", \"love\", \"R\", sep = \"\")\n\n[1] \"IloveR\"\n\npaste0(\"I\", \"love\", \"R\")\n\n[1] \"IloveR\"\n\n\n\n\n2.8.3 Логический тип\nЛогические (logical) данные – это просто TRUE или FALSE.\n\nt1 <- TRUE\nf1 <- FALSE\n\nt1\n\n[1] TRUE\n\nf1\n\n[1] FALSE\n\n\nВообще, можно еще писать T и F (но не True и False!)\n\nt1 <- T\nf1 <- F\n\nЭто плохая практика: R защищает от перезаписи переменные TRUE и FALSE, но не защищает от этого T и F.\n\nTRUE <- FALSE\n\nError in TRUE <- FALSE: invalid (do_set) left-hand side to assignment\n\nTRUE\n\n[1] TRUE\n\nT <- FALSE\nT\n\n[1] FALSE\n\n\nФункция rm() позволяет удалить ненужную переменную:\n\nrm(T)\n\nМы уже встречались с логическими значениями при сравнении двух числовых переменных. Теперь вы можете догадаться, что результаты сравнения, например, числовых или строковых переменных, можно тоже сохранять в переменные!\n\ncomparison <- a == b\ncomparison\n\n[1] FALSE\n\n\nЭто нам очень понадобится, когда мы будем работать с реальными данными: нам нужно будет постоянно вытаскивать какие-то данные из датасета, что как раз и построено на игре со сравнением переменных.\nЧтобы этим хорошо уметь пользоваться, нам нужно еще освоить как работать с логическими операторами. Про один мы немного уже говорили – это логическое НЕ (!). ! превращает TRUE в FALSE, а FALSE в TRUE:\n\nt1\n\n[1] TRUE\n\n!t1\n\n[1] FALSE\n\n!!t1 #Двойное отрицание!\n\n[1] TRUE\n\n\nЕще есть логическое И (выдаст TRUE только в том случае если обе переменные TRUE):\n\nt1 & t1\n\n[1] TRUE\n\nt1 & f1\n\n[1] FALSE\n\nf1 & t1\n\n[1] FALSE\n\nf1 & f1\n\n[1] FALSE\n\n\nА еще логическое ИЛИ (выдаст TRUE в случае если хотя бы одна из переменных TRUE):\n\nt1 | t1\n\n[1] TRUE\n\nt1 | f1\n\n[1] TRUE\n\nf1 | t1\n\n[1] TRUE\n\nf1 | f1\n\n[1] FALSE\n\n\nОбратите внимание: t1 | t1, то есть когда с обоих сторон TRUE, тоже возвращает TRUE!\nЕсли кому-то вдруг понадобится другое ИЛИ (строгое ЛИБО) – есть функция xor(), принимающая два аргумента и возвращая TRUE только в том случае, если ровно один из двух аргументов равен TRUE. Но на практике она нужна очень редко, тогда как логические И и ИЛИ нужны очень часто: например, вам нужно отобрать только респондентов от 18 до 25, для этого нужно сделать два сравнения: что возраст больше 18 и что возраст меньше 25, после чего соединить два сравнения логическим И.\nИтак, мы только что разобрались с самой занудной (хотя и важной) частью - с основными типа данных в R и как с ними работать9. Пора переходить к чему-то более интересному и специфическому для R. Вперед к ВЕКТОРАМ!"
  },
  {
    "objectID": "013-vector.html#sec-atomic",
    "href": "013-vector.html#sec-atomic",
    "title": "3  Вектор",
    "section": "3.1 Понятие atomic вектора в R",
    "text": "3.1 Понятие atomic вектора в R\nЕсли у вас не было линейной алгебры (или у вас с ней было все плохо), то просто запомните, что вектор (atomic vector или просто atomic) – это набор (столбик) чисел в определенном порядке.\nЕсли вы привыкли из школьного курса физики считать вектора стрелочками, то не спешите возмущаться и паниковать. Представьте стрелочки как точки из нуля координат {0,0} до какой-то точки на координатной плоскости, например, {2,3}:\n\nВот последние два числа и будем считать вектором. Попытайтесь теперь мысленно стереть координатную плоскость и выбросить стрелочки из головы, оставив только последовательность чисел {2,3}:\n\nНа самом деле, мы уже работали с векторами в R, но, возможно, вы об этом даже не догадывались. Дело в том, что в R нет как таковых скалярных (т.е. одиночных) значений, есть вектора длиной 1. Такие дела!\nЧтобы создать вектор из нескольких значений, нужно воспользоваться функцией c():\n\nc(4, 8, 15, 16, 23, 42)\n\n[1]  4  8 15 16 23 42\n\nc(\"Hey\", \"Hey\", \"Ho\")\n\n[1] \"Hey\" \"Hey\" \"Ho\" \n\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\n\n\nОдна из самых мерзких и раздражающих причин ошибок в коде – это использование с из кириллицы вместо c из латиницы. Видите разницу? И я не вижу. А R видит. И об этом сообщает:\n\n\nс(3, 4, 5)\n\nError in с(3, 4, 5): could not find function \"с\"\n\n\nДля создания числовых векторов есть удобный оператор :.\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n5:-3\n\n[1]  5  4  3  2  1  0 -1 -2 -3\n\n\nЭтот оператор создает вектор от первого числа до второго с шагом 1. Вы не представляете, как часто эта штука нам пригодится… Если же нужно сделать вектор с другим шагом, то есть функция seq():\n\nseq(10, 100, by = 10)\n\n [1]  10  20  30  40  50  60  70  80  90 100\n\n\nКроме того, можно задавать не шаг, а длину вектора. Тогда функция seq() сама посчитает шаг:\n\nseq(1, 13, length.out = 4)\n\n[1]  1  5  9 13\n\n\nДругая функция – rep() – позволяет создавать вектора с повторяющимися значениями. Первый аргумент – значение, которое нужно повторять, а второй аргумент – сколько раз повторять.\n\nrep(1, 5)\n\n[1] 1 1 1 1 1\n\n\nИ первый, и второй аргумент могут быть векторами!\n\nrep(1:3, 3)\n\n[1] 1 2 3 1 2 3 1 2 3\n\nrep(1:3, 1:3)\n\n[1] 1 2 2 3 3 3\n\n\nЕще можно объединять вектора (что мы, по сути, и делали, просто с векторами длиной 1):\n\nv1 <- c(\"Hey\", \"Ho\")\nv2 <- c(\"Let's\", \"Go!\")\nc(v1, v2)\n\n[1] \"Hey\"   \"Ho\"    \"Let's\" \"Go!\"  \n\n\nОчень многие функции в R работают именно с векторами. Например, функции sum() (считает сумму значений вектора) и mean() (считает среднее арифметическое всех значений в векторе):\n\nsum(1:10)\n\n[1] 55\n\nmean(1:10)\n\n[1] 5.5"
  },
  {
    "objectID": "013-vector.html#sec-coercion",
    "href": "013-vector.html#sec-coercion",
    "title": "3  Вектор",
    "section": "3.2 Приведение типов",
    "text": "3.2 Приведение типов\nЧто будет, если вы объедините два вектора с значениями разных типов? Ошибка?\nМы уже обсуждали, что в обычных векторах (atomic векторах) может быть только один тип данных. В некоторых языках программирования при операции с данными разных типов мы бы получили ошибку. А вот в R при несовпадении типов произойдет попытка привести типы к “общему знаменателю”, то есть конвертировать данные в более “широкий” тип (а иногда – более “узкий” тип, если того требует функция).\nНапример:\n\nc(FALSE, 2)\n\n[1] 0 2\n\n\nFALSE превратился в 0 (а TRUE превратился бы в 1), чтобы оба значения можно было объединить в вектор. То же самое произошло бы в случае операций с векторами:\n\n2 + TRUE\n\n[1] 3\n\n\nЭто называется неявным приведением типов (implicit coercion).\nВот более сложный пример:\n\nc(TRUE, 3, \"hi\")\n\n[1] \"TRUE\" \"3\"    \"hi\"  \n\n\nЗдесь все значения были приведены сразу к строковому типу данных.\n\n\n\n\n\nУ R есть иерархия приведения типов:\nNULL < raw < logical < integer < double < complex < character < list < expression.\nМы из этого списка еще многого не знаем, сейчас важно запомнить, что логические данные – TRUE и FALSE – превращаются в 0 и 1 соответственно, а 0 и 1 в строчки \"0\" и \"1\".\nЕсли Вы боитесь полагаться на приведение типов, то можете воспользоваться функциями as.нужныйтипданных для явного приведения типов (explicit coercion):\n\nas.numeric(c(TRUE, FALSE, FALSE))\n\n[1] 1 0 0\n\nas.character(as.numeric(c(TRUE, FALSE, FALSE)))\n\n[1] \"1\" \"0\" \"0\"\n\n\nМожно превращать и обратно, например, строковые значения в числовые. Если среди числа встретится буква или другой неподходящий знак, то мы получим предупреждение NA – пропущенное значение (мы очень скоро научимся с ними работать).\n\nas.numeric(c(\"1\", \"2\", \"три\"))\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\n\nОдин из распространенных примеров использования неявного приведения типов – использования функций sum() и mean() для подсчета в логическом векторе количества и доли TRUE соответсвенно. Мы будем много раз пользоваться этим приемом в дальнейшем!"
  },
  {
    "objectID": "013-vector.html#sec-vector_op",
    "href": "013-vector.html#sec-vector_op",
    "title": "3  Вектор",
    "section": "3.3 Векторизация",
    "text": "3.3 Векторизация\nВсе те арифметические операторы, что мы использовали ранее, можно использовать с векторами одинаковой длины:\n\nn <- 1:4\nm <- 4:1\nn + m\n\n[1] 5 5 5 5\n\nn - m\n\n[1] -3 -1  1  3\n\nn * m\n\n[1] 4 6 6 4\n\nn / m\n\n[1] 0.2500000 0.6666667 1.5000000 4.0000000\n\nn ^ m + m * (n - m)\n\n[1] -11   5  11   7\n\n\nЕсли применить операторы на двух векторах одинаковой длины, то мы получим результат поэлементного применения оператора к двум векторам. Это называется векторизацией (vectorization).\n\nЕсли после какого-нибудь MATLAB Вы привыкли, что по умолчанию операторы работают по правилам линейной алгебры и m * n будет давать скалярное произведение (dot product), то снова нет. Для скалярного произведения нужно использовать операторы с % по краям:\n\n\nn %*% m\n\n     [,1]\n[1,]   20\n\n\n\nАбсолютно так же и с операциями с матрицами в R, хотя про матрицы будет немного позже.\n\nВ принципе, большинство функций в R, которые работают с отдельными значениями, так же хорошо работают и с целыми векторами. Скажем, если вы хотите извлечь корень из нескольких чисел, то для этого не нужны никакие циклы (как это обычно делается во многих других языках программирования). Можно просто “скормить” вектор функции и получить результат применения функции к каждому элементу вектора:\n\nsqrt(1:10)\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\n\nТаких векторизованных функций в R очень много. Многие из них написаны на более низкоуровневых языках программирования (C, C++, FORTRAN), за счет чего использование таких функций приводит не только к более элегантному, лаконичному, но и к более быстрому коду.\n\nВекторизация в R – это очень важная фишка, которая отличает этот язык программирования от многих других. Если вы уже имеете опыт программирования на другом языке, то вам во многих задачах захочется использовать циклы типа for и while @ref(for). Не спешите этого делать! В очень многих случаях циклы можно заменить векторизацией. Тем не менее, векторизация – это не единственный способ избавить от циклов типа for и while @ref(apply)."
  },
  {
    "objectID": "013-vector.html#sec-recycling",
    "href": "013-vector.html#sec-recycling",
    "title": "3  Вектор",
    "section": "3.4 Ресайклинг",
    "text": "3.4 Ресайклинг\nДопустим мы хотим совершить какую-нибудь операцию с двумя векторами. Как мы убедились, с этим обычно нет никаких проблем, если они совпадают по длине. А что если вектора не совпадают по длине? Ничего страшного! Здесь будет работать правило ресайклинга (правило переписывания, recycling rule). Это означает, что если мы делаем операцию на двух векторах разной длины, то если короткий вектор кратен по длине длинному, короткий вектор будет повторяться необходимое количество раз:\n\nn <- 1:4\nm <- 1:2\nn * m\n\n[1] 1 4 3 8\n\n\nА что будет, если совершать операции с вектором и отдельным значением? Можно считать это частным случаем ресайклинга: короткий вектор длиной 1 будет повторятся столько раз, сколько нужно, чтобы он совпадал по длине с длинным:\n\nn * 2\n\n[1] 2 4 6 8\n\n\nЕсли же меньший вектор не кратен большему (например, один из них длиной 3, а другой длиной 4), то R посчитает результат, но выдаст предупреждение.\n\nn + c(3,4,5)\n\nWarning in n + c(3, 4, 5): longer object length is not a multiple of shorter\nobject length\n\n\n[1] 4 6 8 7\n\n\nПроблема в том, что эти предупреждения могут в неожиданный момент стать причиной ошибок. Поэтому не стоит полагаться на ресайклинг некратных по длине векторов. А вот ресайклинг кратных по длине векторов – это очень удобная штука, которая используется очень часто."
  },
  {
    "objectID": "013-vector.html#sec-index_atomic",
    "href": "013-vector.html#sec-index_atomic",
    "title": "3  Вектор",
    "section": "3.5 Индексирование векторов",
    "text": "3.5 Индексирование векторов\nИтак, мы подошли к одному из самых сложных моментов. И одному из основных. От того, как хорошо вы научись с этим работать, зависит весь ваш дальнейший успех на R-поприще!\nРечь пойдет об индексировании векторов. Задача, которую Вам придется решать каждые пять минут работы в R – как выбрать из вектора (или же списка, матрицы и датафрейма) какую-то его часть. Для этого используются квадратные скобочки [] (не круглые – они для функций!).\nСамое простое – индексировать по номеру индекса, т.е. порядку значения в векторе.\n\nn <- c(0, 1, 1, 2, 3, 5, 8, 13, 21, 34)\nn[1]\n\n[1] 0\n\nn[10]\n\n[1] 34\n\n\n\nЕсли вы знакомы с другими языками программирования (не MATLAB, там все так же) и уже научились думать, что индексация с 0 – это очень удобно и очень правильно (ну или просто свыклись с этим), то в R вам придется переучиться обратно. Здесь первый индекс – это 1, а последний равен длине вектора – ее можно узнать с помощью функции length(). С обоих сторон индексы берутся включительно.\n\nС помощью индексирования можно не только вытаскивать имеющиеся значения в векторе, но и присваивать им новые:\n\nn[3] <- 20\nn\n\n [1]  0  1 20  2  3  5  8 13 21 34\n\n\nКонечно, можно использовать целые векторы для индексирования:\n\nn[4:7]\n\n[1] 2 3 5 8\n\nn[10:1]\n\n [1] 34 21 13  8  5  3  2 20  1  0\n\nn[4:6] <- 0\nn\n\n [1]  0  1 20  0  0  0  8 13 21 34\n\n\nИндексирование с минусом выдаст вам все значения вектора кроме выбранных:\n\nn[-1]\n\n[1]  1 20  0  0  0  8 13 21 34\n\nn[c(-4, -5)]\n\n[1]  0  1 20  0  8 13 21 34\n\n\nМинус здесь “выключает” выбранные значения из вектора, а не означает отсчет с конца как в Python.\nБолее того, можно использовать логический вектор для индексирования. В этом случае нужен логический вектор такой же длины:\n\nn[c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE)]\n\n[1]  0 20  0  8 21\n\n\nЛогический вектор работает здесь как фильтр: пропускает только те значения, где на соответствующей позиции в логическом векторе для индексирования содержится TRUE, и не пропускает те значения, где на соответствующей позиции в логическом векторе для индексирования содержится FALSE.\n\nНу а если эти два вектора (исходный вектор и логический вектор индексов) не равны по длине, то тут будет снова работать правило ресайклинга!\n\nn[c(TRUE, FALSE)] #то же самое - recycling rule!\n\n[1]  0 20  0  8 21\n\n\nЕсть еще один способ индексирования векторов, но он несколько более редкий: индексирование по имени. Дело в том, что для значений векторов можно (но не обязательно) присваивать имена:\n\nmy_named_vector <- c(first = 1,\n                     second = 2,\n                     third = 3)\nmy_named_vector['first']\n\nfirst \n    1 \n\n\nА еще можно “вытаскивать” имена из вектора с помощью функции names() и присваивать таким образом новые имена.\n\nd <- 1:4\nnames(d) <- letters[1:4]\nnames(d)\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\nd[\"a\"]\n\na \n1 \n\n\n\nletters – это “зашитая” в R константа – вектор букв от a до z. Иногда это очень удобно! Кроме того, есть константа LETTERS – то же самое, но заглавными буквами. А еще в R есть названия месяцев на английском и числовая константа pi.\n\nВернемся к нашему вектору n и посчитаем его среднее с помощью функции mean():\n\nmean(n)\n\n[1] 9.7\n\n\nА как вытащить все значения, которые больше среднего?\nСначала получим логический вектор – какие значения больше среднего:\n\nlarger <- n > mean(n)\nlarger\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nА теперь используем его для индексирования вектора n:\n\nn[larger]\n\n[1] 20 13 21 34\n\n\nМожно все это сделать в одну строчку:\n\nn[n > mean(n)]\n\n[1] 20 13 21 34\n\n\nПредыдущая строчка отражает то, что мы будем постоянно делать в R: вычленять (subset) из данных отдельные куски на основании разных условий."
  },
  {
    "objectID": "013-vector.html#sec-logic_vectors",
    "href": "013-vector.html#sec-logic_vectors",
    "title": "3  Вектор",
    "section": "3.6 Работа с логическими векторами",
    "text": "3.6 Работа с логическими векторами\nНа работе с логическими векторами построено очень много удобных фишек, связанных со сравнением условий.\n\neyes <- c(\"green\", \"blue\", \"blue\", \"brown\", \"green\", \"blue\")\n\n\n3.6.1 mean() и sum() для подсчета пропорций и количества TRUE\nУже знакомая нам функция sum() позволяет посчитать количество TRUE в логическом векторе. Например, можно удобно посчитать сколько раз значение \"blue\" встречается в векторе eyes:\n\neyes == \"blue\"\n\n[1] FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\nsum(eyes == \"blue\")\n\n[1] 3\n\n\nФункцию mean() можно использовать для подсчета пропорций TRUE в логическом векторе.\n\neyes == \"blue\"\n\n[1] FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\nmean(eyes == \"blue\")\n\n[1] 0.5\n\n\nУмножив на 100, мы получим долю выраженную в процентах:\n\nmean(eyes == \"blue\") * 100\n\n[1] 50\n\n\n\n\n3.6.2 all() и any()\nФункция all() выдает TRUE только когда все значения логического вектора на входе равны TRUE:\n\nall(eyes == \"blue\")\n\n[1] FALSE\n\n\nФункция any() выдает TRUE когда есть хотя бы одно значение TRUE:\n\nany(eyes == \"blue\")\n\n[1] TRUE\n\n\nВместе с оператором ! можно получить много дополнительных вариантов. Например, есть ли хотя бы один FALSE в векторе?\n\nany(!eyes == \"blue\")\n\n[1] TRUE\n\n!all(eyes == \"blue\")\n\n[1] TRUE\n\n\nВсе ли значения в векторе равны FALSE?\n\nall(!eyes == \"blue\")\n\n[1] FALSE\n\n!any(eyes == \"blue\")\n\n[1] FALSE\n\n\n\n\n3.6.3 Превращение логических значений в индексы: which()\nКак вы уже знаете, и логические векторы, и числовые вектора с индексами могут использоваться для индексирования векторов. Иногда может понадобиться превратить логический вектор в вектор индексов. Для этого есть функция which()\n\nwhich(eyes == \"blue\")\n\n[1] 2 3 6\n\n\n\n\n3.6.4 оператор %in% и match()\nЧасто возникает такая задача: нужно проверить вектор на равенство с хотя бы одним значением из другого вектора. Например, мы хотим вычленить всех зеленоглазых и голубоглазых. Может возникнуть идея сделать так:\n\neyes[eyes == c(\"green\", \"blue\")]\n\n[1] \"green\" \"blue\"  \"green\" \"blue\" \n\n\nПеред нами самый страшный случай: результат похож на правильный, но не правильный! Попытайтесь самостоятельно понять почему этот ответ неверный и что произошло на самом деле.\nА на самом деле мы просто сравнили два вектора, один из которых короче другого, следовательно, у нас сработало правило ресайклинга.\n\nКак мы видим, это совсем не то, что нам нужно! В данной ситуации нам подойдет сравнение с двумя значениями вместе с логическим ИЛИ.\n\neyes[eyes == \"green\" | eyes == \"blue\"]\n\n[1] \"green\" \"blue\"  \"blue\"  \"green\" \"blue\" \n\n\nОднако это не очень удобно, особенно если значений больше 2. Тогда на помощь приходит оператор %in%, который выполняет именно то, что нам изначально нужно: выдает для каждого значения в векторе слева, есть ли это значение среди значений вектора справа.\n\neyes[eyes %in% c(\"green\", \"blue\")]\n\n[1] \"green\" \"blue\"  \"blue\"  \"green\" \"blue\" \n\n\nОсновное преимущество оператора %in% в его простоте и понятности. У оператора %in% есть старший брат, более сложный и более мощный. Функция match() работает похожим образом на %in%, но при совпадении значения в левом векторе с одним из значений в правом выдает индекс соответствующего значения вместо TRUE. Если же совпадений нет, то вместо FALSE функция match() выдает NA (что можно поменять параметром nomatch =).\n\nmatch(eyes, c(\"green\", \"blue\"))\n\n[1]  1  2  2 NA  1  2\n\n\nЗачем это может понадобиться? Во-первых, это способ соединить два набора данных (хотя для этого есть и более подходящие инструменты), во-вторых, так можно заменить все значения кроме выбранных заменить на NA.\n\nc(\"green\", \"blue\")[match(eyes, c(\"green\", \"blue\"))]\n\n[1] \"green\" \"blue\"  \"blue\"  NA      \"green\" \"blue\""
  },
  {
    "objectID": "013-vector.html#sec-na",
    "href": "013-vector.html#sec-na",
    "title": "3  Вектор",
    "section": "3.7 NA - пропущенные значения",
    "text": "3.7 NA - пропущенные значения\nВ реальных данных у нас часто чего-то не хватает. Например, из-за технической ошибки или невнимательности не получилось записать какое-то измерение. Для обозначения пропущенных значений в R есть специальное значение NA (расшифровывается как Not Available - недоступное значение). NA – это не строка \"NA\", не 0, не пустая строка \"\" и не FALSE. NA – это NA. Большинство операций с векторами, содержащими NA будут выдавать NA:\n\nmissed <- NA\nmissed == \"NA\"\n\n[1] NA\n\nmissed == \"\"\n\n[1] NA\n\nmissed == NA\n\n[1] NA\n\n\nЗаметьте, даже сравнение NA c NA выдает NA. Это может прозвучать абсурдно: ну как же так, и то NA, и другое NA – это же одно и то же, они должны быть равны! Не совсем: NA – это отсутствие информации об объекте, неопределенность, неизвестная нам величина. Если мы не знаем двух значений (т.е. имеем два NA), то это еще не значит, что они равны.\nИногда наличие NA в данных очень бесит:\n\nn[5] <- NA\nn\n\n [1]  0  1 20  0 NA  0  8 13 21 34\n\nmean(n)\n\n[1] NA\n\n\nПолучается, что наличие NA “заражает” неопределенностью все последующие действия. Что же делать?\nНаверное, надо сравнить вектор с NA и исключить этих пакостников. Давайте попробуем:\n\nn == NA\n\n [1] NA NA NA NA NA NA NA NA NA NA\n\n\nАх да, мы ведь только что узнали, что даже сравнение NA c NA приводит к NA! Сначала это может показаться нелогичным: ведь с обоих сторон NA, почему же тогда результат их сравнения – это тоже NA, а не TRUE?\nДело в том, что сравнивая две неопределенности, вы не можете установить между ними знак равенства. Представим себе двух супергероев: Бэтмена и Спайдермена. Допустим, мы не знаем их рост:\n\nBatman <- NA\nSpiderman <- NA\n\nОдинаковый ли у них рост?\n\nBatman == Spiderman\n\n[1] NA\n\n\nМы не знаем! Возможно, да, возможно, и нет. Поэтому у нас здесь остается неопределенность.\nТак как же избавиться от NA в данных? Самый простой способ – это функция is.na():\n\nis.na(n)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\nРезультат выполнения is.na(n) выдает FALSE на тех позициях, где у нас числа (или другие значения), и TRUE там, где у нас NA. Чтобы вычленить из вектора n все значения кроме NA нам нужно, чтобы было наоборот: TRUE, если это не NA, FALSE, если это NA. Здесь нам понадобится логический оператор НЕ ! (мы его уже встречали – см. @ref(data_types)), который инвертирует логические значения:\n\nn[!is.na(n)]\n\n[1]  0  1 20  0  0  8 13 21 34\n\n\nУра, мы можем считать среднее без NA!\n\nmean(n[!is.na(n)])\n\n[1] 10.77778\n\n\nТеперь Вы понимаете, зачем нужно отрицание (!)\nВообще, есть еще один из способов посчитать среднее, если есть NA. Для этого надо залезть в хэлп по функции mean():\n\n?mean()\n\nВ хэлпе мы найдем параметр na.rm =, который по умолчанию FALSE. Вы знаете, что нужно делать!\n\nmean(n, na.rm = T)\n\n[1] 10.77778\n\n\nNA может появляться в векторах разных типов. На самом деле, NA - это специальное значение в логических векторах, тогда как в векторах других типов NA появляется как NA_integer_, NA_real_, NA_complex_ или NA_character_, но R обычно сам все переводит в нужный формат и показывает как просто NA. Таким образом, NA в векторах разных типов – это разные NA, хотя на практике эта деталь обычно несущественна.\n\nКроме NA есть еще NaN – это разные вещи. NaN расшифровывается как Not a Number и получается в результате таких операций как 0 / 0. Тем не менее, функция is.na() выдает TRUE на NaN, а вот функция is.nan() выдает TRUE на NaN и FALSE на NA:\n\n\nis.na(NA)\n\n[1] TRUE\n\nis.na(NaN)\n\n[1] TRUE\n\nis.nan(NA)\n\n[1] FALSE\n\nis.nan(NaN)\n\n[1] TRUE"
  },
  {
    "objectID": "013-vector.html#sec-vector_end",
    "href": "013-vector.html#sec-vector_end",
    "title": "3  Вектор",
    "section": "3.8 Заключение",
    "text": "3.8 Заключение\nИтак, с векторами мы более-менее разобрались. Помните, что вектора – это один из краеугольных камней вашей работы в R. Если вы хорошо с ними разобрались, то дальше все будет довольно несложно. Тем не менее, вектора – это не все. Есть еще два важных типа данных: списки (list) и матрицы (matrix). Их можно рассматривать как своеобразное “расширение” векторов, каждый в свою сторону. Ну а списки и матрицы нужны чтобы понять основной тип данных в R – data.frame."
  },
  {
    "objectID": "016-complex_structures.html#sec-matrix",
    "href": "016-complex_structures.html#sec-matrix",
    "title": "4  Сложные структуры данных в R",
    "section": "4.1 Матрица",
    "text": "4.1 Матрица\nЕсли вдруг вас пугает это слово, то совершенно зря. Матрица (matrix) – это всего лишь “двумерный” вектор: вектор, у которого есть не только длина, но и ширина. Создать матрицу можно с помощью функции matrix() из вектора, указав при этом количество строк и столбцов.\n\nA <- matrix(1:20, nrow = 5, ncol = 4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\n\nЗаметьте, значения вектора заполняются следующим образом: сначала заполняется первый столбик сверху вниз, потом второй сверху вниз и так до конца, т.е. заполнение значений матрицы идет в первую очередь по вертикали. Это довольно стандартный способ создания матриц, характерный не только для R.\n\n\nЕсли мы знаем сколько значений в матрице и сколько мы хотим строк, то количество столбцов указывать необязательно:\n\nA <- matrix(1:20, nrow = 5)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\nВсе остальное так же как и с векторами: внутри находится данные только одного типа. Поскольку матрица – это уже двумерный массив, то у него имеется два индекса. Эти два индекса разделяются запятыми.\n\nA[2, 3]\n\n[1] 12\n\nA[2:4, 1:3]\n\n     [,1] [,2] [,3]\n[1,]    2    7   12\n[2,]    3    8   13\n[3,]    4    9   14\n\n\nПервый индекс – выбор строк, второй индекс – выбор колонок1. Результат – пересечение выбранных строк и столбцов.\n\nЕсли же мы оставляем пустое поле вместо числа, то мы выбираем все строки/колонки в зависимости от того, оставили мы поле пустым до или после запятой:\n\nA[, 1:3]\n\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n\nA[2:4, ]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    7   12   17\n[2,]    3    8   13   18\n[3,]    4    9   14   19\n\nA[, ]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\nТак же как и в случае с обычными векторами, часть матрицы можно переписать:\n\nA[2:4, 2:4] <- 100\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2  100  100  100\n[3,]    3  100  100  100\n[4,]    4  100  100  100\n[5,]    5   10   15   20\n\n\nВ принципе, это все, что нам нужно знать о матрицах. Матрицы используются в R довольно редко, особенно по сравнению, например, с MATLAB. Но вот индексировать матрицы хорошо бы уметь: это понадобится в работе с датафреймами.\n\nТо, что матрица – это просто двумерный вектор, не является метафорой: в R матрица – это по сути своей вектор с дополнительными атрибутами dim и (опционально) dimnames. Атрибуты – это свойства объектов, своего рода “метаданные”. Для всех объектов есть обязательные атрибуты типа и длины и могут быть любые необязательные атрибуты. Можно задавать свои атрибуты или удалять уже присвоенные: удаление атрибута dim у матрицы превратит ее в обычный вектор. Про атрибуты подробнее можно почитать здесь или на стр. 99-101 книги “R in a Nutshell” (Adler 2010)."
  },
  {
    "objectID": "016-complex_structures.html#sec-arrays",
    "href": "016-complex_structures.html#sec-arrays",
    "title": "4  Сложные структуры данных в R",
    "section": "4.2 Массив",
    "text": "4.2 Массив\nДва измерения – это не предел! Структура с одним типом данных внутри, но с тремя измерениями или больше, называется массивом (array). Создание массива очень похоже на создание матрицы: задаем вектор, из которого будет собран массив, и размерность массива.\n\narray_3d <- array(1:12, c(3, 2, 2))\narray_3d\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12"
  },
  {
    "objectID": "016-complex_structures.html#sec-list",
    "href": "016-complex_structures.html#sec-list",
    "title": "4  Сложные структуры данных в R",
    "section": "4.3 Список",
    "text": "4.3 Список\nТеперь представим себе вектор без ограничения на одинаковые данные внутри. И получим список (list)!\n\nsimple_list <- list(42, \"Пам пам\", TRUE)\nsimple_list\n\n[[1]]\n[1] 42\n\n[[2]]\n[1] \"Пам пам\"\n\n[[3]]\n[1] TRUE\n\n\nА это значит, что там могут содержаться самые разные данные, в том числе и другие списки, векторы и матрицы (и другие объекты, которые нам еще не знакомы)!\n\ncomplex_list <- list(c(\"Wow\", \"this\", \"list\", \"is\", \"so\", \"big\"), \"16\", simple_list, A)\ncomplex_list\n\n[[1]]\n[1] \"Wow\"  \"this\" \"list\" \"is\"   \"so\"   \"big\" \n\n[[2]]\n[1] \"16\"\n\n[[3]]\n[[3]][[1]]\n[1] 42\n\n[[3]][[2]]\n[1] \"Пам пам\"\n\n[[3]][[3]]\n[1] TRUE\n\n\n[[4]]\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2  100  100  100\n[3,]    3  100  100  100\n[4,]    4  100  100  100\n[5,]    5   10   15   20\n\n\nЕсли у нас сложный список, то есть очень классная функция str(), чтобы посмотреть, как он устроен:\n\nstr(complex_list)\n\nList of 4\n $ : chr [1:6] \"Wow\" \"this\" \"list\" \"is\" ...\n $ : chr \"16\"\n $ :List of 3\n  ..$ : num 42\n  ..$ : chr \"Пам пам\"\n  ..$ : logi TRUE\n $ : num [1:5, 1:4] 1 2 3 4 5 6 100 100 100 10 ...\n\n\n\nПредставьте, что список - это такое дерево с ветвистой структурой. А на конце этих ветвей - листья-векторы.\n\nКак и в случае с векторами мы можем давать имена элементам списка:\n\nnamed_list <- list(name = \"Veronika\", age = 26, student = FALSE)\nnamed_list\n\n$name\n[1] \"Veronika\"\n\n$age\n[1] 26\n\n$student\n[1] FALSE\n\n\nК списку можно обращаться как с помощью индексов, так и по именам. Начнем с последнего:\n\nnamed_list$age\n\n[1] 26\n\n\nА вот с индексами сложнее, и в этом очень легко запутаться. Давайте попробуем сделать так, как мы делали это раньше:\n\nnamed_list[1]\n\n$name\n[1] \"Veronika\"\n\n\nМы, по сути, получили элемент списка – просто как часть списка, т.е. как список длиной один:\n\nclass(named_list)\n\n[1] \"list\"\n\nclass(named_list[1])\n\n[1] \"list\"\n\n\nА вот чтобы добраться до самого элемента списка (и сделать с ним что-то хорошее), нам нужна не одна, а две квадратных скобочки:\n\nnamed_list[[1]]\n\n[1] \"Veronika\"\n\nclass(named_list[[1]])\n\n[1] \"character\"\n\n\nКак и в случае с вектором, к элементу списка можно обращаться по имени. Здесь тоже будет иметь значение, одинарные или двойные квадратные скобки вы используете:\n\nnamed_list[\"age\"]\n\n$age\n[1] 26\n\nnamed_list[[\"age\"]]\n\n[1] 26\n\n\nХотя последнее – практически то же самое, что и использование знака $.\n\nСписки довольно часто используются в R, но реже, чем в Python. Со многими объектами в R, такими как результаты статистических тестов, удобно работать именно как со списками – к ним все вышеописанное применимо. Кроме того, некоторые данные мы изначально получаем в виде древообразной структуры – хочешь не хочешь, а придется работать с этим как со списком. Но обычно после этого стоит как можно скорее превратить список в датафрейм."
  },
  {
    "objectID": "016-complex_structures.html#sec-df",
    "href": "016-complex_structures.html#sec-df",
    "title": "4  Сложные структуры данных в R",
    "section": "4.4 Датафрейм",
    "text": "4.4 Датафрейм\nИтак, мы перешли к самому главному. Самому-самому. Датафреймы (data.frames). Более того, сейчас станет понятно, зачем нам нужно было разбираться со всеми предыдущими темами.\nБез векторов мы не смогли бы разобраться с матрицами и списками. А без последних мы не сможем понять, что такое датафрейм.\nПредставьте себе, что мы хотим записать различную информацию о нескольких респондентах. Мы могли бы записать это в список из векторов.\n\nlist(name =  c(\"Veronika\", \"Eugeny\", \"Lena\", \"Misha\", \"Sasha\"), \n     age = c(26, 34, 23, 27, 26), \n     student = c(FALSE, FALSE, TRUE, TRUE, TRUE))\n\n$name\n[1] \"Veronika\" \"Eugeny\"   \"Lena\"     \"Misha\"    \"Sasha\"   \n\n$age\n[1] 26 34 23 27 26\n\n$student\n[1] FALSE FALSE  TRUE  TRUE  TRUE\n\n\nДатафрейм очень похож на список. Просто поменяем в команде выше list() на data.frame() и посмотрим, что изменится:\n\ndf <- data.frame(name =  c(\"Veronika\", \"Eugeny\", \"Lena\", \"Misha\", \"Sasha\"), \n                 age = c(26, 34, 23, 27, 26), \n                 student = c(FALSE, FALSE, TRUE, TRUE, TRUE))\nstr(df)\n\n'data.frame':   5 obs. of  3 variables:\n $ name   : chr  \"Veronika\" \"Eugeny\" \"Lena\" \"Misha\" ...\n $ age    : num  26 34 23 27 26\n $ student: logi  FALSE FALSE TRUE TRUE TRUE\n\ndf\n\n      name age student\n1 Veronika  26   FALSE\n2   Eugeny  34   FALSE\n3     Lena  23    TRUE\n4    Misha  27    TRUE\n5    Sasha  26    TRUE\n\n\nВообще, очень похоже на список, не правда ли? Так и есть, датафрейм – это что-то вроде проименованного списка, каждый элемент которого является atomic вектором фиксированной длины. Скорее всего, вы представляли список “горизонтально”. Если это так, то теперь “переверните” список у себя в голове на 90 градусов. Так, чтобы названия векторов оказались сверху, а элементы списка стали столбцами.\n\nПоскольку длина всех этих векторов одинаковая (обязательное условие!), то данные представляют собой табличку, похожую на матрицу. Но в отличие от матрицы, разные столбцы могут иметь разные типы данных. В нашем случае первая колонка – character, вторая колонка – numeric, третья колонка – logical. Тем не менее, обращаться с датафреймом можно и как с проименованным списком, и как с матрицей:\n\ndf$age\n\n[1] 26 34 23 27 26\n\n\nЗдесь мы сначала извлекли колонку age с помощью оператора $. Результатом этой операции является числовой вектор.\n\nКолонки датафрейма – это и есть векторы.\n\n\ndf$age[2:3]\n\n[1] 34 23\n\n\nТеперь с ним можно работать как с обычным вектором: мы вытащили кусок, выбрав индексы 2 и 3.\nИспользуя оператор $ и присваивание можно создавать новые колонки датафрейма:\n\ndf$lovesR <- TRUE #правило recycling - узнали? \ndf\n\n      name age student lovesR\n1 Veronika  26   FALSE   TRUE\n2   Eugeny  34   FALSE   TRUE\n3     Lena  23    TRUE   TRUE\n4    Misha  27    TRUE   TRUE\n5    Sasha  26    TRUE   TRUE\n\n\nНу а можно просто обращаться с помощью двух индексов через запятую, как мы это делали с матрицей:\n\ndf[3:5, 2:3]\n\n  age student\n3  23    TRUE\n4  27    TRUE\n5  26    TRUE\n\n\nКак и с матрицами, первый индекс означает строчки, а второй – столбцы.\nА еще можно использовать названия колонок внутри квадратных скобок:\n\ndf[1:2, \"age\"]\n\n[1] 26 34\n\ndf[1:2, c(\"age\", \"name\")]\n\n  age     name\n1  26 Veronika\n2  34   Eugeny\n\n\nИ здесь перед нами открываются невообразимые возможности! Узнаем, любят ли R те, кто моложе среднего возраста в группе:\n\ndf[df$age < mean(df$age), 4]\n\n[1] TRUE TRUE TRUE TRUE\n\n\nОбратите внимание, как удобно нам здесь пригодилось то, что мы научились делать с векторами (Глава 3). Сначала мы посчитали среднее значение абсолютно так же, как мы делали это с векторами:\n\nmean(df$age)\n\n[1] 27.2\n\n\nПолученное среднее поэлементно сравнили с каждым значением колонки (т.е. вектора) df$age:\n\ndf$age < mean(df$age)\n\n[1]  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nМы получили логический вектор, длина которого совпадает с длиной датафрейма. При этом TRUE стоит на тех позициях, где в соответствующей строчке в датафрейме возраст респондента больше среднего, а FALSE – в остальных случаях. Теперь этот логический вектор мы используем для выбора строк в исходном датафрейме:\n\ndf[df$age < mean(df$age), ]\n\n      name age student lovesR\n1 Veronika  26   FALSE   TRUE\n3     Lena  23    TRUE   TRUE\n4    Misha  27    TRUE   TRUE\n5    Sasha  26    TRUE   TRUE\n\n\nНаконец, тут же мы можем вытащить нужные колонки, по номеру колонки или ее названию:\n\ndf[df$age < mean(df$age), 4]\n\n[1] TRUE TRUE TRUE TRUE\n\n\nЭту же задачу можно выполнить другими способами:\n\ndf$lovesR[df$age < mean(df$age)]\n\n[1] TRUE TRUE TRUE TRUE\n\ndf[df$age < mean(df$age), 'lovesR']\n\n[1] TRUE TRUE TRUE TRUE\n\n\nВ большинстве случаев подходят сразу несколько способов – тем не менее, стоит овладеть ими всеми. Чем богаче ваш арсенал инструментов работы в R, тем легче вам обрабатывать свои данные: возможность сделать одно и то же действие добавляет вам гибкости, потому что разные способы будут более или менее подходящими в разных ситуациях.\nДатафреймы удобно просматривать в RStudio. Для это нужно написать команду View(df) или же просто нажать на названии нужной переменной из списка вверху справа (там где Environment). Тогда увидите табличку, очень похожую на Excel и тому подобные программы для работы с таблицами. Там же есть и всякие возможности для фильтрации, сортировки и поиска 2.\n\nНо, конечно, интереснее все эти вещи делать руками, т.е. с помощью написания кода.\nДатафреймы – это структура, которая будет встречаться вам чаще всего при работе с данными в R. С одной стороны, кажется, что она все равно довольно ограниченная: в каждой колонке должно быть одинаковое количество значений, внутри колонки только один тип данных. Но именно так обычно и представлены наши данные. Например, если вы загрузите результаты опроса Google Forms в виде таблицы, то каждая строчка будет респондентом, а каждая колонка – ответом на какой-то вопрос. Поэтому количество значений в каждой колонке будет одинаковым (хотя значения могут быть пропущенными), а каждая колонка – имеет свой тип. Например, год рождения – и это должна быть числовая колонка, с которой вы сможете делать все, что вы умеете делать с числовыми колонками. Например, посчитать возраст. Если в колонке с годом рождения оказалось что-то кроме чисел, то это повод для исследования данных\n\n\n\n\nAdler, Joseph. 2010. R in a nutshell: A desktop quick reference. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "020-install.html#sec-extra_pack",
    "href": "020-install.html#sec-extra_pack",
    "title": "5  Пакеты в R",
    "section": "5.1 Дополнительные пакеты",
    "text": "5.1 Дополнительные пакеты\nR — очень богатый язык с широкими возможностями. Однако очень скоро мы поймем, что этих возможностей нам не хватает. Эти возможности нам могут предоставить дополнительные пакеты (packages).\nВ большинстве случаев основным содержанием пакетов является набор дополнительных функций. Кроме функций, пакеты могут содержать наборы данных и новые структуры данных.\nОбычно пакеты посвящены решению какого-то класса задач в определенной области. Например, есть множество пакетов для создания какого-то одного типа визуализации. Еще один пример — пакет beepr, который содержит всего две функции: beep() и beep_on_error() для воспроизведения звукового сигнала. Это может быть удобно, если ваш скрипт работает долго, но вы хотите получить уведомление, когда его выполнение завершится.\nБолее крупные пакеты посвящены целому классу задач. Например, пакеты stringi и stringr посвящены работе со строками, значительно расширяя и делая более удобной работу со строковыми данными в R. Еще один пример: пакет igraph для работы с графами (сетями). Этот пакет предоставляет дополнительный класс данных igraph для хранения и работы с сетями.\nЕсть и совсем крупные пакеты, которые значительно расширяют базовый функционал R, изменяя основные принципы работы в нем. Это пакеты data.table и tidyverse. Это настолько крупные пакеты, что их даже называют отдельными диалектами R, потому что код, написанный с использованием этих пакетов, довольно сильно отличается от базового R. Кроме того, tidyverse - это не просто пакет, а целая экосистема пакетов, который взаимодополняют друг друга, но для удобства их можно устанавливать и загружать как один пакет tidyverse. Еще один пример крупной экосистемы из пакетов — это пакет mlr3 для машинного обучения, который представляет собой большой расширяемый “пакет пакетов”, где отдельные пакеты посвящены отдельным этапам и задачам машинного обучения."
  },
  {
    "objectID": "020-install.html#sec-r_built_in",
    "href": "020-install.html#sec-r_built_in",
    "title": "5  Пакеты в R",
    "section": "5.2 Встроенные пакеты R",
    "text": "5.2 Встроенные пакеты R\nВообще, даже сам R является набором из нескольких пакетов: основного base и нескольких других, таких как stats, utils, graphics. Вот их полный список:\n\nrownames(installed.packages(priority = \"base\"))\n\n [1] \"base\"      \"compiler\"  \"datasets\"  \"graphics\"  \"grDevices\" \"grid\"     \n [7] \"methods\"   \"parallel\"  \"splines\"   \"stats\"     \"stats4\"    \"tcltk\"    \n[13] \"tools\"     \"utils\"    \n\n\nЧтобы пользоваться этими пакетами ничего дополнительно делать не нужно."
  },
  {
    "objectID": "020-install.html#sec-install_cran",
    "href": "020-install.html#sec-install_cran",
    "title": "5  Пакеты в R",
    "section": "5.3 Установка пакетов с CRAN",
    "text": "5.3 Установка пакетов с CRAN\nФункция install.packages() позволяет скачивать пакеты с Comprehensive R Archive Network (CRAN). На репозитории CRAN собрано более 19000 пакетов (число постоянно меняется, как в большую, так и меньшую сторону). Каждый из этих пакетов проходит проверку перед попаданием в CRAN: он должен быть хорошо задокументирован, стабильно работать и решать какую-то задачу.\nДля примера установим пакет remotes. Это пакет для удобной установки пакетов не с CRAN и скоро нам понадобится.\n\ninstall.packages(\"remotes\")\n\nПри установке вы увидите много непонятных надписей красным шрифтом. Не пугайтесь, это нормально, происходит скачивание и установка пакетов. Скорее всего, если нигде нет слова Error, то пакет успешно установился.\nИногда установка бывает очень долгой, потому что большие пакеты склонны иметь много зависимостей: для работы какого-то пакета может понадобиться другие пакеты, а для тех пакетов - еще какие-то пакеты. Таким образом, устанавливая какой-нибудь современный пакет, вы, возможно, установите десятки других пакетов! Зато если они понадобятся сами по себе, то их уже не нужно будет устанавливать."
  },
  {
    "objectID": "020-install.html#sec-package_load",
    "href": "020-install.html#sec-package_load",
    "title": "5  Пакеты в R",
    "section": "5.4 Загрузка установленного пакета",
    "text": "5.4 Загрузка установленного пакета\nУстановить пакет с помощью install.packages() недостаточно, пакет нужно еще загрузить. Для этого есть функция library().\n\nlibrary(\"remotes\")\n\nВ отличие от install.packages(), функция library() принимает название пакета и как строчку в кавычках, и как название без кавычек.\n\nlibrary(remotes)\n\nТеперь функции, данные и классы из пакета доступны для работы."
  },
  {
    "objectID": "020-install.html#sec-from_package",
    "href": "020-install.html#sec-from_package",
    "title": "5  Пакеты в R",
    "section": "5.5 Вызов функции из пакета с помощью ::",
    "text": "5.5 Вызов функции из пакета с помощью ::\nЕсли пакетом нужно воспользоваться всего один-два раза, то имеет смысл не подключать весь пакет, а загрузить отдельную функцию из него. Для этого есть специальный оператор ::, который использует функцию (указанную справа от ::) из выбранного пакета (указанного слева от ::), не загружая пакет полностью.\nДля примера воспользуемся функцией package_deps() из только что установленного пакета remotes, которая возвращает все зависимости пакета:\n\nremotes::package_deps(\"tidyverse\")\n\nNeeds update -----------------------------\n package    installed available is_cran remote\n vctrs      0.5.2     0.6.0     TRUE    CRAN  \n tibble     3.1.8     3.2.0     TRUE    CRAN  \n rlang      1.0.6     1.1.0     TRUE    CRAN  \n openssl    2.0.5     2.0.6     TRUE    CRAN  \n httr       1.4.4     1.4.5     TRUE    CRAN  \n fastmap    1.1.0     1.1.1     TRUE    CRAN  \n cachem     1.0.6     1.0.7     TRUE    CRAN  \n broom      1.0.3     1.0.4     TRUE    CRAN  \n readr      2.1.3     2.1.4     TRUE    CRAN  \n gtable     0.3.1     0.3.2     TRUE    CRAN  \n blob       1.2.3     1.2.4     TRUE    CRAN  \n readxl     1.4.1     1.4.2     TRUE    CRAN  \n lubridate  1.9.1     1.9.2     TRUE    CRAN  \n haven      2.5.1     2.5.2     TRUE    CRAN  \n ggplot2    3.4.0     3.4.1     TRUE    CRAN  \n dtplyr     1.2.2     1.3.0     TRUE    CRAN  \n dbplyr     2.3.0     2.3.1     TRUE    CRAN  \n conflicted NA        1.2.0     TRUE    CRAN  \n tidyverse  1.3.2     2.0.0     TRUE    CRAN  \n\n\nВ дальнейшем использование оператора :: будет иногда использоваться, чтобы указать, из какого пакета взята функция.\nОператор :: полезен еще и в тех случаях, когда в разных пакетах присутствуют функции с одинаковым названием. Например, у основного пакета tidyverse, dplyr, есть функция filter(). Функция с точно таким же названием есть в базовом R в пакете stats, в котором та выполняет совершенно другую задачу. Если у вас уже загружен dplyr, то использование :: укажет на то, что вы хотите воспользоваться именно функцией filter() из пакета stats:\n\nstats::filter(1:20, rep(1,3))\n\nTime Series:\nStart = 1 \nEnd = 20 \nFrequency = 1 \n [1] NA  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 NA\n\n\nПодобные путаницы могут возникнуть, если у вас загружено много пакетов, поэтому старайтесь не загружать слишком много пакетов, а если есть функции с одинаковым названием, то обязательно используйте оператор ::. Иначе слишком велик риск загрузить пакеты не в том порядке и получить из-за этого ошибку или некорректный результат. Выгрузить ненужный пакет можно с помощью функции detach().\n\ndetach(package:remotes)"
  },
  {
    "objectID": "020-install.html#sec-install_bioc",
    "href": "020-install.html#sec-install_bioc",
    "title": "5  Пакеты в R",
    "section": "5.6 Установка пакетов c Bioconductor",
    "text": "5.6 Установка пакетов c Bioconductor\nУ биологов есть свой большой репозиторий, который является альтернативой CRAN, — Bioconductor. С него можно скачать множество специализированных пакетов для работы с биологическими данными.\nДля установки пакетов с Bioconductor сначала нужно скачать пакет BiocManager с CRAN.\n\ninstall.packages(\"BiocManager\")\n\nТеперь можно воспользоваться функцией install() из пакета BiocManager для установки пакета flowCore — пакета для анализа данных проточной цитометрии.\n\nBiocManager::install(\"flowCore\")"
  },
  {
    "objectID": "020-install.html#sec-install_github",
    "href": "020-install.html#sec-install_github",
    "title": "5  Пакеты в R",
    "section": "5.7 Установка пакетов с Github",
    "text": "5.7 Установка пакетов с Github\nНекоторых пакетов нет ни на CRAN, ни на Bioconductor. Обычно это касается пакетов, разработчики которых по каким-либо причинам решили не проходить проверки или не прошли проверки на строгие требования CRAN. Иногда бывает, что пакет был удален с CRAN (например, автор давно не занимается им) или же версия пакета на CRAN отстает от последней, а именно в ней реализованы так нужные вам функции. В некоторых случаях пакета может не быть на CRAN, потому что его разработчики активно занимаются его развитием и постоянно переделывают уже имеющийся функционал, добавляя новые возможности и удаляя старые. Это нужно делать с осторожностью, когда пакет уже выложен на CRAN, потому что если функции новой версии пакета будут работать по-другому, то это может вызвать массу проблем.\nВо всех этих случаях пакет обычно можно скачать с репозитория Github. Для этого нам понадобится уже установленный (с CRAN, разумеется) пакет remotes1.\n\nremotes::install_github(\"dracor-org/rdracor\")\n\nТеперь установленный пакет осталось загрузить, после чего им можно пользоваться.\n\nlibrary(rdracor)\ngodunov <- get_net_cooccur_igraph(corpus = \"rus\",\n                                  play = \"pushkin-boris-godunov\")\nplot(godunov)\n\n\n\n\nПакет remotes можно так же использовать для загрузки пакетов из Bioconductor:\n\nremotes::install_bioc(\"flowCore\")"
  },
  {
    "objectID": "020-install.html#sec-where_packages",
    "href": "020-install.html#sec-where_packages",
    "title": "5  Пакеты в R",
    "section": "5.8 Где искать нужные пакеты",
    "text": "5.8 Где искать нужные пакеты\nМы разобрались с тем, как устанавливать пакеты. А где же их находить?\nЭто вопрос гораздо более сложный чем может показаться. Например, можно работать в R и не знать, что существует пакет, который решает нужную для вас задачу. Или же найти такой пакет и не знать, что есть более современный пакет, который делает это еще лучше!\nЗдесь нет каких-то готовых решений. CRAN пытается создавать и поддерживать тематические списки (Task View) пакетов с описанием задач, которые они решают:\nhttps://cran.r-project.org/web/views/\nБезусловно, если вы глубоко занимаетесь какой-либо темой из списка, то стоит изучить соотвестствующий Task View, но начинать знакомство с помощью Task View достаточно тяжело.\nДругой вариант — просто погуглить, найти релевантные статьи или книги. Внимательно смотрите на дату публикации: R — очень быстро развивающийся язык, поэтому с большой вероятностью то, что было написано пять лет назад уже потеряло актуальность. Нет, работать это будет, но, скорее всего, появился более удобный и продвинутый инструмент."
  },
  {
    "objectID": "030-import_data.html#sec-wd",
    "href": "030-import_data.html#sec-wd",
    "title": "6  Импорт и экспорт данных",
    "section": "6.1 Рабочая папка и проекты RStudio",
    "text": "6.1 Рабочая папка и проекты RStudio\nДля начала скачайте файл по ссылке\nОн, скорее всего, появился у Вас в папке “Загрузки”. Если мы будем просто пытаться прочитать этот файл (например, с помощью read.csv() — мы к этой функцией очень скоро перейдем), указав его имя и разрешение, то наткнемся на такую ошибку:\n\nread.csv(\"heroes_information.csv\")\n\nWarning in file(file, \"rt\"): cannot open file 'heroes_information.csv': No such\nfile or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nЭто означает, что R не может найти нужный файл. Вообще-то мы даже не сказали, где искать. Нам нужно как-то совместить место, где R ищет загружаемые файлы и сами файлы. Для этого есть несколько способов.\n\nМагомет идет к горе: перемещение файлов в рабочую папку.\n\nДля этого нужно узнать, какая папка является рабочей с помощью функции getwd() (без аргументов), найти эту папку в проводнике и переместить туда файл. После этого можно использовать просто название файла с разрешением:\n\nheroes <- read.csv(\"heroes_information.csv\")\n\nКроме того, путь к рабочей папке можно увидеть в RStudio во вкладке с консолью, в самой верхней части (прямо под надписью “Console”):\n\n\nГора идет к Магомету: изменение рабочей папки.\n\nМожно просто сменить рабочую папку с помощью setwd() на ту, где сейчас лежит файл, прописав путь до этой папки. Теперь файл находится в рабочей папке:\n\nheroes <- read.csv(\"heroes_information.csv\")\n\nЭтот вариант использовать не рекомендуется! Как минимум, это сразу делает невозможным запустить скрипт на другом компьютере. Ну а если все-таки вдруг повезет и получится, то ваш коллега будет очень недоволен, что ваш скрипт изменяет рабочую директорию.\n\nГора находит Магомета по месту прописки: указание полного пути файла.\n\n\nheroes <- read.csv(\"/Users/Username/Some_Folder/heroes_information.csv\")\n\nЭтот вариант страдает теми же проблемами, что и предыдущий, поэтому тоже не рекомендуется!\n\nДля пользователей Windows есть дополнительная сложность: знак / является особым знаком для R, поэтому вместо него нужно использовать двойной //.\n\n\nМагомет использует кнопочный интерфейс: Import Dataset.\n\nВо вкладке Environment справа в окне RStudio есть кнопка “Import Dataset”. Возможно, у Вас возникло непреодолимое желание отдохнуть от написания кода и понажимать кнопочки — сопротивляйтесь этому всеми силами, но не вините себя, если не сдержитесь.\n\nГора находит Магомета в интернете.\n\nМногие функции в R, предназначенные для чтения файлов, могут прочитать файл не только на Вашем компьютере, но и сразу из интернета. Для этого просто используйте ссылку вместо пути:\n\nheroes <- read.csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\")\n\n\nКаждый Магомет получает по своей горе: использование проектов в RStudio.\n\nНа первый взгляд это кажется чем-то очень сложным, но это не так. Это очень просто и ОЧЕНЬ удобно. При создании проекта создается отдельная папка, где у вас лежат данные, хранятся скрипты, вспомогательные файлы и отчеты. Кроме папки создается файл формата .Rproj, в котором хранятся настройки проекта. Если нужно вернуться к другому проекту — просто открываете другой проект, с другими файлами и скриптами. Можно даже иметь открытыми несколько окон RStudio таким образом. Это еще помогает не пересекаться переменным из разных проектов — а то, знаете, использование двух переменных data в разных скриптах чревато ошибками. Поэтому очень удобным решением будет выделение отдельного проекта под этот курс.\n\nПри закрытии проекта все переменные по умолчанию тоже будут сохраняться, а при открытии — восстанавливаться (а вот пакеты все равно придется подгружать заново). Это очень удобно, хотя некоторые рекомендуют от этого отказаться. Это можно сделать во вкладке Tool - Global Options..."
  },
  {
    "objectID": "030-import_data.html#sec-project_workflow",
    "href": "030-import_data.html#sec-project_workflow",
    "title": "6  Импорт и экспорт данных",
    "section": "6.2 Организация проектов",
    "text": "6.2 Организация проектов\nДаже если не пользоваться проектами RStudio (но я настоятельно рекомендую, это очень удобно), то все равно имеет смысл разделять различные свои проекты по отдельным папкам. Для небольших проектов этого уже может быть достаточно, но я рекомендую делать немного более сложную структуру папок внутри проекта. Например, такую:\n.\n└── my_project \n    ├── R \n    ├── data\n    │   ├── raw\n    │   ├── temp\n    │   └── processed\n    ├── figures\n    ├── main_script.R \n    ├── my_project.Rproj\n    ├── output\n    └── README.txt\nВ основной папке содержится автоматически созданный RStudio файл .Rproj, основной скрипт с формат .R (или же это может быть .Rmd файл — см. @ref(rmd)). Вспомогательные скрипты (например, с функциями) могут храниться в папке R. Если скриптов несколько, то их порядок стоит обозначить числами:\n.\n├── 01_first_script_preposcessing.R\n├── 02_second_script_statistics.R\n└── 03_third_script_figures.R \nДанные стоит держать в отдельной папке, причем в некоторых ситуациях вы захотите создать отдельные подпапки, например, отдельные подпапки для данных на входе, временных файлов и данных на выходе. Результаты работы, например, отчеты, сгенерированные с помощью R Markdown (см. @ref(rmd)). Туда же можно поместить папку с графиками или же можно поместить эту папку в корневую директорию.\nЭто лишь пример структуры организации проектов, детали могут различаться, но такая структура позволит не заблудиться в собственных файлах, если тех накопилось достаточно много. Кроме того, другому человеку в такой структуре проекта будет разобраться значительно проще\nПри создании папок внутри основного проекта важно помнить о том, что теперь ваши файлы больше нельзя найти в вашей корневой директории: нужно искать их в соответствующих папках. Это значит, что путь до файла теперь будет не \"heroes_information.csv\", а \"data/heroes_information.csv\" или даже \"data/raw/heroes_information.csv\".\nПакет {here} позволяет удобно работать с путями на любых операционных системах, создавая путь в зависимости от вашей корневой директории проекта.\n\nhere::here(\"data\", \"heroes_information.csv\")\n\n[1] \"/Users/ivan/R/tidy_stats/data/heroes_information.csv\"\n\n\nСозданный путь можно использовать для чтения файлов:\n\nheroes <- read.csv(here::here(\"data\", \"heroes_information.csv\"))\n\nСами скрипты тоже лучше разделять на смысловые части. Для этого есть горячие клавиши Cmd + Shift + R. Это сочетание клавиш выведет окно, в котором вам нужно вписать название, после чего появится вот такой аккуратный комментарий:\n\n# Meaningful part of the script -------------------------------------------\n\nРазделенный на такие части скрипт (да еще и с подробными комментариями) гораздо удобнее читать!\n\n6.2.1 Табличные данные: текстовые и бинарные данные\nКак Вы уже поняли, импортирование данных - одна из самых муторных и неприятных вещей в R. Если у Вас получится с этим справится, то все остальное - ерунда. Мы уже разобрались с первой частью этого процесса - нахождением файла с данными, осталось научиться их читать.\nЗдесь стоит сделать небольшую ремарку. Довольно часто данные представляют собой табличку. Или же их можно свести к табличке. Такая табличка, как мы уже выяснили, удобно репрезентируется в виде датафрейма. Но как эти данные хранятся на компьютере? Есть два варианта: в бинарном и в текстовом файле.\nТекстовый файл означает, что такой файл можно открыть в программе “Блокнот” или аналоге (например, TextEdit на macOS) и увидеть напечатанный текст: скрипт, роман или упорядоченный набор цифр и букв. Нас сейчас интересует именно последний случай. Таблица может быть представлена как текст: отдельные строчки в файле будут разделять разные строчки таблицы, а какой-нибудь знак-разделитель отделять колонки друг от друга.\nДля чтения данных из текстового файла есть довольно удобная функция read.table(). Почитайте хэлп по ней и ужаснитесь: столько разных параметров на входе! Но там же вы увидете функции read.csv(), read.csv2() и некоторые другие — по сути, это тот же read.table(), но с другими параметрами по умолчанию, соответствующие формату файла, который мы загружаем. В данном случае используется формат .csv, что означает “Comma Separated Values” (Значения, Разделенные Запятыми). Формат .csv — это самый известный способ хранения табличных данных в файде на сегодняшний день. Файлы с расширением .csv можно легко открыть в любой программе, работающей с таблицами, в том числе Microsoft Excel и его аналогах.\nФайл с расширением .csv — это просто текстовый файл, в котором “закодирована” таблица: разные строчки разделяют разные строчки таблицы, а столбцы отделяются запятыми (отсюда и название). Вы можете вручную создать такие файлы в Блокноте и сохранять их с форматом .csv - и такая табличка будет нормально открываться в Microsoft Excel и других программах для работы с таблицами. Можете попробовать это сделать самостоятельно!\nКак говорилось ранее, в качестве разделителя ячеек по горизонтали — то есть разделителя между столбцами — используется запятая. С этим связана одна проблема: в некоторых странах (в т.ч. и России) принято использовать запятую для разделения дробной части числа, а не точку, как это делается в большинстве стран мира. Поэтому есть альтернативный вариант формата .csv, где значения разделены точкой с запятой (;), а дробные значения - запятой (,). В этом и различие функций read.csv() и read.csv2() — первая функция предназначена для “международного” формата, вторая - для (условно) “российского”. Оба варианта формата имеют расширение .csv, поэтому заранее понять какой именно будет вариант довольно сложно, приходится либо пробовать оба, либо заранее открывать файл в текстовом редакторе.\nВ первой строчке обычно содержатся названия столбцов - и это чертовски удобно, функции read.csv() и read.csv2() по умолчанию считают первую строчку именно как название для колонок.\nКроме .csv формата есть и другие варианты хранения таблиц в виде текста. Например, .tsv — тоже самое, что и .csv, но разделитель - знак табуляции. Для чтения таких файлов есть функция read.delim() и read.delim2(). Впрочем, даже если бы ее и не было, можно было бы просто подобрать нужные параметры для функции read.table(). Есть даже функции, которые пытаются сами “угадать” нужные параметры для чтения — часто они справляются с этим довольно удачно. Но не всегда. Поэтому стоит научиться справляться с любого рода данными на входе.\nИтак, прочитаем наш файл. Для этого используем только параметр file =, который идет первым:\n\nheroes <- read.csv(\"data/heroes_information.csv\")\n\n\nВ более старых версиях R еще следовало указывать stringsAsFactors = FALSE. Параметр stringsAsFactors = задает то, как будут прочитаны строковые значения - как уже знакомые нам строки или как факторы. По сути, факторы - это примерно то же самое, что и character, но закодированные числами. Когда-то это было придумано для экономии используемых времени и памяти, сейчас же обычно становится просто лишней морокой. Но некоторые функции требуют именно character, некоторые factor, в большинстве случаев это без разницы. Но иногда непонимание может привести к дурацким ошибкам. В данном случае мы просто пока обойдемся без факторов. Если у вас версия R выше 4.0.0, то stringsAsFactors = будет FALSE по умолчанию.\n\nМожете проверить с помощью View(heroes): все работает! Если же вылезает какая-то странная ерунда или же просто ошибка - попробуйте другие функции (read.table(), read.delim()) и покопаться с параметрами. Для этого читайте Help."
  },
  {
    "objectID": "030-import_data.html#sec-check_imported",
    "href": "030-import_data.html#sec-check_imported",
    "title": "6  Импорт и экспорт данных",
    "section": "6.3 Проверка импортированных данных",
    "text": "6.3 Проверка импортированных данных\nПри импорте данных обратите внимания на предупреждения (если таковые появляются), в большинстве случаев они указывают на то, что данные импортированы некорректно.\nПроверим, что все прочиталось нормально с помощью уже известной нам функции str():\n\nstr(heroes)\n\n'data.frame':   734 obs. of  11 variables:\n $ X         : int  0 1 2 3 4 5 6 7 8 9 ...\n $ name      : chr  \"A-Bomb\" \"Abe Sapien\" \"Abin Sur\" \"Abomination\" ...\n $ Gender    : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Eye.color : chr  \"yellow\" \"blue\" \"blue\" \"green\" ...\n $ Race      : chr  \"Human\" \"Icthyo Sapien\" \"Ungaran\" \"Human / Radiation\" ...\n $ Hair.color: chr  \"No Hair\" \"No Hair\" \"No Hair\" \"No Hair\" ...\n $ Height    : num  203 191 185 203 -99 193 -99 185 173 178 ...\n $ Publisher : chr  \"Marvel Comics\" \"Dark Horse Comics\" \"DC Comics\" \"Marvel Comics\" ...\n $ Skin.color: chr  \"-\" \"blue\" \"red\" \"-\" ...\n $ Alignment : chr  \"good\" \"good\" \"good\" \"bad\" ...\n $ Weight    : int  441 65 90 441 -99 122 -99 88 61 81 ...\n\n\n\nВсегда проверяйте данные на входе и никогда не верьте на слово, если вам говорят, что данные вычищенные и не содержат никаких ошибок.\n\nНа что нужно обращать внимание?\n\nПрочитаны ли пропущенные значения как NA. По умолчанию пропущенные значения обозначаются пропущенной строчкой или “NA”, но встречаются самые разнообразные варианты. Возможные варианты кодирования пропущенных значений можно задать в параметре na.strings = функции read.table() и ее вариантов. В нашем датасете как раз такая ситуация, где нужно самостоятельно задавать, какие значения будут прочитаны как NA.\n\nheroes <- read.csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\", \n                   na.strings = c(\"NA\", \"-\", \"-99\"))\n\nПрочитаны ли те столбики, которые должны быть числовыми, как int или num. Если в колонке содержатся числа, а написано chr (= \"character\") или Factor (в случае если stringsAsFactors = TRUE), то, скорее всего, одна из строчек содержит в себе нечисловые знаки, которые не были прочитаны как NA.\nСтранные названия колонок. Это может случиться по самым разным причинам, но в таких случаях стоит открывать файл в другой программе и смотреть первые строчки. Например, может оказаться, что первые несколько строчек — пустые или что первая строчка не содержит название столбцов (тогда для параметра header = нужно поставить FALSE)\nВместо строковых данных у вас кракозябры. Это означает проблемы с кодировкой. В первую очередь попробуйте выставить значение \"UTF-8\" для параметра encoding = в функции для чтения файла:\n\n\nheroes <- read.csv(\"data/heroes_information.csv\",\n                   encoding = \"UTF-8\")\n\nВ случае если это не помогает, попробуйте разобрать, что это за кодировка.\n\nВсе прочиталось как одна колонка. В этом случае, скорее всего, неправильно подобран разделить колонок — параметр sep =. Откройте файл в текстовом редакторе, чтобы понять какой нужно использовать.\nВ отдельных строчках все прочиталось как одна колонка, а в остальных нормально. Скорее всего, в файле есть значения типа \\ или \", которые в функциях read.csv(), read.delim(), read.csv2(), read.delim2() читаются как символы для закавычивания значений. Это может понадобиться, если у вас в таблице есть строковые значения со знаками , или ;, которые могут восприниматься как разделитель столбцов.\nПоявились какие-то новые числовые колонки. Возможно неправильно поставлен разделитель дробной части. Обычно это либо . (read.table(), read.csv(), read.delim()), либо , (read.csv2(), read.delim2()).\n\nКонкретно в нашем случае все прочиталось хорошо с помощью функции read.csv(), но в строковых переменных есть много прочерков, которые обозначают отсутствие информации по данному параметру супергероя, т.е. пропущенное значение. А вот с числовыми значениями все не так просто: для всех супергероев прописано какое-то число, но во многих случаях это -99. Очевидно, отрицательного роста и массы не бывает, это просто обозначение пропущенных значений (такое часто используется). Таким образом, чтобы адекватно прочитать файл, нам нужно поменять параметр na.strings = функции read.csv():\n\nheroes <- read.csv(\"data/heroes_information.csv\", \n                   na.strings = c(\"NA\", \"-\", \"-99\"))"
  },
  {
    "objectID": "030-import_data.html#sec-export_data",
    "href": "030-import_data.html#sec-export_data",
    "title": "6  Импорт и экспорт данных",
    "section": "6.4 Экспорт данных",
    "text": "6.4 Экспорт данных\nПредставим, что вы хотите сохранить табличку с данными про супергероев из вселенной DC в виде отдельного файла .csv.\n\ndc <- heroes[heroes$Publisher == \"DC Comics\",]\n\nФункция write.csv() позволит записать датафрейм в файл формата .csv:\n\nwrite.csv(dc, \"data/dc_heroes_information.csv\")\n\nОбычно названия строк не используются, и их лучше не записывать, поставив для row.names = значение FALSE:\n\nwrite.csv(dc, \"data/dc_heroes_information.csv\", row.names = FALSE)\n\nПо аналогии с read.csv2(), write.csv2() позволит записать файлы формата .csv с разделителем ;.\n\nwrite.csv2(dc, \"data/dc_heroes_information.csv\", row.names = FALSE)"
  },
  {
    "objectID": "030-import_data.html#sec-binary",
    "href": "030-import_data.html#sec-binary",
    "title": "6  Импорт и экспорт данных",
    "section": "6.5 Импорт таблиц в бинарном формате: таблицы Excel, SPSS",
    "text": "6.5 Импорт таблиц в бинарном формате: таблицы Excel, SPSS\nТем не менее, далеко не всегда таблицы представлены в виде текстового файла. Самый распространенный пример таблицы в бинарном виде — родные форматы Microsoft Excel. Если Вы попробуете открыть .xlsx файл в Блокноте, то увидите кракозябры. Это делает работу с этим файлами гораздо менее удобной, поэтому стоит избегать экселевских форматов и стараться все сохранять в .csv.\nТакие файлы не получится прочитать при помощи базового инструментария R. Тем не менее, для чтения таких файлов есть много дополнительных пакетов:\n\nфайлы Microsoft Excel: лучше всего справляется пакет readxl (является частью расширенного tidyverse), у него есть много альтернатив (xlsx, openxlsx).\nфайлы SPSS, SAS, Stata: существуют два основных пакета — haven (часть расширенного tidyverse) и foreign.\n\nЧто такое пакеты и как их устанавливать мы изучим очень скоро."
  },
  {
    "objectID": "030-import_data.html#import_googlesheets",
    "href": "030-import_data.html#import_googlesheets",
    "title": "6  Импорт и экспорт данных",
    "section": "6.6 Импорт данных из Google Sheets",
    "text": "6.6 Импорт данных из Google Sheets\nВсе чаще “кнопочная” работа с данными переезжает из Excel в облачный Google Sheets, который обладает схожим интерфейсом и функционалом, но позволяет удобно работать нескольким пользователям одновременно.\nОттуда данные можно легко выгрузить в нужном формате. Конечно, и в .csv тоже. Но было бы удобно загружать данные из Google Sheets напрямую, по ссылке. И это вполне возможно и даже не очень трудно! Лучший пакет для этого – googlesheets4.\n\ninstall.packages(\"googlesheets\")\n\nОсновная функция – read_sheet(), в ней нужно прописать ссылку, которую можно получить в “Настройках доступа” (или которую вам уже прислали).\n\nheroes_form_gsh <- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1JnkftX8H2n383V6wFBTKBqiMmj79hravsYcSeClSeo8/edit?usp=sharing\")\n\nПосле этого в консоли нужно будет выбрать Google-аккаунт:\n\nВыбираете (в данном случае у меня только один аккаунт, поэтому пишу 1 и жму Enter).\nПосле этого откроется окно в веб-браузере, в котором Google будет спрашивать, доверяете ли вы R и готовы ли дать ему доступ к чтению таблицы (разумеется, отвечаем, что да). Это нужно будет сделать всего один раз, так что в дальнейшем нажимать в веб-браузере ничего будет не нужно.\nПосле этого таблица загрузится."
  },
  {
    "objectID": "030-import_data.html#sec-fastread",
    "href": "030-import_data.html#sec-fastread",
    "title": "6  Импорт и экспорт данных",
    "section": "6.7 Быстрый импорт данных",
    "text": "6.7 Быстрый импорт данных\nЧтение табличных данных обычно происходит очень быстро. По крайней мере, до тех пор пока ваши данные не содержат очень много значений. Если вы попробуете прочитать с помощью read.csv() таблицу с миллионами строчками, то заметите, что это происходит довольно медленно. Впрочем, эта проблема эффективно решается дополнительными пакетами.\n\nПакет readr (часть базового tidyverse) предлагает функции, очень похожие на стандартные read.csv(), read.csv2() и тому подобные, только в названиях используется нижнее подчеркивание: read_csv() и read_csv2(). Они быстрее и немного удобнее, особенно если вы работаете в tidyverse.\n\n\nreadr::read_csv(\"data/heroes_information.csv\",\n         na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\nПакет vroom - это часть расширенного tidyverse. Это такая альтернатива readr из того же tidyverse, но еще быстрее (отсюда и название).\n\n\nvroom::vroom(\"data/heroes_information.csv\")\n\nNew names:\nRows: 734 Columns: 11\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A... dbl\n(3): ...1, Height, Weight\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… -       good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… -       bad    \n 5     4 Abraxas     Male   blue    Cosm… Black      -99 Marvel… -       bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… -       bad    \n 7     6 Adam Monroe Male   blue    -     Blond      -99 NBC - … -       good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… -       good   \n 9     8 Agent 13    Female blue    -     Blond      173 Marvel… -       good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… -       good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\nПакет data.table - это не просто пакет, а целый фреймворк для работы с R, основной конкурент tidyverse. Одна из основных фишек data.table - быстрота работы. Это касается не только процессинга данных, но и их загрузки и записи. Поэтому некоторые используют функции data.table для чтения и записи данных в отдельности от всего остального пакета - они даже и называются соответствующе: fread() и fwrite(), где f означет fast2.\n\n\ndata.table::fread(\"data/heroes_information.csv\")\n\n      V1            name Gender Eye color              Race       Hair color\n  1:   0          A-Bomb   Male    yellow             Human          No Hair\n  2:   1      Abe Sapien   Male      blue     Icthyo Sapien          No Hair\n  3:   2        Abin Sur   Male      blue           Ungaran          No Hair\n  4:   3     Abomination   Male     green Human / Radiation          No Hair\n  5:   4         Abraxas   Male      blue     Cosmic Entity            Black\n ---                                                                        \n730: 729 Yellowjacket II Female      blue             Human Strawberry Blond\n731: 730            Ymir   Male     white       Frost Giant          No Hair\n732: 731            Yoda   Male     brown    Yoda's species            White\n733: 732         Zatanna Female      blue             Human            Black\n734: 733            Zoom   Male       red                 -            Brown\n     Height         Publisher Skin color Alignment Weight\n  1:  203.0     Marvel Comics          -      good    441\n  2:  191.0 Dark Horse Comics       blue      good     65\n  3:  185.0         DC Comics        red      good     90\n  4:  203.0     Marvel Comics          -       bad    441\n  5:  -99.0     Marvel Comics          -       bad    -99\n ---                                                     \n730:  165.0     Marvel Comics          -      good     52\n731:  304.8     Marvel Comics      white      good    -99\n732:   66.0      George Lucas      green      good     17\n733:  170.0         DC Comics          -      good     57\n734:  185.0         DC Comics          -       bad     81\n\n\nЧем же пользоваться среди всего этого многообразия? Бенчмарки3 показывают, что быстрее всех vroom и data.table. Если же у вас нет задачи ускорить работу кода на несколько миллисекунд или прочитать датасет на много миллионов строк, то стандартного read.csv() (если вы работаете в базовом R) и readr::read_csv() (если вы работаете в tidyverse) должно быть достаточно.\nВсе перечисленные пакеты повзоляют не только быстро импортировать данные, но и быстро (и удобно!) экспортировать их:\n\nreadr::write_csv(dc, \"data/dc_heroes_information.csv\")\nreadr::write_excel_csv(dc, \"data/dc_heroes_information.csv\") #Если в Excel возникают проблемы с кодировками при открытии созданного .csv файла, то эта функция решает эти проблемы\nvroom::vroom_write(dc, \"data/dc_heroes_information.csv\", delim = \",\")\ndata.table::fwrite(dc, \"data/dc_heroes_information.csv\")\n\nВ плане скорости записи файлов соотношение сил примерно такое же, как и для чтения: vroom и data.table обгоняют всех, затем идет readr, и только после него - базовые функции R."
  },
  {
    "objectID": "040-if_for.html#sec-sec-if",
    "href": "040-if_for.html#sec-sec-if",
    "title": "7  Условные конструкции и циклы",
    "section": "7.1 Выражения if, else, else if",
    "text": "7.1 Выражения if, else, else if\nСтандратная часть практически любого языка программирования — условные конструкции. R не исключение. Однако и здесь есть свои особенности. Начнем с самого простого варианта с одним условием. Выглядеть условная конcтрукция будет вот так:\nif (условие) выражение\nВот так это будет работать на практике:\n\nnumber <- 1\nif (number > 0) \"Положительное число\"\n\n[1] \"Положительное число\"\n\n\nЕсли выражение (expression) содержит больше одной строчки, то они объединяются фигурными скобками. Впрочем, использовать их можно, даже если строчка всего в выражении всего одна.\n\nnumber <- 1\nif (number > 0) {\n  \"Положительное число\"\n}\n\n[1] \"Положительное число\"\n\n\nВ рассмотренной нами конструкции происходит проверка на условие. Если условие верно1, то происходит то, что записано в последующем выражении. Если же условие неверно2, то ничего не происходит.\nОператор else позволяет задавать действие на все остальные случаи:\nif (условие) выражение else выражение\nРаботает это так:\n\nnumber <- -3\nif (number > 0) {\n  \"Положительное число\"\n} else {\n  \"Отрицательное число или ноль\"\n}\n\n[1] \"Отрицательное число или ноль\"\n\n\nИногда нам нужна последовательная проверка на несколько условий. Для этого есть оператор else if. Вот как выглядит ее применение:\n\nnumber <- 0\nif (number > 0) {\n  \"Положительное число\"\n} else if (number < 0){\n  \"Отрицательное число\"\n} else {\n  \"Ноль\"\n}\n\n[1] \"Ноль\"\n\n\nКак мы помним, R — язык, в котором векторизация играет большое значение. Но вот незадача — условные конструкции не векторизованы в R! Давайте попробуем применить эти конструкции для вектора значений и посмотрим, что получится.\n\nnumbers <- -2:2\nif (numbers > 0) {\n  \"Положительное число\"\n} else if (number < 0){\n  \"Отрицательное число\"\n} else {\n  \"Ноль\"\n}\n\nError in if (numbers > 0) {: the condition has length > 1\n\n\nОшибка! Однако если у вас более старая версия R (до 4.2.0, апрель 2022), то вместо ошибки будет учитываться только первое значение вектора условий: остальные будут игнорироваться, при этом будет выводиться предупреждение. Как же посчитать для всего вектора сразу?"
  },
  {
    "objectID": "040-if_for.html#sec-for",
    "href": "040-if_for.html#sec-for",
    "title": "7  Условные конструкции и циклы",
    "section": "7.2 Циклы for",
    "text": "7.2 Циклы for\nВо-первых, можно использовать for. Синтаксис у for похож на синтаксис условных конструкций.\nfor(переменная in последовательность) выражение\nТеперь мы можем объединить условные конструкции и for. Немножко монструозно, но это работает:\n\nfor (i in numbers) {\n  if (i > 0) {\n    print(\"Положительное число\")\n  } else if (i < 0) {\n    print(\"Отрицательное число\")\n  } else {\n    print(\"Ноль\")\n  }\n}\n\n[1] \"Отрицательное число\"\n[1] \"Отрицательное число\"\n[1] \"Ноль\"\n[1] \"Положительное число\"\n[1] \"Положительное число\"\n\n\n\nЧтобы выводить в консоль результат вычислений внутри for, нужно использовать print().\n\nЗдесь стоит отметить, что for используется в R относительно редко. В подавляющем числе ситуаций использование for можно избежать. Обычно мы работаем в R с векторами или датафреймами, которые представляют собой множество относительно независимых наблюдений. Если мы хотим провести какие-нибудь операции с этими наблюдениями, то они обычно могут быть выполнены параллельно. Скажем, вы хотите для каждого испытуемого пересчитать его массу из фунтов в килограммы. Этот пересчет осуществляется по одинаковой формуле для каждого испытуемого. Эта формула не изменится из-за того, что какой-то испытуемый слишком большой или слишком маленький - для следующего испытуемого формула будет прежняя. Если Вы встречаете подобную задачу (где функцию можно применить независимо для всех значений), то без цикла for вполне можно обойтись.\nДаже во многих случаях, где расчеты для одной строчки зависят от расчетов предыдущих строчек, можно обойтись без for векторизованными функциями, например, cumsum() для подсчета кумулятивной суммы.\n\ncumsum(1:10)\n\n [1]  1  3  6 10 15 21 28 36 45 55\n\n\nЕсли же нет подходящей векторизованной функции, то можно воспользоваться семейством функций apply() (см. Глава 8.5).\n\nПосле этих объяснений кому-то может показаться странным, что я вообще упоминаю про эти циклы. Но для кого-то циклы for настолько привычны, что их полное отсутствие в курсе может показаться еще более странным. Поэтому лучше от меня, чем на улице.\n\nЗачем вообще избегать конструкций for? Некоторые говорят, что они слишком медленные, и частично это верно, если мы сравниваем с векторизованными функциями, которые написаны на более низкоуровневых языках. Но в большинстве случаев низкая скорость for связана с неправильным использованием этой конструкции. Например, стоит избегать ситуации, когда на каждой итерации for какой-то объект (вектор, список, что угодно) изменяется в размере. Лучше будет создать заранее объект нужного размера, который затем будет наполняться значениями:\n\nnumbers_descriptions <- character(length(numbers)) #создаем строковый вектор с такой же длиной, как и исходный вектор\nfor (i in 1:length(numbers)) {\n  if (numbers[i] > 0) {\n    numbers_descriptions[i] <- \"Положительное число\"\n  } else if (numbers[i] < 0) {\n    numbers_descriptions[i] <- \"Отрицательное число\"\n  } else {\n    numbers_descriptions[i] <- \"Ноль\"\n  }\n}\nnumbers_descriptions\n\n[1] \"Отрицательное число\" \"Отрицательное число\" \"Ноль\"               \n[4] \"Положительное число\" \"Положительное число\"\n\n\nВ общем, при правильном обращении с for особых проблем со скоростью не будет. Но все равно это будет громоздкая конструкция, в которой легко ошибиться, и которую, скорее всего, можно заменить одной короткой строчкой. Кроме того, без конструкции for код обычно легко превратить в набор функций, последовательно применяющихся к данным, что мы будем по максимуму использовать, работая в tidyverse и применяя пайпы (см. Глава 10.4)."
  },
  {
    "objectID": "040-if_for.html#sec-ifelse",
    "href": "040-if_for.html#sec-ifelse",
    "title": "7  Условные конструкции и циклы",
    "section": "7.3 Векторизованные условные конструкции: функции ifelse() и dplyr::case_when()",
    "text": "7.3 Векторизованные условные конструкции: функции ifelse() и dplyr::case_when()\nИз-за того, что конструкция if else не векторизованная, она редко используется непосредственно в операциях с данными, обычно она используется при написании функций (Глава 8.1) и разработке пакетов.\nАльтернативой сочетанию условных конструкций и циклов for является использование встроенной функции ifelse(). Функция ifelse() принимает три аргумента - 1) условие (т.е. просто логический вектор, состоящий из TRUE и FALSE), 2) что выдавать в случае TRUE, 3) что выдавать в случае FALSE. На выходе получается вектор такой же длины, как и изначальный логический вектор (условие). Это очень похоже на ЕСЛИ() в Excel.\n\nifelse(numbers > 0, \"Положительное число\", \"Отрицательное число или ноль\")\n\n[1] \"Отрицательное число или ноль\" \"Отрицательное число или ноль\"\n[3] \"Отрицательное число или ноль\" \"Положительное число\"         \n[5] \"Положительное число\"         \n\n\n\nПериодически я встречаю у студентов строчку вроде такой: ifelse(условие, TRUE, FALSE). Эта конструкция избыточна, т.к. получается, что логический вектор из TRUE и FALSE превращается в абсолютно такой же вектор из TRUE и FALSE на тех же самых местах. Выходит, что ничего не меняется!\n\n\n\n\n\n\n\nПредупреждение\n\n\n\nNA в условии в ifelse() возвращает NA.\n\n\nПакеты {dplyr} и {data.table} предоставляют более быстрые и более строгие альтернативы для базовой функции ifelse() с аналогичным синтаксисом:\n\ndplyr::if_else(numbers > 0, \"Положительное число\", \"Отрицательное число или ноль\")\n\n[1] \"Отрицательное число или ноль\" \"Отрицательное число или ноль\"\n[3] \"Отрицательное число или ноль\" \"Положительное число\"         \n[5] \"Положительное число\"         \n\ndata.table::fifelse(numbers > 0, \"Положительное число\", \"Отрицательное число или ноль\")\n\n[1] \"Отрицательное число или ноль\" \"Отрицательное число или ноль\"\n[3] \"Отрицательное число или ноль\" \"Положительное число\"         \n[5] \"Положительное число\"         \n\n\nЕсли вы пользуетесь одним из этих пакетов (о них пойдет речь далее — см. Глава 10.1 ), то я советую пользоваться соотвествующей функцией вместо базового ifelse().\nОбе функции будут избегать скрытого приведения типов (см. Глава 3.2) и намеренно выдавать ошибку при использовании разных типов данных в параметрах yes = и no =3. Помните, что NA по умолчанию — это логический тип данных, поэтому в этих функциях нужно использовать NA соответствующего типа NA_character_, NA_integer_, NA_real_, NA_complex_ (см. Глава 3.7).\nУ ifelse() тоже есть недостаток: он не может включать в себя дополнительных условий по типу else if. В простых ситуациях можно вставлять ifelse() внутри ifelse():\n\nifelse(numbers > 0,\n       \"Положительное число\",\n       ifelse(number < 0, \"Отрицательное число\", \"Ноль\"))\n\n[1] \"Ноль\"                \"Ноль\"                \"Ноль\"               \n[4] \"Положительное число\" \"Положительное число\"\n\n\nДостаточно симпатичное решение есть в пакете dplyr — функция case_when(), которая работает с использованием формулы:\n\ndplyr::case_when(\n  numbers > 0 ~ \"Положительное число\",\n  numbers < 0 ~ \"Отрицательное число\",\n  numbers == 0 ~ \"Ноль\")\n\n[1] \"Отрицательное число\" \"Отрицательное число\" \"Ноль\"               \n[4] \"Положительное число\" \"Положительное число\"\n\n\nФункция case_when() по той же логике, что и if else конструкция: сначала идет проверка на первое условие (как первое if в конструкции if else). Если она проходит (то есть в условие получается TRUE), то это значение возвращается, а остальные условия не проверяются. Если же первое условие не выполняется, то идет проверка на следующее условие (аналог else if). Если же и оно не выполняется, то идет проверка на следующее (следующее else if), пока проверка не пройдет до последнего условия. Можно поставить значение по умолчанию с помощью параметра .default =, которое будет возвращаться, если все проверки выдали FALSE.\n\nheroes <- read.csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\", na.strings = c(\"NA\", \"-\", \"-99\"))\n\nheroes$weight_group <- dplyr::case_when(\n  heroes$Weight > 200 ~ \"overweight\", # \"if\"\n  heroes$Weight > 120 ~ \"somewhat overweight\", # \"else if\"\n  heroes$Weight < 50 ~ \"underweight\", # next \"else if\"\n  .default = \"typical weight\" # final \"else\" \n) \n\n\n\n\n\n\n\nОсторожность\n\n\n\nБудьте внимательны с запятыми!\n\n\nВажный момент: если ifelse() возвращает NA на NA в условии, что обычно нас устраивает (у нас нет данных, что у нас на входе, следовательно, не знаем, что на выходе), то case_when() такого не делает. NA в условии считается как FALSE, поэтому нужно дополнительно обрабатывать условие для него. Чтобы на место NA поставить NA, нужно записать вот так:\n\nheroes$weight_group <- dplyr::case_when(\n  heroes$Weight > 200 ~ \"overweight\", # \"if\"\n  heroes$Weight > 120 ~ \"somewhat overweight\", # \"else if\"\n  heroes$Weight < 50 ~ \"underweight\", # next \"else if\"\n  is.na(heroes$Weight) ~ NA, # one more \"else if\", maps NA to NA\n  .default = \"typical weight\" # final \"else\" \n  ) # final \"else\" \n\nВ {data.table} тоже есть свой (более быстрый) аналог case_when() — функция fcase(). Синтаксис отличается только тем, что вместо формул используются простые запятые. То есть первый аргумент – условие, второй – значение, которое возвращается при верности первого аргумента, третий аргумент – условие, четвертый – возвращаемое значение при верности третьего аргумента и т.д.\n\ndata.table::fcase(\n  numbers > 0, \"Положительное число\",\n  numbers < 0, \"Отрицательное число\",\n  numbers == 0, \"Ноль\")\n\n[1] \"Отрицательное число\" \"Отрицательное число\" \"Ноль\"               \n[4] \"Положительное число\" \"Положительное число\"\n\n\nЗадача создания вектора или колонки по множественным условиям из другой колонки плавно перетекает в задачу объединения двух датафреймов по единому ключу, и такое решение может оказаться наиболее быстрым (см. Глава 11.1.2)."
  },
  {
    "objectID": "050-functional.html#sec-create_fun",
    "href": "050-functional.html#sec-create_fun",
    "title": "8  Функциональное программирование в R",
    "section": "8.1 Создание функций",
    "text": "8.1 Создание функций\nПоздравляю, сейчас мы выйдем на качественно новый уровень владения R. Вместо того, чтобы пользоваться теми функциями, которые уже написали за нас, мы можем сами создавать свои функции! В этом нет ничего сложного.\nСинтаксис создания функции внешне похож на создание циклов или условных конструкций. Мы пишем ключевое слово function, в круглых скобках обозначаем переменные, с которыми собираемся что-то делать. Внутри фигурных скобок пишем выражения, которые будут выполняться при запуске функции. У функции есть свое собственное окружение — место, где хранятся переменные. Именно те объекты, которые мы передаем в скобочках, и будут в окружении, так же как и “обычные” переменные для нас в глобальном окружении. Это означает, что функция будет искать переменные в первую очередь среди объектов, которые переданы в круглых скобочках. С ними функция и будет работать. На выходе функция выдаст то, что вычисляется внутри функции return(). Если return() появляется в теле функции несколько раз, то до результат будет возвращаться из той функции return(), до которой выполнение дошло первым.\n\npow <- function(x, p) {\n  power <- x ^ p\n  return(power)\n}\npow(3, 2)\n\n[1] 9\n\n\nЕсли функция проработала до конца, а функция return() так и не встретилась, то возвращается последнее посчитанное значение.\n\npow <- function(x, p) {\n  x ^ p\n}\npow(3, 2)\n\n[1] 9\n\n\nЕсли в последней строчке будет присвоение, то функция ничего не вернет обратно. Это очень распространенная ошибка: функция вроде бы работает правильно, но ничего не возвращает. Нужно писать так, как будто бы в последней строчке результат выполнения выводится в консоль.\n\npow <- function(x, p) {\n  power <- x ^ p #Функция ничего не вернет, потому что в последней строчке присвоение!\n}\npow(3, 2) #ничего не возвращается из функции\n\nЕсли функция небольшая, то ее можно записать в одну строчку без фигурных скобок.\n\npow <- function(x, p) x ^ p\npow(3, 2) \n\n[1] 9\n\n\nВообще, фигурные скобки используются для того, чтобы выполнить серию выражений, но вернуть только результат выполнения последнего выражения. Это можно использовать, чтобы не создавать лишних временных переменных в глобальном окружении.\nМы можем оставить в функции параметры по умолчанию.\n\npow <- function(x, p = 2) x ^ p\npow(3) \n\n[1] 9\n\npow(3, 3) \n\n[1] 27\n\n\n\n\n\n\n\n\nСовет\n\n\n\nВ R работают ленивые вычисления (lazy evaluations). Это означает, что параметры функций будут только когда они понадобятся, а не заранее. R будет как самый ленивый прокрастинатор откладывать чтение данных, пока они не понадобятся в вычислениях. Это приводит к тому, что если параметр никак не задан, то обнаружится это только при его непосредственном использовании. Например, эта функция не будет выдавать ошибку, если мы не зададим параметр we_will_not_use_this_parameter =, потому что он нигде не используется в расчетах.\n\npow <- function(x, p = 2, we_will_not_use_this_parameter) x ^ p\npow(x = 3)\n\n[1] 9"
  },
  {
    "objectID": "050-functional.html#sec-sanity_check",
    "href": "050-functional.html#sec-sanity_check",
    "title": "8  Функциональное программирование в R",
    "section": "8.2 Проверка на адекватность",
    "text": "8.2 Проверка на адекватность\nЛучший способ не бояться ошибок и предупреждений — научиться прописывать их самостоятельно в собственных функциях. Это позволит понять, что за текстом предупреждений и ошибок, которые у вас возникают, стоит забота разработчиков о пользователях, которые хотят максимально обезопасить нас от наших непродуманных действий.\nХорошо написанные функции не только выдают правильный результат на все возможные адекватные данные на входе, но и не дают получить правдоподобные результаты при неадекватных входных данных. Как вы уже знаете, если на входе у вас имеются пропущенные значения, то многие функции будут в ответ тоже выдавать пропущенные значения. И это вполне осознанное решение, которое позволяет избегать ситуаций вроде той, когда около одной пятой научных статей по генетике содержало ошибки в приложенных данных и замечать пропущенные значения на ранней стадии. Кроме того, можно проводить проверки на адекватность входящих данных (sanity check).\nРазберем это на примере самодельной функции imt(), которая выдает индекс массы тела, если на входе задать вес (аргумент weight =) в килограммах и рост (аргумент height =) в метрах.\n\nimt <- function(weight, height) weight / height ^ 2\n\nПроверим, что функция работает верно:\n\nw <- c(60, 80, 120)\nh <- c(1.6, 1.7, 1.8)\nimt(weight = w, height = h)\n\n[1] 23.43750 27.68166 37.03704\n\n\nОчень легко перепутать и написать рост в сантиметрах. Было бы здорово предупредить об этом пользователя, показав ему предупреждающее сообщение, если рост больше, чем, например, 3. Это можно сделать с помощью функции warning()\n\nimt <- function(weight, height) {\n  if (any(height > 3)) warning(\"Рост в аргументе height больше 3: возможно, указан рост в сантиметрах, а не в метрах\\n\")\n  weight / height ^ 2\n}\nimt(78, 167)\n\nWarning in imt(78, 167): Рост в аргументе height больше 3: возможно, указан рост в сантиметрах, а не в метрах\n\n\n[1] 0.002796802\n\n\nВ некоторых случаях ответ будет совершенно точно некорректным, хотя функция все посчитает и выдаст ответ, как будто так и надо. Например, если какой-то из аргументов функции imt() будет меньше или равен 0. В этом случае нужно прописать проверку на это условие, и если это действительно так, то выдать пользователю ошибку.\n\nimt <- function(weight, height) {\n  if (any(weight <= 0 | height <= 0)) stop(\"Индекс массы тела не может быть посчитан для отрицательных значений\")\n  if (any(height > 3)) warning(\"Рост в аргументе height больше 3: возможно, указан рост в сантиметрах, а не в метрах\\n\")\n  weight / height ^ 2\n}\nimt(-78, 167)\n\nError in imt(-78, 167): Индекс массы тела не может быть посчитан для отрицательных значений\n\n\nКогда вы попробуете самостоятельно прописывать предупреждения и ошибки в функциях, то быстро поймете, что ошибки - это вовсе не обязательно результат того, что где-то что-то сломалось и нужно паниковать. Совсем даже наоборот, прописанная ошибка - чья-то забота о пользователях, которых пытаются максимально проинформировать о том, что и почему пошло не так.\nЭто естественно в начале работы с R (и вообще с программированием) избегать ошибок, конечно, в самом начале обучения большая часть из них остается непонятной. Но постарайтесь понять текст ошибки, вспомнить в каких случаях у вас возникала похожая ошибка. Очень часто этого оказывается достаточно чтобы понять причину ошибки даже если вы только-только начали изучать R.\nНу а в дальнейшем я советую ознакомиться со средствами отладки кода в R для того, чтобы научиться справляться с ошибками в своем коде на более продвинутом уровне."
  },
  {
    "objectID": "050-functional.html#sec-why_functions",
    "href": "050-functional.html#sec-why_functions",
    "title": "8  Функциональное программирование в R",
    "section": "8.3 Когда и зачем создавать функции?",
    "text": "8.3 Когда и зачем создавать функции?\nКогда стоит создавать функции? Существует “правило трех” — если у вас есть три куска очень похожего кода, то самое время превратить код в функцию. Это очень условное правило, но, действительно, стоит избегать копипастинга в коде. В этом случае очень легко ошибиться, а сам код становится нечитаемым.\nЕсть и другой подход к созданию функций: их стоит создавать не столько для того, чтобы использовать тот же код снова, сколько для абстрагирования от того, что происходит в отдельных строчках кода. Если несколько строчек кода были написаны для того, чтобы решить одну задачу, которой можно дать понятное название (например, подсчет какой-то особенной метрики, для которой нет готовой функции в R), то этот код стоит обернуть в функцию. Если функция работает корректно, то теперь не нужно думать над тем, что происходит внутри нее. Вы ее можете мысленно представить как операцию, которая имеет определенный вход и выход — как и встроенные функции в R.\nОтсюда следует важный вывод, что хорошее название для функции — это очень важно. Очень, очень, очень важно."
  },
  {
    "objectID": "050-functional.html#sec-functions_objects",
    "href": "050-functional.html#sec-functions_objects",
    "title": "8  Функциональное программирование в R",
    "section": "8.4 Функции как объекты первого порядка",
    "text": "8.4 Функции как объекты первого порядка\nРанее мы убедились, что арифметические операторы — это тоже функции. На самом деле, практически все в R — это функции. Даже function — это функция function(). Даже скобочки (, { — это функции!\nА сами функции — это объекты первого порядка в R. Это означает, что с функциями вы можете делать практически все то же самое, что и с другими объектами в R (векторами, датафреймами и т.д.). Небольшой пример, который может взорвать ваш мозг:\n\nlist(mean, min, `{`)\n\n[[1]]\nfunction (x, ...) \nUseMethod(\"mean\")\n<bytecode: 0x1067c5c80>\n<environment: namespace:base>\n\n[[2]]\nfunction (..., na.rm = FALSE)  .Primitive(\"min\")\n\n[[3]]\n.Primitive(\"{\")\n\n\nМы можем создать список из функций! Зачем — это другой вопрос, но ведь можем же!\nЕще можно создавать функции внутри функций 1, использовать функции в качестве аргументов функций, сохранять функции как переменные. Пожалуй, самое важное из этого всего - это то, что функция может быть аргументом в функции. Не просто название функции как строковая переменная, не результат выполнения функции, а именно сама функция. Это лежит в основе использования семейства функций apply() (@ref(apply_f) и многих фишек tidyverse.\n\nВ Python дело обстоит похожим образом: функции там тоже являются объектами первого порядка, поэтому все эти фишки функционального программирования (с поправкой на синтаксис, конечно) будут работать и там."
  },
  {
    "objectID": "050-functional.html#sec-apply_f",
    "href": "050-functional.html#sec-apply_f",
    "title": "8  Функциональное программирование в R",
    "section": "8.5 Семейство функций apply()",
    "text": "8.5 Семейство функций apply()\n\n8.5.1 Применение apply() для матриц\nСемейство? Да, их целое множество: apply(), lapply(),sapply(), vapply(),tapply(),mapply(), rapply()… Ладно, не пугайтесь, всех их знать не придется. Обычно достаточно первых двух-трех. Проще всего пояснить как они работают на простой матрице с числами:\n\nA <- matrix(1:12, 3, 4)\nA \n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n\n\nФункция apply() предназначена для работы с матрицами (или многомерными массивами). Если вы скормите функции apply() датафрейм, то этот датафрейм будет сначала превращен в матрицу. Главное отличие матрицы от датафрейма в том, что в матрице все значения одного типа, поэтому будьте готовы, что сработает имплицитное приведение к общему типу данных. Например, если среди колонок датафрейма есть хотя бы одна строковая колонка, то все колонки станут строковыми.\n\nТеперь представим, что нам нужно посчитать что-нибудь (например, сумму) по каждой из строк. С помощью функции apply() вы можете в буквальном смысле “применить” функцию к матрице или датафрейму. Синтаксис такой: apply(X, MARGIN, FUN, ...), где X — данные, MARGIN это 1 (для строк), 2 (для колонок), c(1,2) для строк и колонок (т.е. для каждого элемента по отдельности), а FUN — это функция, которую вы хотите применить! apply() будет брать строки/колонки из X в качестве первого аргумента для функции.\n\n\n\napply\n\n\n\n\n\n\n\n\nВажное уведомление\n\n\n\nЗаметьте, мы вставляем функцию без скобок и кавычек как аргумент в функцию. Это как раз тот случай, когда аргументом в функции выступает сама функция, а не ее название или результат ее выполнения.\n\n\nДавайте разберем на примере:\n\napply(A, 1, sum) #сумма по каждой строчке\n\n[1] 22 26 30\n\napply(A, 2, sum) #сумма по каждой колонке\n\n[1]  6 15 24 33\n\napply(A, c(1,2), sum) #кхм... сумма каждого элемента\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n\n\nКонкретно для подсчета сумм и средних по столбцам и строкам в R есть функции colSums(), rowSums(), colMeans() и rowMeans(), которые можно использовать как альтернативы apply() в данном случае.\n\nЕсли же мы хотим прописать дополнительные аргументы для функции, то их можно перечислить через запятую после функции:\n\napply(A, 1, sum, na.rm = TRUE)\n\n[1] 22 26 30\n\n\n\napply(A, 1, weighted.mean, w = c(0.2, 0.4, 0.3, 0.1)) \n\n[1] 4.9 5.9 6.9\n\n\n\n\n8.5.2 Анонимные функции\nЧто делать, если мы хотим сделать что-то более сложное, чем просто применить одну функцию? А если функция принимает не первым, а вторым аргументом данные из матрицы? В этом случае нам помогут анонимные функции.\nАнонимные функции - это функции, которые будут использоваться один раз и без названия.\n\n\n\n\n\n\nСовет\n\n\n\nПитонистам знакомо понятие лямбда-функций. Да, это то же самое.\n\n\nНапример, мы можем посчитать сумму квадратичных отклонений от среднего без называния этой функции:\n\napply(A, 1, function(x) sum((x - mean(x))^2)) #отклонения от среднего по строчке\n\n[1] 45 45 45\n\napply(A, 2, function(x) sum((x - mean(x))^2)) #отклонения от среднего по столбцу\n\n[1] 2 2 2 2\n\napply(A, c(1, 2), function(x) sum((x - mean(x))^2)) #отклонения от одного значения, т.е. ноль\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    0    0\n[2,]    0    0    0    0\n[3,]    0    0    0    0\n\n\n\n\n\n\n\n\nСовет\n\n\n\nКак и в случае с обычной функцией, в качестве x выступает объект, с которым мы хотим что-то сделать, а дальше следует функция, которую мы собираемся применить к х. Можно использовать не х, а что угодно, как и в обычных функциях:\n\napply(A, 1, function(whatevername) sum((whatevername - mean(whatevername))^2))\n\n[1] 45 45 45\n\n\n\n\n\n\n8.5.3 Другие функции семейства apply()\nОк, с apply() разобрались. А что с остальными? Некоторые из них еще проще и не требуют индексов, например, lapply (для применения к каждому элементу списка) и sapply() - упрощенная версия lapply(), которая пытается по возможности “упростить” результат до вектора или матрицы.\n\nsome_list <- list(some = 1:10, list = letters)\nlapply(some_list, length)\n\n$some\n[1] 10\n\n$list\n[1] 26\n\nsapply(some_list, length)\n\nsome list \n  10   26 \n\n\n\n\n\n\n\n\n\nОсторожность\n\n\n\nДостаточно сложно предсказать, в каких именно случаях будет произведено упрощение, а в каких нет. Поэтому sapply() удобен в исследовании данных, но использовать эту функцию в скриптах не очень рекомендуется. Один из вариантов решения этой проблемы — это функция vapply(), которая позволяет управлять результатом lapply(), но гораздо более красиво эта проблема решена в пакете {purrr} (см. Глава 11.4 ).\n\n\n\nИспользование sapply() на векторе приводит к тем же результатам, что и просто применить векторизованную функцию обычным способом.\n\nsapply(1:10, sqrt)\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\nsqrt(1:10)\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\n\nЗачем вообще тогда нужен sapply(), если мы можем просто применить векторизованную функцию? Ключевое слово здесь векторизованная функция. Если функция не векторизована, то sapply() становится удобным вариантом для того, чтобы избежать итерирования с помощью циклов for.\n\n\n\n\n\n\nСовет\n\n\n\nЕще одна альтернатива - это векторизация невекторизованной функции с помощью Vectorize(). Эта функция просто оборачивает функцию одним из вариантов apply().\n\n\nМожно применять функции lapply() и sapply() на датафреймах. Поскольку фактически датафрейм - это список из векторов одинаковой длины (см. Глава 4.4), то итерироваться эти функции будут по колонкам:\n\nheroes <- read.csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\", \n                   na.strings = c(\"-\", \"-99\"))\nsapply(heroes, class)\n\n          X        name      Gender   Eye.color        Race  Hair.color \n  \"integer\" \"character\" \"character\" \"character\" \"character\" \"character\" \n     Height   Publisher  Skin.color   Alignment      Weight \n  \"numeric\" \"character\" \"character\" \"character\"   \"integer\" \n\n\nЕще одна функция из семейства apply() - функция replicate() - самый простой способ повторить одну и ту же операцию много раз. Обычно эта функция используется при симуляции данных и моделировании. Например, давайте сделаем выборку из логнормального распределения (подробнее про распределения см. в Глава 17.2 ):\n\nsamp <- rlnorm(30)\nhist(samp)\n\n\n\n\nА теперь давайте сделаем 1000 таких выборок и из каждой возьмем среднее:\n\nsampdist <- replicate(1000, mean(rlnorm(30)))\nhist(sampdist)\n\n\n\n\n\n\n\n\n\n\nСовет\n\n\n\nПро функции для генерации случайных чисел и про визуализацию будет в следующих главах: Глава 17.2 и Глава 13 соответственно.\n\n\nЕсли хотите познакомиться с семейством apply() чуточку ближе, то рекомендую вот этот туториал.\nВ заключение стоит сказать, что семейство функций apply() — это очень сильное колдунство, но в tidyverse оно практически полностью перекрывается функциями из пакета {purrr}. Впрочем, если вы поняли логику apply(), то при желании вы легко сможете переключиться на альтернативы из пакета {purrr} (см. Глава 11.4)"
  },
  {
    "objectID": "107-beyond_base_r.html#sec-dt_approach",
    "href": "107-beyond_base_r.html#sec-dt_approach",
    "title": "9  За пределами base R: tidyverse и data.table",
    "section": "9.1 Подход {data.table}",
    "text": "9.1 Подход {data.table}\n{data.table} – это распространенный пакет, который позволяет анализировать датафреймы максимально быстро и с помощью очень лаконичного кода.\ninstall.packages(\"data.table\")\nДавайте импортируем наш набор данных про супергероев. Для этого воспользуемся функцией fread() из пакета {data.table}. Эта функция нам уже знакома как функция для импорта больших наборов данных Глава 6.7.\n“f” в fread() означает “fast and friendly”: эта функция очень быстрая и довольно хорошо угадывает формат текстовой таблицы.\n\nlibrary(data.table)\nheroes_dt <-\n  fread(\n    \"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n    na.strings = c(\"NA\", \"-\", \"-99\")\n  )\n\nФункция fread() создает не просто датафрейм, а дататейбл:\n\nheroes_dt\n\n      V1            name Gender Eye color              Race       Hair color\n  1:   0          A-Bomb   Male    yellow             Human          No Hair\n  2:   1      Abe Sapien   Male      blue     Icthyo Sapien          No Hair\n  3:   2        Abin Sur   Male      blue           Ungaran          No Hair\n  4:   3     Abomination   Male     green Human / Radiation          No Hair\n  5:   4         Abraxas   Male      blue     Cosmic Entity            Black\n ---                                                                        \n730: 729 Yellowjacket II Female      blue             Human Strawberry Blond\n731: 730            Ymir   Male     white       Frost Giant          No Hair\n732: 731            Yoda   Male     brown    Yoda's species            White\n733: 732         Zatanna Female      blue             Human            Black\n734: 733            Zoom   Male       red              <NA>            Brown\n     Height         Publisher Skin color Alignment Weight\n  1:  203.0     Marvel Comics       <NA>      good    441\n  2:  191.0 Dark Horse Comics       blue      good     65\n  3:  185.0         DC Comics        red      good     90\n  4:  203.0     Marvel Comics       <NA>       bad    441\n  5:     NA     Marvel Comics       <NA>       bad     NA\n ---                                                     \n730:  165.0     Marvel Comics       <NA>      good     52\n731:  304.8     Marvel Comics      white      good     NA\n732:   66.0      George Lucas      green      good     17\n733:  170.0         DC Comics       <NA>      good     57\n734:  185.0         DC Comics       <NA>       bad     81\n\nclass(heroes_dt)\n\n[1] \"data.table\" \"data.frame\"\n\n\nДататейбл – это “улучшенный” датафрейм: с ним работают все те функции, которые мы применяли для датафрейма, специальные функции для дататейбла, а что-то работает немного по-другому по сравнению с датафреймом. Например, оператор [, т.е. квадратные скобки.\nДавайте посмотрим по-внимательнее как это происходит на примере расчета среднего роста супергероев, группируя по полу:\n\nheroes_dt[, mean(Height, na.rm = TRUE), by = Gender]\n\n   Gender       V1\n1:   Male 191.9749\n2: Female 174.6840\n3:   <NA> 177.0667\n\n\nСразу уже усложним задачу: возьмем только хороших (у кого в колонке Alignment стоит \"good\"), а потом еще отсортируем по среднему росту.\n\nheroes_dt[Alignment == \"good\", \n          .(mean_height = mean(Height, na.rm = TRUE)), \n          by = Gender][\n            order(-mean_height)\n          ]\n\n   Gender mean_height\n1:   Male    188.9601\n2:   <NA>    179.5000\n3: Female    174.7607\n\n\nУух! Выглядит монструозно, да? Зато как мы все сделали используя минимальное количество знаков. Заметьте, что здесь необычного для нас:\n\nНе нужно прописывать heroes_dt$Alignment, поиск переменной будет начинаться с колонок дататейбла.\nТам, где мы раньше выбирали колонки, мы еще и расчеты можем вести.\nВнутри квадратных скобок появилась вторая запятая, т.е. третье поле, в котором мы прописали группировку.\nНесколько операций прописываются путем соединения квадратных скобочек, код превращается в эдакий паровозик1.\n\nИ это не все отличия!\nНа сайте пакета {data.table} особенно уделяется вниманию скорости {data.table}, приводя в качестве доказательства бэнчмарк, где сравниваются по скорости различные инструменты для работы с данными. {data.table} почти на порядок обгоняет как {dplyr}, так и питоновский pandas – самый используемый пакет для анализа данных в Python.\nРазработчики {data.table} делают особый акцент на “консервативности” пакета: у него нет никаких зависимостей (в этом плане пакет {data.table} обгоняет большинство российских экспатов в Тбилиси), ему достаточно очень старой версии R, функционирование пакета не будет ломаться из-за выкинутых устаревших функций. В общем, {data.table} очень суров и уважаем программистами. Он и не особо пытается понравиться рядовым пользователям. Зато освоив его, вы сможете творить магию: то, что с помощью базового R, tidyverse или Python будет выполняться очень долго (если выполнится вообще), {data.table} сможет сделать гораздо быстрее, иногда в десятки и сотни раз!\nОчень сильно, не правда ли? Чем же может ответить tidyverse?"
  },
  {
    "objectID": "107-beyond_base_r.html#sec-tidy_approach",
    "href": "107-beyond_base_r.html#sec-tidy_approach",
    "title": "9  За пределами base R: tidyverse и data.table",
    "section": "9.2 Подход tidyverse",
    "text": "9.2 Подход tidyverse\nДавайте посмотрим, как будет выглядеть решение тех же задач (отбор строк по условию, агрегация и сортировка) в tidyverse.\ninstall.packages(\"tidyverse\")\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()   masks data.table::between()\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::first()     masks data.table::first()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::last()      masks data.table::last()\n✖ purrr::transpose() masks data.table::transpose()\n\n\nНе пугайтесь сообщений, все в порядке. Во-первых, пакет {tidyverse} – это не просто пакет, а “пакет с пакетами” (да-да, как у вас дома), который подключает сразу несколько других пакетов, которые составляют ядро tidyverse. Список и версии этих пакетов {tidyverse} выводит при подключении. Разные пакеты tidyverse мы очень детально разберем позже (Глава 10 ), а сейчас просто посмотрите, как это все выглядит.\n\nheroes_tbl <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n    na = c(\"NA\", \"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nФункция read_csv() (не путать с функцией из базового R – read.csv()!) возвращает тиббл – “улучшенный” датафрейм, примерно как это было с дататейблом.\n\nheroes_tbl\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\nclass(heroes_tbl)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nТеперь же сделаем то же самое с нашими данными, что мы делали с помощью {data.table}:\n\nheroes_tbl %>%\n  filter(Alignment == \"good\") %>%\n  group_by(Gender) %>%\n  summarise(mean_height = mean(Height, na.rm = TRUE)) %>%\n  arrange(desc(mean_height))\n\n# A tibble: 3 × 2\n  Gender mean_height\n  <chr>        <dbl>\n1 Male          189.\n2 <NA>          180.\n3 Female        175.\n\n\nОчень сильно отличается от того, как мы работали раньше! Хотя в основе лежит все тот же R. Код, написанный в tidyverse, нарочито многословен (особенно по сравнению с {data.table}), каждая отдельная операция имеет свою функцию. Писать нужно больше, зато это гораздо легче: меньше нужно думать, какими хитрыми трюками сделать преобразование данных. Нужно просто разделить весь процесс преобразования данных на отдельные операции и последовательно прописать их. Код получается аккуратный и очень читаемый, даже для человека, который не знает tidyverse или даже R в целом. Даже этот новый оператор %>% выглядит довольно понятно: его можно прочитать как “затем”.\nЗаметьте, что tidyverse выводит очень подробные сообщения, которые даже выглядят очень красиво: со всякими иконками, красивым форматированием. Разработчики tidyverse работают над тем, чтобы делать свой интерфейс максимально понятным для пользователя: говорящие сами за себя названия функций, куча удобных фишек на все случаи жизни.\ntidyverse постоянно обновляется, регулярно появляются новые функции, а старые функции заменяются на более удобные новые. И это не всегда плюс: обновив пакеты, установленные год назад, вы можете обнаружить, что старый код перестал работать! Мол, мы тут придумали, как сделать лучше, переписывайте код заново (или используйте старые версии пакетов).\nРазработчики tidyverse, в целом, не стремится за высокой скоростью. Часто можно заметить, что новые функции работают довольно медленно. Но если у вас строчек меньше миллиона, то разницу в скорости с {data.table} вы едва ли заметите.\nКоманда разработчиков tidyverse работает на компанию Posit (бывшая RStudio). Поэтому в RStudio вы найдете несколько “шпаргалок” для tidyverse, но не для {data.table}. Они также активно активно работают над популяризацией tidyverse, стараясь сделать вход в него максимально комфортным, особенно для людей без опыта программирования. tidyverse команда открыто заявляет о своей политике diversity, некоторые члены этой команды – открытые представители гендерных и сексуальных меньшинств."
  },
  {
    "objectID": "107-beyond_base_r.html#sec-dt_vs_tidy",
    "href": "107-beyond_base_r.html#sec-dt_vs_tidy",
    "title": "9  За пределами base R: tidyverse и data.table",
    "section": "9.3 {data.table} vs tidyverse",
    "text": "9.3 {data.table} vs tidyverse\nТак что же лучше: {data.table} или tidyverse? Это один из самых частых споров в R-комьюнити. У обоих подходов есть плюсы, которые можно обсуждать вечно. Сегодня tidyverse выигрывает в популярности, особенно за пределами русскоязычного пространства.\nВ последнее время {data.table} и tidyverse все меньше противостоят друг другу и все больше взаимодополняют. Например, некоторые используют в качестве основного инструмента tidyverse, но при работе с данными побольше переключаются на {data.table}2. Кроме того, сами разработчики tidyverse пытаются приладить суперскоростной {data.table} в tidyverse: пакет {dtplyr} позволяет “переводить” код, написанный в tidyverse в код на {data.table}.\nТаким образом, выбирая из tidyverse и {data.table}, начинать лучше с более удобного и популярного tidyverse, чем и займемся далее."
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tidy_verse",
    "href": "110-tidyverse_basic.html#sec-tidy_verse",
    "title": "10  Введение в tidyverse",
    "section": "10.1 Вселенная tidyverse",
    "text": "10.1 Вселенная tidyverse\ntidyverse - это не один, а целое множество пакетов. Есть ключевые пакеты (ядро тайдиверса), а есть побочные - в основном для работы со специфическими видами данных.\ntidyverse — это набор пакетов:\n\nggplot2, для визуализации\ntibble, для работы с тибблами, продвинутый вариант датафрейма\ntidyr, для формата tidy data\nreadr, для чтения файлов в R\npurrr, для функционального программирования (замена семейства функций *apply())\ndplyr, для преобразованиия данных\nstringr, для работы со строковыми переменными\nforcats, для работы с переменными-факторами\n\nПолезно также знать о следующих пакетах, не включенных в ядро, но также считающихся частью тайдиверса:\n\nvroom, для быстрой загрузки табоичных данных\nreadxl, для чтения .xls и .xlsx\njsonlite, для работы с JSON\nxml, для работы с XML\nDBI, для работы с базами данных\nrvest, для веб-скреппинга\nlubridate, для работы с временем\ntidytext, для работы с текстами и корпусами\nglue, для продвинутого объединения строк\nmagrtittr, с несколькими вариантами pipe оператора\ntidymodels, для моделирования и машинного обучения1\ndtplyr, для ускорения dplyr за счет перевод синтаксиса на data.table\n\nИ это еще не все пакеты tidyverse! Есть еще много других небольших пакетов, которые тоже считаются частью tidyverse. Кроме официальных пакетов tidyverse есть множество пакетов, которые пытаются соответствовать принципам tidyverse и дополняют его.\nВсе пакеты tidyverse объединены tidy философией и взаимосовместимым синтаксисом. Это означает, что, во многих случаях даже не нужно думать о том, из какого именно пакета тайдиверса пришла функция. Можно просто установить и загрузить пакет tidyverse.\n\ninstall.packages(\"tidyverse\")\n\nПакет tidyverse — это такой пакет с пакетами.\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nПодключение пакета tidyverse автоматически приводит к подключению ядра tidyverse, остальные же пакеты нужно подключать дополнительно при необходимости."
  },
  {
    "objectID": "110-tidyverse_basic.html#загрузка-данных-с-помощью-readr",
    "href": "110-tidyverse_basic.html#загрузка-данных-с-помощью-readr",
    "title": "10  Введение в tidyverse",
    "section": "10.2 Загрузка данных с помощью readr",
    "text": "10.2 Загрузка данных с помощью readr\nСтандартной функцией для чтения .csv файлов в R является функция read.csv(), но мы будем использовать функцию read_csv() из пакета readr. Синтаксис функции read_csv() очень похож на read.csv(): первым аргументом является путь к файлу (в том числе можно использовать URL), некоторые остальные параметры тоже совпадают.\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nПодробнее про импорт данных, в том числе в tidyverse, смотри в @ref(real_data)."
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tibble",
    "href": "110-tidyverse_basic.html#sec-tibble",
    "title": "10  Введение в tidyverse",
    "section": "10.3 tibble",
    "text": "10.3 tibble\nКогда мы загрузили данные с помощью read_csv(), то мы получили tibble, а не data.frame:\n\nclass(heroes)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nТиббл (tibble) - это такой “усовершенствованный” data.frame. Почти все, что работает с data.frame, работает и с тибблами. Однако у тибблов есть свои дополнительные фишки. Самая очевидная из них - более аккуратный вывод в консоль:\n\nheroes\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nВыводятся только первые 10 строк, если какие-то колонки не влезают на экран, то они просто перечислены внизу. Ну а тип данных написан прямо под названием колонки.\nФункции различных пакетов tidyverse сами конвертируют в тиббл при необходимости. Если же нужно это сделать самостоятельно, то можно это сделать так:\n\nheroes_df <- as.data.frame(heroes) #создаем простой датафрейм\nclass(heroes_df)\n\n[1] \"data.frame\"\n\nas_tibble(heroes_df) #превращаем обратно в тиббл\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\nВ дальнейшем мы будем работать только с tidyverse, а это значит, что только с тибблами, а не обычными датафреймами. Тем не менее, тибблы и датафреймы будут в дальнейшем использоваться как синонимы.\n\nМожно создавать тибблы вручную с помощью функции tibble(), которая работает аналогично функции data.frame():\n\ntibble(\n  a = 1:3,\n  b = letters[1:3]\n)\n\n# A tibble: 3 × 2\n      a b    \n  <int> <chr>\n1     1 a    \n2     2 b    \n3     3 c"
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-pipe",
    "href": "110-tidyverse_basic.html#sec-pipe",
    "title": "10  Введение в tidyverse",
    "section": "10.4 magrittr::%>%",
    "text": "10.4 magrittr::%>%\nОператор %>% называется “пайпом” (pipe), т.е. “трубой”. Он означает, что следующая функция (справа от пайпа) принимает на вход в качестве первого аргумента результат выполнения предыдущей функции (той, что слева). Фактически, это примерно то же самое, что и вставлять результат выполнения функции в качестве первого аргумента в другую функцию. Просто выглядит это красивее и читабельнее. Как будто данные пропускаются через трубы функций или конвеерную ленту на заводе, если хотите. А то, что первый параметр функции - это почти всегда данные, работает нам здесь на руку. Этот оператор взят из пакета magrittr2. Возможно, даже если вы не захотите пользоваться tidyverse, использование пайпов Вам понравится.\nВажно понимать, что пайп не дает какой-то дополнительной функциональности или дополнительной скорости работы3. Он создан исключительно для читабельности и комфорта.\nС помощью пайпов вот эту команду…\n\nsum(sqrt(abs(sin(1:22))))\n\n[1] 16.72656\n\n\n…можно переписать вот так:\n\n1:22 %>% \n  sin() %>% \n  abs() %>% \n  sqrt() %>% \n  sum()\n\n[1] 16.72656\n\n\n\nВ очень редких случаях результат выполнения функции нужно вставить не на первую позицию (или же мы хотим использовать его несколько раз). В этих случаях можно использовать ., чтобы обозначить, куда мы хотим вставить результат выполнения выражения слева от %>%.\n\n\"Всем привет!\" %>%\n  c(\"--\", ., \"--\")\n\n[1] \"--\"           \"Всем привет!\" \"--\"          \n\n\nОсновные функции в tidyverse …"
  },
  {
    "objectID": "110-tidyverse_basic.html#главные-пакеты-tidyverse-dplyr-и-tidyr",
    "href": "110-tidyverse_basic.html#главные-пакеты-tidyverse-dplyr-и-tidyr",
    "title": "10  Введение в tidyverse",
    "section": "10.5 Главные пакеты tidyverse: dplyr и tidyr",
    "text": "10.5 Главные пакеты tidyverse: dplyr и tidyr\ndplyr4 — это самая основа всего tidyverse. Этот пакет предоставляет основные функции для манипуляции с тибблами. Пакет dplyr является наследником и более усовершенствованной версией plyr, так что если увидите использование пакета plyr, то, скорее всего, скрипт был написан очень давно.\nПакет tidyr дополняет dplyr, предоставляя полезные функции для тайдификации тибблов. Тайдификация (“аккуратизация”) данных означает приведение табличных данных к такому формату, в котором:\n\nКаждая переменная имеет собственный столбец\nКаждый наблюдение имеет собственную строку\nКаждое значение имеет свою собственную ячейку\n\nВпрочем, многие функции dplyr часто используются при тайдификации, так же как и многие функции tidyr имеет применение вне тайдификации. В общем, функционал этих двух пакетов несколько смешался, поэтому мы будем рассматривать их вместе. А чтобы представлять, какая функция относится к какому пакету (хотя запоминать это необязательно), я буду использовать запись с двумя двоеточиями ::, которая обычно используется для использования функции без подгрузки всего пакета, при первом упоминании функции.\nПакет tidyr — это более усовершенствованная версия пакета reshape2, который в свою очередь является усовершенствованной версией reshape. По аналогии с plyr, если вы видите использование этих пакетов, то это указывает на то, что перед вами морально устаревший код.\nКод с использованием dplyr и tidyrсильно непохож на то, что мы видели раньше. Большинство функций dplyr и tidyr работают с целым тибблом сразу, принимая его в качестве первого аргумента и возвращая измененный тиббл. Это позволяет превратить весь код в последовательный набор применяемых функций, соединенный пайпами. На практике это выглядит очень элегантно, и вы в этом скоро убедитесь."
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tidy_select_cols",
    "href": "110-tidyverse_basic.html#sec-tidy_select_cols",
    "title": "10  Введение в tidyverse",
    "section": "10.6 Работа с колонками тиббла",
    "text": "10.6 Работа с колонками тиббла\n\n10.6.1 Выбор колонок: dplyr::select()\nФункция dplyr::select() позволяет выбирать колонки по номеру или имени (кавычки не нужны).\n\nheroes %>%\n  select(1,5)\n\n# A tibble: 734 × 2\n    ...1 Race             \n   <dbl> <chr>            \n 1     0 Human            \n 2     1 Icthyo Sapien    \n 3     2 Ungaran          \n 4     3 Human / Radiation\n 5     4 Cosmic Entity    \n 6     5 Human            \n 7     6 <NA>             \n 8     7 Human            \n 9     8 <NA>             \n10     9 Human            \n# … with 724 more rows\n\n\n\nheroes %>%\n  select(name, Race, Publisher, `Hair color`)\n\n# A tibble: 734 × 4\n   name          Race              Publisher         `Hair color`\n   <chr>         <chr>             <chr>             <chr>       \n 1 A-Bomb        Human             Marvel Comics     No Hair     \n 2 Abe Sapien    Icthyo Sapien     Dark Horse Comics No Hair     \n 3 Abin Sur      Ungaran           DC Comics         No Hair     \n 4 Abomination   Human / Radiation Marvel Comics     No Hair     \n 5 Abraxas       Cosmic Entity     Marvel Comics     Black       \n 6 Absorbing Man Human             Marvel Comics     No Hair     \n 7 Adam Monroe   <NA>              NBC - Heroes      Blond       \n 8 Adam Strange  Human             DC Comics         Blond       \n 9 Agent 13      <NA>              Marvel Comics     Blond       \n10 Agent Bob     Human             Marvel Comics     Brown       \n# … with 724 more rows\n\n\nОбратите внимание, если в названии колонки присутствует пробел или, например, колонка начинается с цифры или точки и цифры, то это синтаксически невалидное имя (@ref(variables)). Это не значит, что такие названия колонок недопустимы. Но такие названия колонок нужно обособлять ` грависом (правый штрих, на клавиатуре находится там же где и буква ё и ~).\nЕще обратите внимание на то, что функции tidyverse не изменяют сами изначальные тибблы/датафреймы. Это означает, что если вы хотите полученный результат сохранить, то нужно добавить присвоение:\n\nheroes_some_cols <- heroes %>%\n  select(name, Race, Publisher, `Hair color`)\nheroes_some_cols\n\n# A tibble: 734 × 4\n   name          Race              Publisher         `Hair color`\n   <chr>         <chr>             <chr>             <chr>       \n 1 A-Bomb        Human             Marvel Comics     No Hair     \n 2 Abe Sapien    Icthyo Sapien     Dark Horse Comics No Hair     \n 3 Abin Sur      Ungaran           DC Comics         No Hair     \n 4 Abomination   Human / Radiation Marvel Comics     No Hair     \n 5 Abraxas       Cosmic Entity     Marvel Comics     Black       \n 6 Absorbing Man Human             Marvel Comics     No Hair     \n 7 Adam Monroe   <NA>              NBC - Heroes      Blond       \n 8 Adam Strange  Human             DC Comics         Blond       \n 9 Agent 13      <NA>              Marvel Comics     Blond       \n10 Agent Bob     Human             Marvel Comics     Brown       \n# … with 724 more rows\n\n\n\n\n10.6.2 Мини-язык tidyselect для выбора колонок\nДля выбора столбцов (не только в select(), но и для других функций tidyverse) используется специальный мини-язык tidyselect из одноименного пакета5. tidyselect дает очень широкие возможности для выбора колонок.\nМожно использовать оператор : для выбора нескольких соседних колонок (по аналогии с созданием числового вектора с шагом 1).\n\nheroes %>%\n  select(name:Publisher)\n\n# A tibble: 734 × 7\n   name          Gender `Eye color` Race              Hair colo…¹ Height Publi…²\n   <chr>         <chr>  <chr>       <chr>             <chr>        <dbl> <chr>  \n 1 A-Bomb        Male   yellow      Human             No Hair        203 Marvel…\n 2 Abe Sapien    Male   blue        Icthyo Sapien     No Hair        191 Dark H…\n 3 Abin Sur      Male   blue        Ungaran           No Hair        185 DC Com…\n 4 Abomination   Male   green       Human / Radiation No Hair        203 Marvel…\n 5 Abraxas       Male   blue        Cosmic Entity     Black           NA Marvel…\n 6 Absorbing Man Male   blue        Human             No Hair        193 Marvel…\n 7 Adam Monroe   Male   blue        <NA>              Blond           NA NBC - …\n 8 Adam Strange  Male   blue        Human             Blond          185 DC Com…\n 9 Agent 13      Female blue        <NA>              Blond          173 Marvel…\n10 Agent Bob     Male   brown       Human             Brown          178 Marvel…\n# … with 724 more rows, and abbreviated variable names ¹​`Hair color`,\n#   ²​Publisher\n\n\n\nheroes %>%\n  select(name:`Eye color`, Publisher:Weight)\n\n# A tibble: 734 × 7\n   name          Gender `Eye color` Publisher         Skin colo…¹ Align…² Weight\n   <chr>         <chr>  <chr>       <chr>             <chr>       <chr>    <dbl>\n 1 A-Bomb        Male   yellow      Marvel Comics     <NA>        good       441\n 2 Abe Sapien    Male   blue        Dark Horse Comics blue        good        65\n 3 Abin Sur      Male   blue        DC Comics         red         good        90\n 4 Abomination   Male   green       Marvel Comics     <NA>        bad        441\n 5 Abraxas       Male   blue        Marvel Comics     <NA>        bad         NA\n 6 Absorbing Man Male   blue        Marvel Comics     <NA>        bad        122\n 7 Adam Monroe   Male   blue        NBC - Heroes      <NA>        good        NA\n 8 Adam Strange  Male   blue        DC Comics         <NA>        good        88\n 9 Agent 13      Female blue        Marvel Comics     <NA>        good        61\n10 Agent Bob     Male   brown       Marvel Comics     <NA>        good        81\n# … with 724 more rows, and abbreviated variable names ¹​`Skin color`,\n#   ²​Alignment\n\n\nИспользуя ! можно вырезать ненужные колонки.\n\nheroes %>%\n  select(!...1)\n\n# A tibble: 734 × 10\n   name       Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n   <chr>      <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n 1 A-Bomb     Male   yellow  Human No Hair    203 Marvel… <NA>    good       441\n 2 Abe Sapien Male   blue    Icth… No Hair    191 Dark H… blue    good        65\n 3 Abin Sur   Male   blue    Unga… No Hair    185 DC Com… red     good        90\n 4 Abominati… Male   green   Huma… No Hair    203 Marvel… <NA>    bad        441\n 5 Abraxas    Male   blue    Cosm… Black       NA Marvel… <NA>    bad         NA\n 6 Absorbing… Male   blue    Human No Hair    193 Marvel… <NA>    bad        122\n 7 Adam Monr… Male   blue    <NA>  Blond       NA NBC - … <NA>    good        NA\n 8 Adam Stra… Male   blue    Human Blond      185 DC Com… <NA>    good        88\n 9 Agent 13   Female blue    <NA>  Blond      173 Marvel… <NA>    good        61\n10 Agent Bob  Male   brown   Human Brown      178 Marvel… <NA>    good        81\n# … with 724 more rows, and abbreviated variable names ¹​`Eye color`,\n#   ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\nheroes %>%\n  select(!(Gender:Height))\n\n# A tibble: 734 × 6\n    ...1 name          Publisher         `Skin color` Alignment Weight\n   <dbl> <chr>         <chr>             <chr>        <chr>      <dbl>\n 1     0 A-Bomb        Marvel Comics     <NA>         good         441\n 2     1 Abe Sapien    Dark Horse Comics blue         good          65\n 3     2 Abin Sur      DC Comics         red          good          90\n 4     3 Abomination   Marvel Comics     <NA>         bad          441\n 5     4 Abraxas       Marvel Comics     <NA>         bad           NA\n 6     5 Absorbing Man Marvel Comics     <NA>         bad          122\n 7     6 Adam Monroe   NBC - Heroes      <NA>         good          NA\n 8     7 Adam Strange  DC Comics         <NA>         good          88\n 9     8 Agent 13      Marvel Comics     <NA>         good          61\n10     9 Agent Bob     Marvel Comics     <NA>         good          81\n# … with 724 more rows\n\n\nДругие известные нам логические операторы (& и |) тоже работают в tidyselect.\nВ дополнение к логическим операторам и :, в tidyselect есть набор вспомогательных функций, работающих исключительно в контексте выбора колонок с помощью tidyselect.\nВспомогательная функция last_col() позволит обратиться к последней колонке тиббла:\n\nheroes %>%\n  select(name:last_col())\n\n# A tibble: 734 × 10\n   name       Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n   <chr>      <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n 1 A-Bomb     Male   yellow  Human No Hair    203 Marvel… <NA>    good       441\n 2 Abe Sapien Male   blue    Icth… No Hair    191 Dark H… blue    good        65\n 3 Abin Sur   Male   blue    Unga… No Hair    185 DC Com… red     good        90\n 4 Abominati… Male   green   Huma… No Hair    203 Marvel… <NA>    bad        441\n 5 Abraxas    Male   blue    Cosm… Black       NA Marvel… <NA>    bad         NA\n 6 Absorbing… Male   blue    Human No Hair    193 Marvel… <NA>    bad        122\n 7 Adam Monr… Male   blue    <NA>  Blond       NA NBC - … <NA>    good        NA\n 8 Adam Stra… Male   blue    Human Blond      185 DC Com… <NA>    good        88\n 9 Agent 13   Female blue    <NA>  Blond      173 Marvel… <NA>    good        61\n10 Agent Bob  Male   brown   Human Brown      178 Marvel… <NA>    good        81\n# … with 724 more rows, and abbreviated variable names ¹​`Eye color`,\n#   ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nА функция everything() позволяет выбрать все колонки.\n\nheroes %>%\n  select(everything())\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nПри этом everything() не будет дублировать выбранные колонки, поэтому можно использовать everything() для перестановки колонок в тиббле:\n\nheroes %>%\n  select(name, Publisher, everything())\n\n# A tibble: 734 × 11\n   name        Publi…¹  ...1 Gender Eye c…² Race  Hair …³ Height Skin …⁴ Align…⁵\n   <chr>       <chr>   <dbl> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>  \n 1 A-Bomb      Marvel…     0 Male   yellow  Human No Hair    203 <NA>    good   \n 2 Abe Sapien  Dark H…     1 Male   blue    Icth… No Hair    191 blue    good   \n 3 Abin Sur    DC Com…     2 Male   blue    Unga… No Hair    185 red     good   \n 4 Abomination Marvel…     3 Male   green   Huma… No Hair    203 <NA>    bad    \n 5 Abraxas     Marvel…     4 Male   blue    Cosm… Black       NA <NA>    bad    \n 6 Absorbing … Marvel…     5 Male   blue    Human No Hair    193 <NA>    bad    \n 7 Adam Monroe NBC - …     6 Male   blue    <NA>  Blond       NA <NA>    good   \n 8 Adam Stran… DC Com…     7 Male   blue    Human Blond      185 <NA>    good   \n 9 Agent 13    Marvel…     8 Female blue    <NA>  Blond      173 <NA>    good   \n10 Agent Bob   Marvel…     9 Male   brown   Human Brown      178 <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​Publisher, ²​`Eye color`, ³​`Hair color`, ⁴​`Skin color`, ⁵​Alignment\n\n\nВпрочем, для перестановки колонок удобнее использовать специальную функцию relocate() (@ref(tidy_relocate)) Можно даже выбирать колонки по паттернам в названиях. Например, с помощью ends_with() можно выбрать все колонки, заканчивающиеся одинаковым суффиксом:\n\nheroes %>%\n  select(ends_with(\"color\"))\n\n# A tibble: 734 × 3\n   `Eye color` `Hair color` `Skin color`\n   <chr>       <chr>        <chr>       \n 1 yellow      No Hair      <NA>        \n 2 blue        No Hair      blue        \n 3 blue        No Hair      red         \n 4 green       No Hair      <NA>        \n 5 blue        Black        <NA>        \n 6 blue        No Hair      <NA>        \n 7 blue        Blond        <NA>        \n 8 blue        Blond        <NA>        \n 9 blue        Blond        <NA>        \n10 brown       Brown        <NA>        \n# … with 724 more rows\n\n\nАналогично, с помощью функции starts_with() можно найти колонки с одинаковым префиксом, с помощью contains() — все колонки с выбранным паттерном в любой части названия колонки6.\n\nheroes %>%\n  select(starts_with(\"Eye\") & ends_with(\"color\"))\n\n# A tibble: 734 × 1\n   `Eye color`\n   <chr>      \n 1 yellow     \n 2 blue       \n 3 blue       \n 4 green      \n 5 blue       \n 6 blue       \n 7 blue       \n 8 blue       \n 9 blue       \n10 brown      \n# … with 724 more rows\n\nheroes %>%\n  select(contains(\"eight\"))\n\n# A tibble: 734 × 2\n   Height Weight\n    <dbl>  <dbl>\n 1    203    441\n 2    191     65\n 3    185     90\n 4    203    441\n 5     NA     NA\n 6    193    122\n 7     NA     NA\n 8    185     88\n 9    173     61\n10    178     81\n# … with 724 more rows\n\n\nНу и наконец, можно выбирать по содержимому колонок с помощью where(). Это напоминает применение sapply()(@ref(apply_other)) на датафрейме для индексирования колонок: в качестве аргумента для where принимается функция, которая применяется для каждой из колонок, после чего выбираются только те колонки, для которых было получено TRUE.\n\nheroes %>%\n  select(where(is.numeric))\n\n# A tibble: 734 × 3\n    ...1 Height Weight\n   <dbl>  <dbl>  <dbl>\n 1     0    203    441\n 2     1    191     65\n 3     2    185     90\n 4     3    203    441\n 5     4     NA     NA\n 6     5    193    122\n 7     6     NA     NA\n 8     7    185     88\n 9     8    173     61\n10     9    178     81\n# … with 724 more rows\n\n\nФункция where() дает невиданную мощь. Например, можно выбрать все колонки без NA:\n\nheroes %>%\n  select(where(function(x) !any(is.na(x))))\n\n# A tibble: 734 × 3\n    ...1 name          Publisher        \n   <dbl> <chr>         <chr>            \n 1     0 A-Bomb        Marvel Comics    \n 2     1 Abe Sapien    Dark Horse Comics\n 3     2 Abin Sur      DC Comics        \n 4     3 Abomination   Marvel Comics    \n 5     4 Abraxas       Marvel Comics    \n 6     5 Absorbing Man Marvel Comics    \n 7     6 Adam Monroe   NBC - Heroes     \n 8     7 Adam Strange  DC Comics        \n 9     8 Agent 13      Marvel Comics    \n10     9 Agent Bob     Marvel Comics    \n# … with 724 more rows\n\n\n###Переименование колонок: dplyr::rename()\nВнутри select() можно не только выбирать колонки, но и переименовывать их:\n\nheroes %>%\n  select(id = ...1)\n\n# A tibble: 734 × 1\n      id\n   <dbl>\n 1     0\n 2     1\n 3     2\n 4     3\n 5     4\n 6     5\n 7     6\n 8     7\n 9     8\n10     9\n# … with 724 more rows\n\n\nОднако удобнее для этого использовать специальную функцию dplyr::rename(). Синтаксис у нее такой же, как и у select(), но rename() не выбрасывает колонки, которые не были упомянуты.\n\nheroes %>%\n  rename(id = ...1)\n\n# A tibble: 734 × 11\n      id name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nДля массового переименования колонок можно использовать функцию rename_with(). Эта функция так же использует tidyselect синтаксис для выбора колонок (по умолчанию выбираются все колонки) и применяет функцию в качестве аргумента, которая изменяет\n\nheroes %>%\n  rename_with(make.names)\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye.c…¹ Race  Hair.…² Height Publi…³ Skin.…⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​Eye.color, ²​Hair.color, ³​Publisher, ⁴​Skin.color, ⁵​Alignment\n\n\n###Перестановка колонок: dplyr::relocate() {#sec-tidy_relocate}\nДля изменения порядка колонок можно использовать функцию relocate(). Она тоже работает похожим образом на select() и rename()7. Как и rename(), функция relocate() не выкидывает неиспользованные колонки:\n\nheroes %>%\n  relocate(Publisher)\n\n# A tibble: 734 × 11\n   Publisher      ...1 name  Gender Eye c…¹ Race  Hair …² Height Skin …³ Align…⁴\n   <chr>         <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>  \n 1 Marvel Comics     0 A-Bo… Male   yellow  Human No Hair    203 <NA>    good   \n 2 Dark Horse C…     1 Abe … Male   blue    Icth… No Hair    191 blue    good   \n 3 DC Comics         2 Abin… Male   blue    Unga… No Hair    185 red     good   \n 4 Marvel Comics     3 Abom… Male   green   Huma… No Hair    203 <NA>    bad    \n 5 Marvel Comics     4 Abra… Male   blue    Cosm… Black       NA <NA>    bad    \n 6 Marvel Comics     5 Abso… Male   blue    Human No Hair    193 <NA>    bad    \n 7 NBC - Heroes      6 Adam… Male   blue    <NA>  Blond       NA <NA>    good   \n 8 DC Comics         7 Adam… Male   blue    Human Blond      185 <NA>    good   \n 9 Marvel Comics     8 Agen… Female blue    <NA>  Blond      173 <NA>    good   \n10 Marvel Comics     9 Agen… Male   brown   Human Brown      178 <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​`Skin color`, ⁴​Alignment\n\n\nПри этом relocate() имеет дополнительные параметры .after = и .before =, которые позволяют выбирать, куда поместить выбранные колонки.\n\nheroes %>%\n  relocate(Publisher, .after = name)\n\n# A tibble: 734 × 11\n    ...1 name        Publi…¹ Gender Eye c…² Race  Hair …³ Height Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>   <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>  \n 1     0 A-Bomb      Marvel… Male   yellow  Human No Hair    203 <NA>    good   \n 2     1 Abe Sapien  Dark H… Male   blue    Icth… No Hair    191 blue    good   \n 3     2 Abin Sur    DC Com… Male   blue    Unga… No Hair    185 red     good   \n 4     3 Abomination Marvel… Male   green   Huma… No Hair    203 <NA>    bad    \n 5     4 Abraxas     Marvel… Male   blue    Cosm… Black       NA <NA>    bad    \n 6     5 Absorbing … Marvel… Male   blue    Human No Hair    193 <NA>    bad    \n 7     6 Adam Monroe NBC - … Male   blue    <NA>  Blond       NA <NA>    good   \n 8     7 Adam Stran… DC Com… Male   blue    Human Blond      185 <NA>    good   \n 9     8 Agent 13    Marvel… Female blue    <NA>  Blond      173 <NA>    good   \n10     9 Agent Bob   Marvel… Male   brown   Human Brown      178 <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​Publisher, ²​`Eye color`, ³​`Hair color`, ⁴​`Skin color`, ⁵​Alignment\n\n\nrelocate() очень хорошо работает в сочетании с выбором колонок с помощью tidyselect. Например, можно передвинуть в одно место все колонки с одним типом данных:\n\nheroes %>%\n  relocate(Publisher, where(is.numeric), .after = name)\n\n# A tibble: 734 × 11\n   name         Publi…¹  ...1 Height Weight Gender Eye c…² Race  Hair …³ Skin …⁴\n   <chr>        <chr>   <dbl>  <dbl>  <dbl> <chr>  <chr>   <chr> <chr>   <chr>  \n 1 A-Bomb       Marvel…     0    203    441 Male   yellow  Human No Hair <NA>   \n 2 Abe Sapien   Dark H…     1    191     65 Male   blue    Icth… No Hair blue   \n 3 Abin Sur     DC Com…     2    185     90 Male   blue    Unga… No Hair red    \n 4 Abomination  Marvel…     3    203    441 Male   green   Huma… No Hair <NA>   \n 5 Abraxas      Marvel…     4     NA     NA Male   blue    Cosm… Black   <NA>   \n 6 Absorbing M… Marvel…     5    193    122 Male   blue    Human No Hair <NA>   \n 7 Adam Monroe  NBC - …     6     NA     NA Male   blue    <NA>  Blond   <NA>   \n 8 Adam Strange DC Com…     7    185     88 Male   blue    Human Blond   <NA>   \n 9 Agent 13     Marvel…     8    173     61 Female blue    <NA>  Blond   <NA>   \n10 Agent Bob    Marvel…     9    178     81 Male   brown   Human Brown   <NA>   \n# … with 724 more rows, 1 more variable: Alignment <chr>, and abbreviated\n#   variable names ¹​Publisher, ²​`Eye color`, ³​`Hair color`, ⁴​`Skin color`\n\n\nПоследняя важная функция для выбора колонок — pull(). Эта функция делает то же самое, что и индексирование с помощью $, т.е. вытаскивает из тиббла вектор с выбранным названием. Это лучше вписывается в логику tidyverse, поскольку позволяет извлечь колонку из тиббла с использованием пайпа:\n\nheroes %>%\n  select(Height) %>%\n  pull() %>%\n  head()\n\n[1] 203 191 185 203  NA 193\n\nheroes %>%\n  pull(Height) %>%\n  head()\n\n[1] 203 191 185 203  NA 193\n\n\nУ функции pull() есть аргумент name =, который позволяет создать проименованный вектор:\n\nheroes %>%\n  pull(Height, name) %>%\n  head()\n\n       A-Bomb    Abe Sapien      Abin Sur   Abomination       Abraxas \n          203           191           185           203            NA \nAbsorbing Man \n          193 \n\n\nВ отличие от базового R, tidyverse нигде не сокращает имплицитно результат вычислений до вектора, поэтому функция pull() - это основной способ извлечения колонки из тиббла как вектора."
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tidy_select_rows",
    "href": "110-tidyverse_basic.html#sec-tidy_select_rows",
    "title": "10  Введение в tidyverse",
    "section": "10.7 Работа со строками тиббла",
    "text": "10.7 Работа со строками тиббла\n\n10.7.1 Выбор строк по номеру: dplyr::slice()\nНачнем с выбора строк. Функция dplyr::slice() выбирает строчки по их числовому индексу.\n\nheroes %>%\n  slice(1:3)\n\n# A tibble: 3 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1     0 A-Bo… Male   yellow  Human No Hair    203 Marvel… <NA>    good       441\n2     1 Abe … Male   blue    Icth… No Hair    191 Dark H… blue    good        65\n3     2 Abin… Male   blue    Unga… No Hair    185 DC Com… red     good        90\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\n\n10.7.2 Выбор строк по условию: dplyr::filter()\nФункция dplyr::filter() делает то же самое, что и slice(), но уже по условию. Причем для условий нужно использовать не векторы из тиббла, а название колонок (без кавычек) как будто бы они были переменными в окружении.\n\nheroes %>% \n  filter(Publisher == \"DC Comics\")\n\n# A tibble: 215 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 2     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 3    13 Alan Scott  Male   blue    <NA>  Blond      180 DC Com… <NA>    good   \n 4    16 Alfred Pen… Male   blue    Human Black      178 DC Com… <NA>    good   \n 5    19 Amazo       Male   red     Andr… <NA>       257 DC Com… <NA>    bad    \n 6    27 Animal Man  Male   blue    Human Blond      183 DC Com… <NA>    good   \n 7    31 Anti-Monit… Male   yellow  God … No Hair     61 DC Com… <NA>    bad    \n 8    35 Aquababy    Male   blue    <NA>  Blond       NA DC Com… <NA>    good   \n 9    36 Aqualad     Male   blue    Atla… Black      178 DC Com… <NA>    good   \n10    37 Aquaman     Male   blue    Atla… Blond      185 DC Com… <NA>    good   \n# … with 205 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\n\n10.7.3 Семейство функций slice()\nУ функции slice() есть множество родственников, которые объединяют функционал обычного slice() и filter(). Например, с помощью функций dplyr::slice_max() и dplyr::slice_min() можно выбрать заданное количество строк, содержащих наибольшие или наименьшие значения по колонке соответственно:\n\nheroes %>%\n  slice_max(Weight, n = 3)\n\n# A tibble: 3 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   575 Sasq… Male   red     <NA>  Orange     305 Marvel… <NA>    good       900\n2   373 Jugg… Male   blue    Human Red        287 Marvel… <NA>    neutral    855\n3   203 Dark… Male   red     New … No Hair    267 DC Com… grey    bad        817\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\nheroes %>%\n  slice_min(Weight, n = 3)\n\n# A tibble: 3 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   346 Iron… Male   blue    <NA>  No Hair     NA Marvel… <NA>    bad          2\n2   302 Groot Male   yellow  Flor… <NA>       701 Marvel… <NA>    good         4\n3   350 Jack… Male   blue    Human Brown       71 Dark H… <NA>    good        14\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\nФункция slice_sample() позволяет выбирать заданное количество случайных строчек:\n\nheroes %>%\n  slice_sample(n = 3)\n\n# A tibble: 3 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   547 Red … Male   green   Human Red        180 DC Com… <NA>    good        83\n2   564 Robi… Male   blue    Human Red        183 DC Com… <NA>    good       101\n3    37 Aqua… Male   blue    Atla… Blond      185 DC Com… <NA>    good       146\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\nИли же долю строчек:\n\nheroes %>%\n  slice_sample(prop = .01)\n\n# A tibble: 7 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   494 Nite… Male   <NA>    <NA>  <NA>        NA DC Com… <NA>    good        NA\n2   433 Marv… Female green   <NA>  Red        170 Marvel… <NA>    good        56\n3   663 Thun… Male   brown   <NA>  Black      185 Marvel… <NA>    good       101\n4   565 Robi… Male   blue    Human Black      165 DC Com… <NA>    good        56\n5   693 Vert… Female blue    <NA>  Silver     168 Marvel… <NA>    good        52\n6    76 Beet… Male   <NA>    <NA>  <NA>        NA Marvel… <NA>    bad         NA\n7   470 Moon… Male   brown   Human Brown      188 Marvel… <NA>    good       101\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\nЕсли поставить значение параметра prop = равным 1, то таким образом можно перемешать порядок строчек в тиббле:\n\nheroes %>%\n  slice_sample(prop = 1)\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 2   372 Judge Dredd Male   <NA>    Human <NA>       188 Rebell… <NA>    good   \n 3   453 Minna Murr… Female <NA>    <NA>  <NA>        NA Wildst… <NA>    good   \n 4   274 Gamora      Female yellow  Zen-… Black      183 Marvel… green   good   \n 5   417 Luke Campb… Male   <NA>    <NA>  <NA>        NA NBC - … <NA>    bad    \n 6   499 Offspring   Male   <NA>    <NA>  <NA>        NA DC Com… <NA>    good   \n 7   400 Lady Death… Female brown   Cybo… Black      175 Marvel… <NA>    bad    \n 8   336 Hydro-Man   Male   brown   <NA>  Brown      188 Marvel… <NA>    bad    \n 9   511 Penance     <NA>   <NA>    <NA>  <NA>        NA Marvel… <NA>    good   \n10   585 Sentry      Male   blue    Muta… Blond      188 Marvel… <NA>    neutral\n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\n\n10.7.4 Удаление строчек с NA: tidyr::drop_na()\nЕсли нужно выбрать только строчки без пропущенных значений, то можно воспользоваться удобной функцией tidyr::drop_na().\n\nheroes %>%\n  drop_na()\n\n# A tibble: 50 × 11\n    ...1 name       Gender Eye co…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>      <chr>  <chr>    <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     1 Abe Sapien Male   blue     Icth… No Hair    191 Dark H… blue    good   \n 2     2 Abin Sur   Male   blue     Unga… No Hair    185 DC Com… red     good   \n 3    34 Apocalypse Male   red      Muta… Black      213 Marvel… grey    bad    \n 4    39 Archangel  Male   blue     Muta… Blond      183 Marvel… blue    good   \n 5    41 Ardina     Female white    Alien Orange     193 Marvel… gold    good   \n 6    56 Azazel     Male   yellow   Neya… Black      183 Marvel… red     bad    \n 7    74 Beast      Male   blue     Muta… Blue       180 Marvel… blue    good   \n 8    75 Beast Boy  Male   green    Human Green      173 DC Com… green   good   \n 9    92 Bizarro    Male   black    Biza… Black      191 DC Com… white   neutral\n10   108 Blackout   Male   red      Demon White      191 Marvel… white   bad    \n# … with 40 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nМожно выбрать колонки, наличие NA в которых будет приводить к удалению соответствующих строчек (не затрагивая другие строчки, в которых есть NA в остальных столбцах).\n\nheroes %>%\n  drop_na(Weight)\n\n# A tibble: 495 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 6     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 7     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n 8     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n 9    10 Agent Zero  Male   <NA>    <NA>  <NA>       191 Marvel… <NA>    good   \n10    11 Air-Walker  Male   blue    <NA>  White      188 Marvel… <NA>    bad    \n# … with 485 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nДля выбора колонок в drop_na() используется tidyselect, с которым мы недавно познакомились (@ref(tidyselect)).\n\n\n10.7.5 Сортировка строк: dplyr::arrange()\nФункция dplyr::arrange() сортирует строчки от меньшего к большему (или по алфавиту - для текстовых значений) по выбранной колонке.\n\nheroes %>%\n  arrange(Weight)\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1   346 Iron Monger Male   blue    <NA>  No Hair     NA Marvel… <NA>    bad    \n 2   302 Groot       Male   yellow  Flor… <NA>       701 Marvel… <NA>    good   \n 3   350 Jack-Jack   Male   blue    Human Brown       71 Dark H… <NA>    good   \n 4   272 Galactus    Male   black   Cosm… Black      876 Marvel… <NA>    neutral\n 5   731 Yoda        Male   brown   Yoda… White       66 George… green   good   \n 6   255 Fin Fang F… Male   red     Kaka… No Hair    975 Marvel… green   good   \n 7   330 Howard the… Male   brown   <NA>  Yellow      79 Marvel… <NA>    good   \n 8   396 Krypto      Male   blue    Kryp… White       64 DC Com… <NA>    good   \n 9   568 Rocket Rac… Male   brown   Anim… Brown      122 Marvel… <NA>    good   \n10   208 Dash        Male   blue    Human Blond      122 Dark H… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nЧтобы отсортировать в обратном порядке, воспользуйтесь функцией desc().\n\nheroes %>%\n  arrange(desc(Weight))\n\n# A tibble: 734 × 11\n    ...1 name       Gender Eye co…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>      <chr>  <chr>    <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1   575 Sasquatch  Male   red      <NA>  Orange   305   Marvel… <NA>    good   \n 2   373 Juggernaut Male   blue     Human Red      287   Marvel… <NA>    neutral\n 3   203 Darkseid   Male   red      New … No Hair  267   DC Com… grey    bad    \n 4   283 Giganta    Female green    <NA>  Red       62.5 DC Com… <NA>    bad    \n 5   331 Hulk       Male   green    Huma… Green    244   Marvel… green   good   \n 6   549 Red Hulk   Male   yellow   Huma… Black    213   Marvel… red     neutral\n 7   119 Bloodaxe   Female blue     Human Brown    218   Marvel… <NA>    bad    \n 8   718 Wolfsbane  Female green    <NA>  Auburn   366   Marvel… <NA>    good   \n 9   657 Thanos     Male   red      Eter… No Hair  201   Marvel… purple  bad    \n10     0 A-Bomb     Male   yellow   Human No Hair  203   Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nМожно сортировать по нескольким колонкам сразу. В таких случаях удобно в качестве первой переменной выбирать переменную, обозначающую принадлежность к группе, а в качестве второй — континуальную числовую переменную:\n\nheroes %>%\n  arrange(Gender, desc(Weight))\n\n# A tibble: 734 × 11\n    ...1 name      Gender Eye col…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>     <chr>  <chr>     <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1   283 Giganta   Female green     <NA>  Red       62.5 DC Com… <NA>    bad    \n 2   119 Bloodaxe  Female blue      Human Brown    218   Marvel… <NA>    bad    \n 3   718 Wolfsbane Female green     <NA>  Auburn   366   Marvel… <NA>    good   \n 4   591 She-Hulk  Female green     Human Green    201   Marvel… <NA>    good   \n 5   320 Hela      Female green     Asga… Black    213   Marvel… <NA>    bad    \n 6   686 Valkyrie  Female blue      <NA>  Blond    191   Marvel… <NA>    good   \n 7   596 Sif       Female blue      Asga… Black    188   Marvel… <NA>    good   \n 8   271 Frigga    Female blue      <NA>  White    180   Marvel… <NA>    good   \n 9   667 Thundra   Female green     <NA>  Red      218   Marvel… <NA>    good   \n10   592 She-Thing Female blue      Huma… No Hair  183   Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tidy_mutate",
    "href": "110-tidyverse_basic.html#sec-tidy_mutate",
    "title": "10  Введение в tidyverse",
    "section": "10.8 Создание колонок: dplyr::mutate() и dplyr::transmute()",
    "text": "10.8 Создание колонок: dplyr::mutate() и dplyr::transmute()\nФункция dplyr::mutate() позволяет создавать новые колонки в тиббле.\n\nheroes %>%\n  mutate(imt = Weight/(Height/100)^2) %>%\n  select(name, imt) %>%\n  arrange(desc(imt))\n\n# A tibble: 734 × 2\n   name          imt\n   <chr>       <dbl>\n 1 Utgard-Loki 2510.\n 2 Giganta     1613.\n 3 Red Hulk     139.\n 4 Darkseid     115.\n 5 Machine Man  114.\n 6 Thanos       110.\n 7 Destroyer    108.\n 8 A-Bomb       107.\n 9 Abomination  107.\n10 Hulk         106.\n# … with 724 more rows\n\n\ndplyr::transmute() - это аналог mutate(), который не только создает новые колонки, но и сразу же выкидывает все старые:\n\nheroes %>%\n  transmute(imt = Weight/(Height/100)^2)\n\n# A tibble: 734 × 1\n     imt\n   <dbl>\n 1 107. \n 2  17.8\n 3  26.3\n 4 107. \n 5  NA  \n 6  32.8\n 7  NA  \n 8  25.7\n 9  20.4\n10  25.6\n# … with 724 more rows\n\n\nВнутри mutate() и transmute() мы можем использовать либо векторизованные операции (длина новой колонки должна равняться длине датафрейма), либо операции, которые возвращают одно значение. В последнем случае значение будет одинаковым на всю колонку, т.е. будет работать правило ресайклинга (@ref(recycling)):\n\nheroes %>%\n  transmute(name, weight_mean = mean(Weight, na.rm = TRUE))\n\n# A tibble: 734 × 2\n   name          weight_mean\n   <chr>               <dbl>\n 1 A-Bomb               112.\n 2 Abe Sapien           112.\n 3 Abin Sur             112.\n 4 Abomination          112.\n 5 Abraxas              112.\n 6 Absorbing Man        112.\n 7 Adam Monroe          112.\n 8 Adam Strange         112.\n 9 Agent 13             112.\n10 Agent Bob            112.\n# … with 724 more rows\n\n\nОднако в функциях mutate() и transmute() правило ресайклинга не будет работать в остальных случаях: если полученный вектор будет не равен 1 или длине датафрейма, то мы получим ошибку.\n\nheroes %>%\n  mutate(one_and_two = 1:2)\n\nError in `mutate()`:\nℹ In argument: `one_and_two = 1:2`.\nCaused by error:\n! `one_and_two` must be size 734 or 1, not 2.\n\n\nЭто не баг, а фича: авторы пакета dplyr считают, что ресайклинг кратных друг другу векторов — это слишком удобное место для выстрелов себе в ногу. Поэтому в таких случаях разработчики dplyr рекомендуют использовать функцию rep(), знакомую нам уже очень давно (@ref(atomic)).\n\nheroes %>%\n  mutate(one_and_two = rep(1:2, length.out = nrow(.)))\n\n# A tibble: 734 × 12\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 2 more variables: Weight <dbl>, one_and_two <int>, and\n#   abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "110-tidyverse_basic.html#sec-tidy_aggregate",
    "href": "110-tidyverse_basic.html#sec-tidy_aggregate",
    "title": "10  Введение в tidyverse",
    "section": "10.9 Агрегация данных в тиббле",
    "text": "10.9 Агрегация данных в тиббле\n\n10.9.1 Подытоживание: summarise()\nАггрегация по группам - это очень часто возникающая задача, например, это может использоваться для усреднения данных по испытуемым или условиям. Сделать аггрегацию в датафрейме удобной Хэдли Уикхэм пытался еще в предшественнике dplyr, пакете plyr. dplyr позволяет делать аггрегацию очень симпатичным и понятным способым. Аггрегация в dplyr состоит из двух этапов: группировки (group_by()) и подытоживания (summarise()). Начнем с последнего.\nФункция dplyr::summarise()8 позволяет аггрегировать данные в тиббле. Работает она очень похоже на mutate(), но если внутри mutate() используются векторизованные функции, возвращающие вектор такой же длины, что и колонки, использовавшиеся для расчетов, то в summarise() используются функции, которые возвращают вектор длиной 1. Например, min(), mean(), max() и т.д. Можно создавать несколько колонок через запятую (это работает и для mutate()).\n\nheroes %>%\n  mutate(imt = Weight/(Height/100)^2) %>%\n  summarise(min(imt, na.rm = TRUE),\n            max(imt, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  `min(imt, na.rm = TRUE)` `max(imt, na.rm = TRUE)`\n                     <dbl>                    <dbl>\n1                   0.0814                    2510.\n\n\nВ dplyr есть дополнительные суммирующие функции для более удобного индексирования в стиле tidyverse. Например, функции dplyr::nth(), dplyr::first() и dplyr::last(), которые позволяют вытаскивать значения из вектора по индексу (что-то вроде slice(), но для векторов)\n\nheroes %>%\n  mutate(imt = Weight/(Height/100)^2) %>%\n  arrange(imt) %>%\n  summarise(first = first(imt),\n            tenth = nth(imt, 10),\n            last = last(imt))\n\n# A tibble: 1 × 3\n   first tenth  last\n   <dbl> <dbl> <dbl>\n1 0.0814  16.7    NA\n\n\nВ отличие от mutate(), функции внутри summarise() вполне позволяют функциям внутри возвращать вектор из нескольких значений, создавая тиббл такой же длины, как и получившийся вектор.\n\nheroes %>%\n  mutate(imt = Weight/(Height/100)^2) %>%\n  summarise(imt_range = range(imt, na.rm = TRUE)) #функция range() возвращает вектор из двух значений: минимальное и максимальное\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n# A tibble: 2 × 1\n  imt_range\n      <dbl>\n1    0.0814\n2 2510.    \n\n\n\n\n10.9.2 Группировка: group_by()\ndplyr::group_by() - это функция для группировки данных в тиббле по дискретной переменной для дальнейшей аггрегации с помощью summarise(). После применения group_by() тиббл будет выглядеть так же, но у него появятся атрибут groups9:\n\nheroes %>%\n  group_by(Gender)\n\n# A tibble: 734 × 11\n# Groups:   Gender [3]\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nЕсли после этого применить на тиббле функцию summarise(), то мы получим не тиббл длиной один, а тиббл со значением для каждой из групп.\n\nheroes %>%\n  mutate(imt = Weight/(Height/100)^2) %>%\n  group_by(Gender) %>%\n  summarise(min(imt, na.rm = TRUE),\n            max(imt, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  Gender `min(imt, na.rm = TRUE)` `max(imt, na.rm = TRUE)`\n  <chr>                     <dbl>                    <dbl>\n1 Female                  15.5                       1613.\n2 Male                     0.0814                    2510.\n3 <NA>                    16.3                        114.\n\n\nСхематически это выглядит вот так:\n\n\n\n10.9.3 Подсчет строк: dplyr::n(), dplyr::count()\nДля подсчет количества значений можно воспользоваться функцией n().\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(n = n())\n\n# A tibble: 3 × 2\n  Gender     n\n  <chr>  <int>\n1 Female   200\n2 Male     505\n3 <NA>      29\n\n\nФункция n() вместе с group_by() внутри filter() позволяет удобным образом “отрезать” от тиббла редкие группы…\n\nheroes %>%\n  group_by(Race) %>%\n  filter(n() > 10) %>%\n  select(name, Race)\n\n# A tibble: 611 × 2\n# Groups:   Race [6]\n   name          Race             \n   <chr>         <chr>            \n 1 A-Bomb        Human            \n 2 Abomination   Human / Radiation\n 3 Absorbing Man Human            \n 4 Adam Monroe   <NA>             \n 5 Adam Strange  Human            \n 6 Agent 13      <NA>             \n 7 Agent Bob     Human            \n 8 Agent Zero    <NA>             \n 9 Air-Walker    <NA>             \n10 Ajax          Cyborg           \n# … with 601 more rows\n\n\nили же наоборот, выделить только маленькие группы:\n\nheroes %>%\n  group_by(Race) %>%\n  filter(n() == 1) %>%\n  select(name, Race)\n\n# A tibble: 34 × 2\n# Groups:   Race [34]\n   name          Race              \n   <chr>         <chr>             \n 1 Abe Sapien    Icthyo Sapien     \n 2 Abin Sur      Ungaran           \n 3 Alien         Xenomorph XX121   \n 4 Azazel        Neyaphem          \n 5 Bizarro       Bizarro           \n 6 Boba Fett     Human / Clone     \n 7 Darth Maul    Dathomirian Zabrak\n 8 Fin Fang Foom Kakarantharaian   \n 9 Gamora        Zen-Whoberian     \n10 Gladiator     Strontian         \n# … with 24 more rows\n\n\nТаблицу частот можно создать без group_by() и summarise(n = n()). Функция count() заменяет эту конструкцию:\n\nheroes %>%\n  count(Gender)\n\n# A tibble: 3 × 2\n  Gender     n\n  <chr>  <int>\n1 Female   200\n2 Male     505\n3 <NA>      29\n\n\nЭту таблицу частот удобно сразу проранжировать, указав в параметре sort = значение TRUE.\n\nheroes %>%\n  count(Gender, sort = TRUE)\n\n# A tibble: 3 × 2\n  Gender     n\n  <chr>  <int>\n1 Male     505\n2 Female   200\n3 <NA>      29\n\n\n\nФункция count(), несмотря на свою простоту, является одной из наиболее используемых в tidyverse.\n\n\n\n10.9.4 Уникальные значения: dplyr::distinct()\ndplyr::distinct() - это более быстрый аналог unique(), позволяет извлекать уникальные значения для одной или нескольких колонок.\n\nheroes %>%\n  distinct(Gender)\n\n# A tibble: 3 × 1\n  Gender\n  <chr> \n1 Male  \n2 Female\n3 <NA>  \n\n\n\nheroes %>%\n  distinct(Gender, Race)\n\n# A tibble: 81 × 2\n   Gender Race             \n   <chr>  <chr>            \n 1 Male   Human            \n 2 Male   Icthyo Sapien    \n 3 Male   Ungaran          \n 4 Male   Human / Radiation\n 5 Male   Cosmic Entity    \n 6 Male   <NA>             \n 7 Female <NA>             \n 8 Male   Cyborg           \n 9 Male   Xenomorph XX121  \n10 Male   Android          \n# … with 71 more rows\n\n\nИногда нужно аггрегировать данные, но при этом сохранить исходную структуру тиббла. Например, нужно посчитать размер групп или посчитать средние значения по группе для последующего сравнения с индивидуальными значениями.\n\n\n10.9.5 Создание колонок с группировкой\nВ tidyverse это можно сделать с помощью сочетания group_by() и mutate() (вместо summarise()):\n\nheroes %>%\n  group_by(Race) %>%\n  mutate(Race_n = n()) %>%\n  select(Race, name, Gender, Race_n)\n\n# A tibble: 734 × 4\n# Groups:   Race [62]\n   Race              name          Gender Race_n\n   <chr>             <chr>         <chr>   <int>\n 1 Human             A-Bomb        Male      208\n 2 Icthyo Sapien     Abe Sapien    Male        1\n 3 Ungaran           Abin Sur      Male        1\n 4 Human / Radiation Abomination   Male       11\n 5 Cosmic Entity     Abraxas       Male        4\n 6 Human             Absorbing Man Male      208\n 7 <NA>              Adam Monroe   Male      304\n 8 Human             Adam Strange  Male      208\n 9 <NA>              Agent 13      Female    304\n10 Human             Agent Bob     Male      208\n# … with 724 more rows\n\n\nРезультаты аггрегации были записаны в отдельную колонку, при этом значения этой колонки внутри одной группы повторяются:"
  },
  {
    "objectID": "120-tidyverse_advanced.html#sec-tidy_several",
    "href": "120-tidyverse_advanced.html#sec-tidy_several",
    "title": "11  Продвинутый tidyverse",
    "section": "11.1 Объединение нескольких датафреймов",
    "text": "11.1 Объединение нескольких датафреймов\n\n11.1.1 Соединение структурно схожих датафреймов: bind_rows(), bind_cols()\nДля начала подключим tidyverse и возьмем уже знакомый нам датасет про супергероев:\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nТеперь создадим следующие тибблы и сохраним их как dc, marvel и other_publishers:\n\ndc <- heroes %>%\n  filter(Publisher == \"DC Comics\") %>%\n  group_by(Gender) %>%\n  summarise(weight_mean = mean(Weight, na.rm = TRUE))\ndc\n\n# A tibble: 3 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        76.8\n2 Male         113. \n3 <NA>         NaN  \n\nmarvel <- heroes %>%\n  filter(Publisher == \"Marvel Comics\") %>%\n  group_by(Gender) %>%\n  summarise(weight_mean = mean(Weight, na.rm = TRUE))\nmarvel\n\n# A tibble: 3 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        80.1\n2 Male         134. \n3 <NA>         129. \n\nother_publishers <- heroes %>%\n  filter(!(Publisher %in% c(\"DC Comics\",\"Marvel Comics\"))) %>%\n  group_by(Gender) %>%\n  summarise(weight_mean = mean(Weight, na.rm = TRUE))\nother_publishers\n\n# A tibble: 3 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        70.8\n2 Male         111. \n3 <NA>         NaN  \n\n\nНесколько тибблов можно объединить вертикально с помощью функции bind_rows(). Для корректного объединения тибблы должны иметь одинаковые названия колонок.\n\nbind_rows(dc, marvel)\n\n# A tibble: 6 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        76.8\n2 Male         113. \n3 <NA>         NaN  \n4 Female        80.1\n5 Male         134. \n6 <NA>         129. \n\n\nЧтобы соединить тибблы горизонтально, воспользуйтесь функцией bind_cols().\n\nbind_cols(dc, marvel)\n\nNew names:\n• `Gender` -> `Gender...1`\n• `weight_mean` -> `weight_mean...2`\n• `Gender` -> `Gender...3`\n• `weight_mean` -> `weight_mean...4`\n\n\n# A tibble: 3 × 4\n  Gender...1 weight_mean...2 Gender...3 weight_mean...4\n  <chr>                <dbl> <chr>                <dbl>\n1 Female                76.8 Female                80.1\n2 Male                 113.  Male                 134. \n3 <NA>                 NaN   <NA>                 129. \n\n\nФункции bind_rows() и bind_cols() могут работать не только с двумя, но сразу с несколькими датафреймами.\n\nbind_rows(dc, marvel, other_publishers)\n\n# A tibble: 9 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        76.8\n2 Male         113. \n3 <NA>         NaN  \n4 Female        80.1\n5 Male         134. \n6 <NA>         129. \n7 Female        70.8\n8 Male         111. \n9 <NA>         NaN  \n\n\nНа входе в функции bind_rows() и bind_cold() можно подавать как сами датафреймы или тибблы через запятую, так и список из датафреймов/тибблов.\n\nheroes_list_of_df <- list(DC = dc, \n                          Marvel = marvel, \n                          Other = other_publishers)\nbind_rows(heroes_list_of_df)\n\n# A tibble: 9 × 2\n  Gender weight_mean\n  <chr>        <dbl>\n1 Female        76.8\n2 Male         113. \n3 <NA>         NaN  \n4 Female        80.1\n5 Male         134. \n6 <NA>         129. \n7 Female        70.8\n8 Male         111. \n9 <NA>         NaN  \n\n\nЧтобы не потерять, из какого датафрейма какие данные, можно указать любое строковое значение (название будущей колонки) для необязательного аргумента .id =.\n\nbind_rows(heroes_list_of_df, .id = \"Publisher\")\n\n# A tibble: 9 × 3\n  Publisher Gender weight_mean\n  <chr>     <chr>        <dbl>\n1 DC        Female        76.8\n2 DC        Male         113. \n3 DC        <NA>         NaN  \n4 Marvel    Female        80.1\n5 Marvel    Male         134. \n6 Marvel    <NA>         129. \n7 Other     Female        70.8\n8 Other     Male         111. \n9 Other     <NA>         NaN  \n\n\nbind_rows() обычно используется, когда ваши данные находятся в разных файлах с одинаковой структурой. Тогда вы можете прочитать все таблицы в папке, сохранить их в качестве списка из датафреймов и объединить в один датафрейм с помощью bind_rows().\n\n\n11.1.2 Реляционные данные: *_join()\nВ реальности иногда возникает ситуация, когда нужно соединить две таблички, у которых есть общий столбец (или несколько столбцов), но все остальные столбцы различаются. Табличек может быть и больше, это может быть целая сеть таблиц, некоторые из которых содержат основные данные, а некоторые - дополнительные, которые необходимо на определенном этапе “включить” в анализ. Например, таблица с расшифровкой аббревиатур или сокращений вроде коротких названий стран или таблица телефонных кодов разных стран. Совокупность нескольких связанных друг с другом таблиц называют реляционными данными.\nВ случае с реляционными данными простых bind_rows() и bind_cols() становится недостаточно.\nЭти две таблички нужно объединить (join). Эта задача обычно возникает не очень часто, обычно это происходит один-два раза в одном проекте, когда нужно дополнить имеющиеся данные дополнительной информацией извне или объединить два набора данных, обрабатывавшихся в разных программах. Всякий раз, когда такая задача возникает, это доставляет много боли. dplyr предлагает интуитивно понятный инструмент для объединения реляционных данных - семейство функций *_join().\nВозьмем для примера два тиббла band_members и band_instruments, встроенных в dplyr специально для демонстрации работы функций *_join().\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  <chr> <chr>  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  <chr> <chr> \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nУ этих двух тибблов есть колонка с одинаковым названием, которая по своему смыслу соединяет данные обоих тибблов. Такая колонка называется ключом. Ключ должен однозначно идентифицировать наблюдения1.\nДавайте попробуем посоединять band_members и band_instruments разными вариантами *_join() и посмотрим, что у нас получится. Все эти функции имеют на входе два обязательных аргумента (x = и y =) в которые мы должны подставить два датафрейма/тиббла которые мы хотим объединить. Главное различие между этими функциями заключается в том, что они будут делать, если уникальные значения в ключах x и y не соответствуют друг другу.\n\n\nleft_join():\n\n\nband_members %>%\n  left_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n\n\nleft_join() - это самая простая для понимания и самая используемая функция из семейства *_join(). Она как бы “дополняет” информацию из первого тиббла вторым тибблом. В этом случае сохраняются все уникальные наблюдения в x, но отбрасываются лишние наблюдения в тиббле y. Тем значениям, которым не нашлось соотвествия в y, в колонках, взятых их y, ставятся значения NA.\nВы можете сами задать колонки-ключи параметром by =, по умолчанию это все колонки с одинаковыми названиями в двух тибблах.\n\nband_members %>%\n  left_join(band_instruments, by = \"name\")\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n\n\nЧасто случается, что колонки-ключи называются по-разному в двух тибблах. Их необязательно переименовывать, можно поставить соответстие вручную используя проименованный вектор:\n\nband_members %>%\n  left_join(band_instruments2, by = c(\"name\" = \"artist\"))\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n\n\n\nright_join():\n\n\nband_members %>%\n  right_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n3 Keith <NA>    guitar\n\n\nright_join() отбрасывает строчки в x, которых не было в y, но сохраняет соответствующие строчки y - left_join() наоборот.\n\nfull_join():\n\n\nband_members %>%\n  full_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 4 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith <NA>    guitar\n\n\nФункция full_join() сохраняет все строчки и из x и y. Пожалуй, наиболее используемая функция после left_join() – благодаря full_join() вы точно ничего не потеряете при объединении.\n\ninner_join():\n\n\nband_members %>%\n  inner_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 2 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n\n\nФункция inner_join() сохраняет только строчки, которые присутствуют и в x, и в y.\n\nsemi_join():\n\n\nband_members %>%\n  semi_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 2 × 2\n  name  band   \n  <chr> <chr>  \n1 John  Beatles\n2 Paul  Beatles\n\n\n\nanti_join():\n\n\nband_members %>%\n  anti_join(band_instruments)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 1 × 2\n  name  band  \n  <chr> <chr> \n1 Mick  Stones\n\n\nФункции semi_join() и anti_join() не присоединяют второй датафрейм/тиббл (y) к первому. Вместо этого они используются как некоторый словарь-фильтр для отделения только тех значений в x, которые есть в y (semi_join()) или, наоборот, которых нет в y (anti_join())."
  },
  {
    "objectID": "120-tidyverse_advanced.html#sec-tidy_data",
    "href": "120-tidyverse_advanced.html#sec-tidy_data",
    "title": "11  Продвинутый tidyverse",
    "section": "11.2 Tidy data: tidyr::pivot_longer(), tidyr::pivot_wider()",
    "text": "11.2 Tidy data: tidyr::pivot_longer(), tidyr::pivot_wider()\nПринцип tidy data предполагает, что каждая строчка содержит в себе одно измерение, а каждая колонка - одну характеристику. Тем не менее, это не говорит однозначно о том, как именно хранить повторные измерения. Их можно хранить как одну колонку для каждого измерения (широкий формат) и как две колонки: одна колонка - для идентификатора измерения, другая колонка - для записи самого измерения.\nЭто лучше понять на примере. Например, вес до и после прохождения курса. Как это лучше записать - как два числовых столбца (один испытуемый - одна строка) или же создать отдельную “группирующую” колонку, в которой будет написано время измерения, а в другой - измеренные значения (одно измерение - одна строка)?\n\nШирокий формат:\n\n\n\n\nСтудент\nДо курса по R\nПосле курса по R\n\n\n\n\nМаша\n70\n63\n\n\nРома\n80\n74\n\n\nАнтонина\n86\n71\n\n\n\n\nДлинный” формат:\n\n\n\n\nСтудент\nВремя измерения\nМасса (кг)\n\n\n\n\nМаша\nДо курса по R\n70\n\n\nРома\nДо курса по R\n80\n\n\nАнтонина\nДо курса по R\n86\n\n\nМаша\nПосле курса по R\n63\n\n\nРома\nПосле курса по R\n74\n\n\nАнтонина\nПосле курса по R\n71\n\n\n\nНа самом деле, оба варианта приемлимы, оба варианта возможны в реальных данных, а разные функции и статистические пакеты могут требовать от вас как длинный, так и широкий форматы.\nТаким образом, нам нужно научиться переводить из широкого формата в длинный и наоборот.\n\ntidyr::pivot_longer(): из широкого в длинный формат\ntidyr::pivot_wider(): из длинного в широкий формат\n\n\n\n\n\nnew_diet <- tibble(\n  student = c(\"Маша\", \"Рома\", \"Антонина\"),\n  before_r_course = c(70, 80, 86),\n  after_r_course = c(63, 74, 71)\n)\nnew_diet\n\n# A tibble: 3 × 3\n  student  before_r_course after_r_course\n  <chr>              <dbl>          <dbl>\n1 Маша                  70             63\n2 Рома                  80             74\n3 Антонина              86             71\n\n\nТиббл new_diet - это пример широкого формата данных.\nПревратим тиббл new_diet длинный:\n\nnew_diet %>%\n  pivot_longer(cols = before_r_course:after_r_course,\n               names_to = \"measurement_time\", \n               values_to = \"weight_kg\")\n\n# A tibble: 6 × 3\n  student  measurement_time weight_kg\n  <chr>    <chr>                <dbl>\n1 Маша     before_r_course         70\n2 Маша     after_r_course          63\n3 Рома     before_r_course         80\n4 Рома     after_r_course          74\n5 Антонина before_r_course         86\n6 Антонина after_r_course          71\n\n\nА теперь обратно в короткий:\n\nnew_diet %>%\n  pivot_longer(cols = before_r_course:after_r_course,\n               names_to = \"measurement_time\", \n               values_to = \"weight_kg\") %>%\n  pivot_wider(names_from = \"measurement_time\",\n              values_from = \"weight_kg\")\n\n# A tibble: 3 × 3\n  student  before_r_course after_r_course\n  <chr>              <dbl>          <dbl>\n1 Маша                  70             63\n2 Рома                  80             74\n3 Антонина              86             71"
  },
  {
    "objectID": "120-tidyverse_advanced.html#трансформация-нескольких-колонок-dplyracross",
    "href": "120-tidyverse_advanced.html#трансформация-нескольких-колонок-dplyracross",
    "title": "11  Продвинутый tidyverse",
    "section": "11.3 Трансформация нескольких колонок: dplyr::across()",
    "text": "11.3 Трансформация нескольких колонок: dplyr::across()\nДопустим, вы хотите посчитать среднюю массу и рост, группируя по полу супергероев. Можно посчитать это внутри одного summarise(), использую запятую:\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(height = mean(Height, na.rm = TRUE),\n            weight = mean(Weight, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  Gender height weight\n  <chr>   <dbl>  <dbl>\n1 Female   175.   78.8\n2 Male     192.  126. \n3 <NA>     177.  129. \n\n\nЕсли таких колонок будет много, то это уже станет сильно неудобным, нам придется много копировать код, а это чревато ошибками и очень скучно.\nПоэтому в dplyr есть функция для операций над несколькими колонками сразу: dplyr::across()2. Эта функция работает похожим образом на функции семейства apply() и использует tidyselect для выбора колонок.\nТаким образом, конструкции с функцией across() можно разбить на три части:\n\nВыбор колонок с помощью tidyselect. Здесь работают все те приемы, которые мы изучили при выборе колонок (Глава 10.6.2).\nСобственно применение функции across(). Первый аргумент .col – колонки, выбранные на первом этапе с помощью tidyselect, по умолчанию это everything(), т.е. все колонки. Второй аргумент .fns – это функция или целый список из функций, которые будут применены к выбранным колонкам. Если функции требуют дополнительных аргументов, то они могут быть перечислены внутри across().\nИспользование summarise() или другой функции dplyr. В этом случае в качестве аргумента для функции используется результат работы функции across().\n\nВот такой вот бутерброд выходит. Давайте посмотрим, как это работает на практике и посчитаем среднее значение по колонкам Height и Weight.\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(c(Height,Weight), mean))\n\n# A tibble: 3 × 3\n  Gender Height Weight\n  <chr>   <dbl>  <dbl>\n1 Female     NA     NA\n2 Male       NA     NA\n3 <NA>       NA     NA\n\n\nЗдесь мы столкнулись с уже известной нам проблемой: функция mean() при столкновении хотя бы с одним NA будет возвращать NA, если мы не изменим параметр na.rm =. Как и в случае с функциями семейства apply() (Глава 8.5), дополнительные параметры для функции можно перечислить через запятую после самой функции:\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(c(Height, Weight), mean, na.rm = TRUE))\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(c(Height, Weight), mean, na.rm = TRUE)`.\nℹ In group 1: `Gender = \"Female\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 3\n  Gender Height Weight\n  <chr>   <dbl>  <dbl>\n1 Female   175.   78.8\n2 Male     192.  126. \n3 <NA>     177.  129. \n\n\nДо этого мы просто использовали выбор колонок по их названию. Но именно внутри across() использование tidyselect раскрывается как удивительно элегантный и мощный инструмент. Например, можно посчитать среднее для всех numeric колонок:\n\nheroes %>%\n  drop_na(Height, Weight) %>%\n  group_by(Gender) %>%\n  summarise(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 × 4\n  Gender  ...1 Height Weight\n  <chr>  <dbl>  <dbl>  <dbl>\n1 Female  394.   174.   78.3\n2 Male    369.   193.  126. \n3 <NA>    375.   182   129. \n\n\nИли длину строк для строковых колонок. Для этого нам понадобится вспомнить, как создавать анонимные функции (@ref(anon_f)).\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(where(is.character), \n                   function(x) mean(nchar(x), na.rm = TRUE)))\n\n# A tibble: 3 × 8\n  Gender  name `Eye color`  Race `Hair color` Publisher `Skin color` Alignment\n  <chr>  <dbl>       <dbl> <dbl>        <dbl>     <dbl>        <dbl>     <dbl>\n1 Female  9.04        4.68  6.42         5.05      11.5         4.57      3.88\n2 Male    9.05        4.53  6.75         5.48      11.4         5.02      3.78\n3 <NA>    9.48        5.16 10.1          6.44      11.9         4         3.96\n\n\nИли же даже посчитать и то, и другое внутри одного summarise()!\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(where(is.numeric), mean, na.rm = TRUE),\n            across(where(is.character), \n                   function(x) mean(nchar(x), na.rm = TRUE)))\n\n# A tibble: 3 × 11\n  Gender  ...1 Height Weight  name Eye c…¹  Race Hair …² Publi…³ Skin …⁴ Align…⁵\n  <chr>  <dbl>  <dbl>  <dbl> <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Female  395.   175.   78.8  9.04    4.68  6.42    5.05    11.5    4.57    3.88\n2 Male    357.   192.  126.   9.05    4.53  6.75    5.48    11.4    5.02    3.78\n3 <NA>    329    177.  129.   9.48    5.16 10.1     6.44    11.9    4       3.96\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\nВнутри одного across() можно применить не одну функцию к каждой из выбранных колонок, а сразу несколько функций для каждой из колонок. Для этого нам нужно использовать список функций (желательно - проименованный).\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(c(Height, Weight), \n                   list(minimum = min,\n                        average = mean,\n                        maximum = max), \n                   na.rm = TRUE))\n\n# A tibble: 3 × 7\n  Gender Height_minimum Height_average Height_maximum Weight_m…¹ Weigh…² Weigh…³\n  <chr>           <dbl>          <dbl>          <dbl>      <dbl>   <dbl>   <dbl>\n1 Female           62.5           175.            366         41    78.8     630\n2 Male             15.2           192.            975          2   126.      900\n3 <NA>            108             177.            198         39   129.      383\n# … with abbreviated variable names ¹​Weight_minimum, ²​Weight_average,\n#   ³​Weight_maximum\n\n\n\nВот нам и понадобился список функций (@ref(functions_objects))!\n\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(c(Height, Weight),\n                   list(min = function(x) min(x, na.rm = TRUE),\n                        mean = function(x) mean(x, na.rm = TRUE),\n                        max = function(x) max(x, na.rm = TRUE),\n                        na_n = function(x, ...) sum(is.na(x)))\n                   )\n            )\n\n# A tibble: 3 × 9\n  Gender Height_min Height_mean Height…¹ Heigh…² Weigh…³ Weigh…⁴ Weigh…⁵ Weigh…⁶\n  <chr>       <dbl>       <dbl>    <dbl>   <int>   <dbl>   <dbl>   <dbl>   <int>\n1 Female       62.5        175.      366      56      41    78.8     630      58\n2 Male         15.2        192.      975     147       2   126.      900     166\n3 <NA>        108          177.      198      14      39   129.      383      15\n# … with abbreviated variable names ¹​Height_max, ²​Height_na_n, ³​Weight_min,\n#   ⁴​Weight_mean, ⁵​Weight_max, ⁶​Weight_na_n\n\n\nХотя основное применение функции across() – это массовое подытоживание с помощью summarise(), across() можно использовать и с другими функциями dplyr. Например, можно делать массовые операции с колонками с помощью mutate():\n\nheroes %>%\n  mutate(across(where(is.character), as.factor))\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <fct>       <fct>  <fct>   <fct> <fct>    <dbl> <fct>   <fct>   <fct>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <dbl>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\nКонструкция across() работает не только внутри summarise() и mutate(), можно применять across() и с другими функциями, которые используют data-masking. Например, можно использовать across() внутри count() вместе с функцией n_distinct(), которая считает количество уникальных значений в векторе. Это позволяет посмотреть таблицу частот для группирующих переменных:\n\nheroes %>%\n  count(across(where(function(x) n_distinct(x) <= 6)))\n\n# A tibble: 11 × 3\n   Gender Alignment     n\n   <chr>  <chr>     <int>\n 1 Female bad          35\n 2 Female good        161\n 3 Female neutral       4\n 4 Male   bad         165\n 5 Male   good        316\n 6 Male   neutral      18\n 7 Male   <NA>          6\n 8 <NA>   bad           7\n 9 <NA>   good         19\n10 <NA>   neutral       2\n11 <NA>   <NA>          1"
  },
  {
    "objectID": "120-tidyverse_advanced.html#sec-purrr",
    "href": "120-tidyverse_advanced.html#sec-purrr",
    "title": "11  Продвинутый tidyverse",
    "section": "11.4 Функциональное программирование: purrr",
    "text": "11.4 Функциональное программирование: purrr\npurrr – это пакет для функционального программирования в tidyverse. Как и многие пакеты tidyverse, purrr пытается заменить собой базовый функционал R на более понятный и удобный. В данном случае, речь в первую очередь идет о функциях семейства apply(), с которыми мы работали ранее (@ref(apply_f)).\nДавайте вспомним, как работает lapply(). В качестве первого аргумента функция lapply() принимает список (или то, что может быть в него превращено, например, датафрейм), в качестве второго - функцию, которая будет применена к каждому элементу списка. На выходе мы получим список такой же длины.\n\nlapply(heroes, class)\n\n$...1\n[1] \"numeric\"\n\n$name\n[1] \"character\"\n\n$Gender\n[1] \"character\"\n\n$`Eye color`\n[1] \"character\"\n\n$Race\n[1] \"character\"\n\n$`Hair color`\n[1] \"character\"\n\n$Height\n[1] \"numeric\"\n\n$Publisher\n[1] \"character\"\n\n$`Skin color`\n[1] \"character\"\n\n$Alignment\n[1] \"character\"\n\n$Weight\n[1] \"numeric\"\n\n\nФункция purrr::map() работает по тому же принципу: можно просто заменить lapply() на map(), и мы получим тот же результат.\n\nmap(heroes, class)\n\n$...1\n[1] \"numeric\"\n\n$name\n[1] \"character\"\n\n$Gender\n[1] \"character\"\n\n$`Eye color`\n[1] \"character\"\n\n$Race\n[1] \"character\"\n\n$`Hair color`\n[1] \"character\"\n\n$Height\n[1] \"numeric\"\n\n$Publisher\n[1] \"character\"\n\n$`Skin color`\n[1] \"character\"\n\n$Alignment\n[1] \"character\"\n\n$Weight\n[1] \"numeric\"\n\n\nmap() можно встроить в канал с пайпом (впрочем, как и lapply()):\n\nheroes %>%\n  map(class)\n\n$...1\n[1] \"numeric\"\n\n$name\n[1] \"character\"\n\n$Gender\n[1] \"character\"\n\n$`Eye color`\n[1] \"character\"\n\n$Race\n[1] \"character\"\n\n$`Hair color`\n[1] \"character\"\n\n$Height\n[1] \"numeric\"\n\n$Publisher\n[1] \"character\"\n\n$`Skin color`\n[1] \"character\"\n\n$Alignment\n[1] \"character\"\n\n$Weight\n[1] \"numeric\"\n\n\nКак и lapply(), map() всегда возвращает список. Из-за этого мы больше пользовались функцией sapply(), а не lapply(). Функция sapply() упрощала результат до вектора, если это возможно. Подобное упрощение может показаться удобным пока не сталкиваешься с тем, что иногда очень сложно предсказать, какой тип данных получится на выходе. Есть функция vapply() в которой можно управлять типом данных на выходе, но она не очень удобная. В purrr эта проблема решена просто: есть множество функций map_*(), где вместо звездочки - нужный формат на выходе.\nНапример, если мы хотим получить строковый вектор на выходе, то нам нужна функция map_chr().\n\nheroes %>%\n  map_chr(class)\n\n       ...1        name      Gender   Eye color        Race  Hair color \n  \"numeric\" \"character\" \"character\" \"character\" \"character\" \"character\" \n     Height   Publisher  Skin color   Alignment      Weight \n  \"numeric\" \"character\" \"character\" \"character\"   \"numeric\" \n\n\nМожно превратить результат в датафрейм с помощью map_df().\n\nheroes %>%\n  map_df(class)\n\n# A tibble: 1 × 11\n  ...1  name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <chr> <chr> <chr>  <chr>   <chr> <chr>   <chr>  <chr>   <chr>   <chr>   <chr> \n1 nume… char… chara… charac… char… charac… numer… charac… charac… charac… numer…\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\nТак же как и функции семейства apply(), функции map_*() отлично сочетаются с анонимными функциями.\n\nheroes %>%\n  map_int(function(x) sum(is.na(x)))\n\n      ...1       name     Gender  Eye color       Race Hair color     Height \n         0          0         29        172        304        172        217 \n Publisher Skin color  Alignment     Weight \n         0        662          7        239 \n\n\nОднако у purrr есть свой, более короткий способ записи анонимных функций: function(arg) заменяется на ~, а arg на ..\n\nheroes %>%\n  map_int(~sum(is.na(.)))\n\n      ...1       name     Gender  Eye color       Race Hair color     Height \n         0          0         29        172        304        172        217 \n Publisher Skin color  Alignment     Weight \n         0        662          7        239 \n\n\nЕсли нужно итерироваться сразу по нескольким спискам, то есть функции map2_*() (для двух списков) и pmap_*() (для нескольких списков)."
  },
  {
    "objectID": "120-tidyverse_advanced.html#sec-list_colums_nest",
    "href": "120-tidyverse_advanced.html#sec-list_colums_nest",
    "title": "11  Продвинутый tidyverse",
    "section": "11.5 Колонки-списки и нестинг: nest()",
    "text": "11.5 Колонки-списки и нестинг: nest()\nРанее мы говорили о том, что датафрейм – это по своей сути список из векторов разной длины. На самом деле, это не совсем так: колонки обычного датафрейма вполне могут быть списками. Однако делать так обычно не рекомендуется, пусть R это и не запрещает создавать такие колонки: многие функции предполагают, что все колонки датафрейма являются векторами.\ntidyverse гораздо дружелюбнее относится к использовании списка в качестве колонки. Такие колонки называются колонками-списками (list columns). Основной способ их создания - использования функции tidyr::nest(). С помощью tidyselect нужно выбрать сжимаемые колонки, которые будут агрегированы по невыбранным колонками. Это и называется нестингом.\n\nheroes %>%\n  nest(!Gender)\n\nWarning: Supplying `...` without names was deprecated in tidyr 1.0.0.\nℹ Please specify a name for each selection.\nℹ Did you want `data = !Gender`?\n\n\n# A tibble: 3 × 2\n  Gender data               \n  <chr>  <list>             \n1 Male   <tibble [505 × 10]>\n2 Female <tibble [200 × 10]>\n3 <NA>   <tibble [29 × 10]> \n\n\nЗаметьте, у нас появилась колонка data, в которой содержатся тибблы. Туда и спрятались все наши данные.\nНестинг похож на агрегирование с помощью group_by(). Если сделать нестинг сгруппированного с помощью group_by() тиббла, то сожмутся все колонки кроме тех, которые выступают в качестве групп:\n\nheroes %>%\n  group_by(Gender) %>%\n  nest()\n\n# A tibble: 3 × 2\n# Groups:   Gender [3]\n  Gender data               \n  <chr>  <list>             \n1 Male   <tibble [505 × 10]>\n2 Female <tibble [200 × 10]>\n3 <NA>   <tibble [29 × 10]> \n\n\nТеперь можно работать с колонкой-списком как с обычной колонкой. Например, применять функцию для каждой строчки (то есть для каждого тиббла) с помощью map() и записывать результат в новую колонку с помощью mutate().\n\nheroes %>%\n  group_by(Gender) %>%\n  nest() %>%\n  mutate(dim = map(data, dim))\n\n# A tibble: 3 × 3\n# Groups:   Gender [3]\n  Gender data                dim      \n  <chr>  <list>              <list>   \n1 Male   <tibble [505 × 10]> <int [2]>\n2 Female <tibble [200 × 10]> <int [2]>\n3 <NA>   <tibble [29 × 10]>  <int [2]>\n\n\nВ конце концов нам нужно “разжать” сжатую колонку-список. Сделать это можно с помощью unnest(), выбрав с помощью tidyselect нужные колонки.\n\nheroes %>%\n  group_by(Gender) %>%\n  nest() %>%\n  mutate(dim = map(data, dim)) %>%\n  unnest(dim)\n\n# A tibble: 6 × 3\n# Groups:   Gender [3]\n  Gender data                  dim\n  <chr>  <list>              <int>\n1 Male   <tibble [505 × 10]>   505\n2 Male   <tibble [505 × 10]>    10\n3 Female <tibble [200 × 10]>   200\n4 Female <tibble [200 × 10]>    10\n5 <NA>   <tibble [29 × 10]>     29\n6 <NA>   <tibble [29 × 10]>     10\n\n\nРазжатая колонка обычно больше сжатой, поэтому разжатие привело к удлинению тиббла. Вместо удлинения тиббла, его можно расширить с помощью unnest_wider().\n\nheroes %>%\n  group_by(Gender) %>%\n  nest() %>%\n  mutate(dim = map(data, dim)) %>%\n  unnest_wider(dim, names_sep = \"_\") \n\n# A tibble: 3 × 4\n# Groups:   Gender [3]\n  Gender data                dim_1 dim_2\n  <chr>  <list>              <int> <int>\n1 Male   <tibble [505 × 10]>   505    10\n2 Female <tibble [200 × 10]>   200    10\n3 <NA>   <tibble [29 × 10]>     29    10\n\n\nНестинг - это мощный инструмент tidyverse, хотя во многих случаях можно обойтись и без него. Наиболее эффективна эта конструкция именно в тех ситуациях, где вы делаете операции над целыми тибблами. Поэтому наибольшее распространение нестинг получил в смычке с пакетом broom для расчета множественных статистических моделей.\nДругое применение нестинга – решение проблемы с несколькими значениями в одной ячейки, которые записаны через запятую или какой-либо другой знак. Такое часто встречается в данных, поэтому хорошо бы уметь с этим работать!\nВозьмем небольшой искусственный пример:\n\nfilms <- tribble(\n  ~film, ~genres,\n  \"Ирония Судьбы\", \"comedy, drama\",\n  \"Большой Лебовски\", \"comedy, criminal\",\n  \"Аватар\", \"fantasy, drama\"\n)\n\nfilms\n\n# A tibble: 3 × 2\n  film             genres          \n  <chr>            <chr>           \n1 Ирония Судьбы    comedy, drama   \n2 Большой Лебовски comedy, criminal\n3 Аватар           fantasy, drama  \n\n\nДля этого разобъем значения колонки genres с помощью встроенной функции strsplit(). Она разбивает значения вектора по выбранному разделителю. Здесь нам нужен разделитель \", \" (с пробелом после запятой!). На выходе мы получим список такой же длины, что и исходный вектором, а каждый элемент этого списка будет строковым вектором. Количество значений внутри векторов может быть каким угодно. Поскольку результат – список, перезаписанная колонка genres станет колонкой-списком.\n\nfilms %>%\n  mutate(genres = strsplit(genres, \", \"))\n\n# A tibble: 3 × 2\n  film             genres   \n  <chr>            <list>   \n1 Ирония Судьбы    <chr [2]>\n2 Большой Лебовски <chr [2]>\n3 Аватар           <chr [2]>\n\n\nТеперь нам нужно сделать unnest()\n\nfilms %>%\n  mutate(genres = strsplit(genres, \", \")) %>%\n  unnest()\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(genres)`.\n\n\n# A tibble: 6 × 2\n  film             genres  \n  <chr>            <chr>   \n1 Ирония Судьбы    comedy  \n2 Ирония Судьбы    drama   \n3 Большой Лебовски comedy  \n4 Большой Лебовски criminal\n5 Аватар           fantasy \n6 Аватар           drama   \n\n\nТеперь у нас данные в длинном виде! Результат можно расширить с помощью уже знакомого pivot_wider() и дополнительной колонки со значениями TRUE. Если соответствующей пары нет в тиббле, то в итоговой широкой таблице будет NA, мы можем поменять их на FALSE с помощью параметра values_fill =.\n\nfilms %>%\n  mutate(genres = strsplit(genres, \", \")) %>%\n  unnest() %>%\n  mutate(value = TRUE) %>%\n  pivot_wider(names_from = \"genres\",\n              values_from = \"value\", values_fill = FALSE)\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(genres)`.\n\n\n# A tibble: 3 × 5\n  film             comedy drama criminal fantasy\n  <chr>            <lgl>  <lgl> <lgl>    <lgl>  \n1 Ирония Судьбы    TRUE   TRUE  FALSE    FALSE  \n2 Большой Лебовски TRUE   FALSE TRUE     FALSE  \n3 Аватар           FALSE  TRUE  FALSE    TRUE   \n\n\nПравда, то же самое можно сделать чуть проще, без колонок списков. Специально для этой задачи есть функция tidyr::separate_rows(), которая заменяет связку strsplit() с unnest():\n\nfilms %>%\n  separate_rows(genres, sep = \", \") %>%\n  mutate(value = TRUE) %>%\n  pivot_wider(names_from = \"genres\",\n              values_from = \"value\", values_fill = FALSE)\n\n# A tibble: 3 × 5\n  film             comedy drama criminal fantasy\n  <chr>            <lgl>  <lgl> <lgl>    <lgl>  \n1 Ирония Судьбы    TRUE   TRUE  FALSE    FALSE  \n2 Большой Лебовски TRUE   FALSE TRUE     FALSE  \n3 Аватар           FALSE  TRUE  FALSE    TRUE"
  },
  {
    "objectID": "205-eda.html",
    "href": "205-eda.html",
    "title": "Разведочный анализ и создание отчетов",
    "section": "",
    "text": "Этот раздел посвящен исследованию данных с помощью описательной статистики и визуализации данных, а также представлению результатов в виде отчетов.\nВ главе Глава 12 мы впервые познакомимся со статистикой, а именно с ее наиболее простой частью – описательной статистикой. Здесь разобраны как сами статистики, так и функции, которые позволяют удобным образом посчитать их все вместе для имеющихся данных\nВ главах ?sec-r_viz, Глава 14, Глава 15 разобраны различные инструменты визуализации данных: как простые встроенные инструменты, более сложный и гибкий пакет ggplot2 с его дополнениями и даже интерактивные визуализации!\nВ главе Глава 16 мы научимся делать отчеты и презентации с помощью R Markdown, совмещая отформатированный текст, картинки, ссылки и прочее с кусками кода. Кстати, эта книга написана именно с помощью R Markdown!"
  },
  {
    "objectID": "210-desc_stats.html#sec-desc_infer",
    "href": "210-desc_stats.html#sec-desc_infer",
    "title": "12  Описательная статистика",
    "section": "12.1 Описательная статистика и статистика вывода",
    "text": "12.1 Описательная статистика и статистика вывода\nСтатистика делится на описательную статистику (descriptive statistics) и статистику вывода (inferential statistics). Описательная статистика пытается описать нашу выборку (sample, т.е. те данные, что у нас на руках) различными способами. Проблема в том, что описательная статистика может описать только то, что у нас есть, но не позволяет сделать выводы о генеральной совокупности (population) - это уже цель статистики вывода. Цель описательной статистики - “ужать” данные для их обобщенного понимания с помощью статистик.\n\nЗаметьте, у выборки (sample) мы считаем статистики (statistics), а у генеральной совокупности (Population) есть параметры (Parameters). Вот такая вот мнемотехника.\n\nСтатистики часто выступают в роли точечной оценки (point estimators) параметров, так что в этом легко запутаться. Например, среднее (в выборке) - это оценка среднего (в генеральной совокупности). Да, можно свихнуться. Мы это будем разбирать подробнее в следующие занятия (это действительно важно, поверьте), пока что остановимся только на описании выборки."
  },
  {
    "objectID": "210-desc_stats.html#типы-шкал",
    "href": "210-desc_stats.html#типы-шкал",
    "title": "12  Описательная статистика",
    "section": "12.2 Типы шкал",
    "text": "12.2 Типы шкал\nПеред тем, как начать речь об описательных статистиках, нужно разобраться с существующими типами шкал. Типы шкал классифицируются на основании типа измеряемых данных, которые задают допустимые для данной шкалы отношения.\n- Шкала наименований (номинальная шкала) — самая простая шкала, где единственное отношение между элементами — это отношения равенства и неравенства. Это любая качественная шкала, между элементами которой не могут быть установлены отношения “больше — меньше”. Это большинство группирующих переменных (экспериментальная группа, пол, политическая партия, страна), переменные с id. Еще один пример - номера на майках у футболистов.\n- Шкала порядка (ранговая шкала) — шкала следующего уровня, для которой можно установить отношения “больше — меньше”, причем если B больше A, а C больше B, то и C должно быть больше A. Если это верно, то мы можем выстроить последовательность значений. Однако мы еще не можем говорить о разнице между значениями. Ответы на вопросы “Как часто вы курите?” по шкале “Никогда”, “Редко” и “Часто” являются примером ранговой шкалы. “Часто” — это чаще, чем “Редко”, “Редко” — это чаще чем “Никогда”, и, соотвественно, “Часто” — это чаще, чем “Никогда”. Но мы не можем сказать, что разница между “Часто” и “Редко” такая же, как и между “Редко” и “Никогда”. Соответственно, даже если мы обозначим “Часто”, “Редко” и “Никогда” как 3, 2 и 1 соответственно, то многого не можем сделать с этой шкалой, Например, мы не можем посчитать арифметическое среднее для такой шкалы.\n- Шкала разностей (интервальная шкала) — шкала, для которой мы уже можем говорить про разницы между интервалами. Например, разница между 10 Cº и 20 Cº такая же как и между 80 Cº и 90 Cº. Для шкалы разностей уже можно сравнивать средние, но операции умножения и деления не имеют смысл, потому что ноль в шкале разностей относительный. Например, мы не можем сказать, что 20 Cº — это в два раза теплее, чем 10 Cº, потому что 0 Cº — это просто условно взятая точка — температура плавления льда.\n- Шкала отношений (абсолютная шкала) — самая “полноценная” шкала, которая отличается от интервальной наличием естественного и однозначного начала координат. Например, масса в килограммах или та же температура, но в градусах Кельвина, а не Цельсия."
  },
  {
    "objectID": "210-desc_stats.html#sec-quantiles",
    "href": "210-desc_stats.html#sec-quantiles",
    "title": "12  Описательная статистика",
    "section": "12.3 Квантили",
    "text": "12.3 Квантили\nВ жизни мы постоянно проходим какие-нибудь тесты, получаем баллы и рано или поздно встает вопрос: ну а как оно у других? Как бы нас ни учили книжки по саморазвитию, что не стоит сравнивать себя с другими, от этого вопроса очень сложно избавиться. А иногда и вовсе не нужно.\nДопустим, вы проходите профессиональный тест с задачами одинаковой сложности. Как понять, если вы решили 10 из 20 задач (допустим, что задачи одинаковой сложности), то это много или мало? Мы договорились, что задачи одинаковой сложности, но не сказали какой. Если все 20 задач очень легкие, то 10 – это мало, а если сложные – то много. В этой ситуации может быть важен относительный успех: сколько людей справились с тестом хуже вас, а сколько - лучше вас. Вот это и позволяют посчитать процентили (percentile rank) – процент значений в распределении ниже заданного значения. То есть 90ый процентиль означает, что вы справились лучше, чем 90% людей, который прошли тот же тест. То есть вы находитесь в 10% самых-самых! Поэтому настоящие понторезы должны меряться не абсолютными значениями, а процентилями.\nЗдесь сразу нужно оговориться, что понятие процентиля имеет несколько неоднозначностей. В английском принято разделять percentile и percentile rank. Percentile rank – это процент значений в распределении ниже заданного, то просто percentile – это само значение, ниже которого находится соответствующий процент значений. А иногда и вовсе процентилем называют сам интервал между процентильными границами. Все эти понятия взаимосвязаны, поэтому о том, в каком именно значении используется понятие “процентиль” можно догадаться из контекста. Другая неоднозначность понятия процентиля связана с тем, в какой процентиль относить пограничные значения. Эта проблема породила целых девять различных подходов к расчету процентилей! Однако если шкала континуальная и имеет достаточно много значений, то разницы между этими подходами не будет.\nМожно делить значения не на 100 интервалов, а на меньшее количество. Например, на 4. Для этого нам нужно три точки: одна отделяет 25% наименьших значений, вторая отделяет нижнее 50% от верхних 50% (то есть это медиана!), третья – верхние 25% отнижних 75%. Эти точки и интервалы, разделяемые ими, называются квартилями.\n\nКроме процентилей и квартилей есть еще децили, квинтили, секстили, септили и что угодно -тили, хотя и используются они гораздо реже. Общее название для всех них – квантили."
  },
  {
    "objectID": "210-desc_stats.html#sec-cent_tend",
    "href": "210-desc_stats.html#sec-cent_tend",
    "title": "12  Описательная статистика",
    "section": "12.4 Меры центральной тенденции",
    "text": "12.4 Меры центральной тенденции\nПродолжим работать с данными про супергероев.\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nДля примера мы возьмем массу супергероев, предварительно удалив из нее все NA для удобства.\n\nweight <- heroes %>%\n  drop_na(Weight) %>%\n  pull(Weight)\n\nМера центральной тенденции - это число для описания центра распределения.\n\n12.4.1 Арифметическое среднее\nСамая распространенная мера центральных тенденций - арифметическое среднее, то самое, которые мы считаем с помощью функции mean().\n\\[\\overline{x}= \\frac{\\sum\\limits_{i=1}^{n} x_{i}} {n}\\]\nНе пугайтесь значка \\[\\sum\\limits_{i=1}^{n}\\] - это означает сумму от i = 1 до n. Что-то вроде цикла for!\nВ качестве упражнения попробуйте самостоятельно превратить эту формулу в функцию mymean() c помощью sum() и length(). Можете убирать NA по дефолту! Сравните с результатом функции mean().\n\nmean(weight)\n\n[1] 112.2525\n\n\n\n\n12.4.2 Медиана\nПредставьте себе, что мы считаем среднюю зарплату сотрудников завода. Большинство рабочих получает 30000-40000 рублей в месяц, а директор завода получает 2 миллиона в месяц. Средняя зарплата на заводе в итоге равна 70000 рублей. Никакого подвоха: мы просто применили арифметическое среднее. Что спросили, то и получили, никаких манипуляций с цифрами! На деле же нас интересует обычно не средняя зарплата, а сколько получает средний сотрудник. Не директор, не главный мастер, но и не новичок и не алкоголик Василий, который постоянно опаздывает и плохо справляется с работой. Простой рабочий Иван, нормальный парень. Сколько зарабатывают такие как он? Для ответа на этот вопрос используют не арифметическое среднее, а медиану.\nМедиана (median) - это середина распределения. Представим, что мы расставили значения по порядку (от меньшего к большему) и взяли значение посередине.\n\nЕсли у нас четное количество значений, то берется среднее значение между теми двумя, что по середине.\n\nДля расчета медианы есть функция median():\n\nmedian(weight)\n\n[1] 81\n\n\nРазница медианы со средним существенная. Это значит, что распределение довольно асимметричное.\nПредставьте себе, что кто-то говорит про среднюю зарплату в Москве. Но ведь эта средняя зарплата становится гораздо больше, если учитывать относительно небольшое количество мультимиллионеров и миллиардеров! А вот медианная зарплата будет гораздо меньше.\nПредставьте себе, что в среде супергероев поялвяется кто-то, кто весит 9000 килограммов! Тогда среднее сильно изменится:\n\nmean(c(weight, 9000))\n\n[1] 130.1714\n\n\nА вот медиана останется той же.\n\nmedian(c(weight, 9000))\n\n[1] 81\n\n\nТаким образом, экстремально большие или маленькие значения оказывают сильное влияние на арифметическое среднее, но не на медиану. Поэтому медиана считается более “робастной” оценкой, т.е. более устойчивой к выбросам и крайним значениям.\n\n\n12.4.3 Усеченное среднее (trimmed mean)\nЕсли про среднее и медиану слышали все, то про усеченное (тримленное) среднее известно гораздо меньше. Тем не менее, на практике это довольно удобная штука, потому что представляет собой некий компромисс между арифметическим средним и медианой.\nВ усеченном среднем значения ранжируются так же, как и для медианы, но отбрасывается только какой-то процент крайних значений. Усеченное среднее можно посчитать с помощью обычной функции mean(), поставив нужное значение параметра trim =:\n\nmean(weight, trim = 0.1)\n\n[1] 89.56423\n\n\ntrim = 0.1 означает, что мы отбросили 10% слева и 10% справа. trim может принимать значения от 0 до 0.5. Что будет, если trim = 0?\n\nmean(weight, trim = 0)\n\n[1] 112.2525\n\n\nОбычное арифметическое среднее! А если trim = 0.5?\n\nmean(weight, trim = 0.5)\n\n[1] 81\n\n\nМедиана!\n\n\n12.4.4 Мода\nМода (mode) - это самое частое значение. Обычно используется для номинальных переменных, для континуальных данных мода неприменима. Что интересно, в R нет встроенной функции для подсчета моды. Обычно она и не нужна: мы можем посчитать таблицу частот и даже проранжировать ее (и мы уже умеем это делать разными способами).\n\nheroes %>%\n  count(Gender, sort = TRUE)\n\n# A tibble: 3 × 2\n  Gender     n\n  <chr>  <int>\n1 Male     505\n2 Female   200\n3 <NA>      29\n\n\n\nМожете попробовать написать свою функцию для моды!"
  },
  {
    "objectID": "210-desc_stats.html#sec-vary",
    "href": "210-desc_stats.html#sec-vary",
    "title": "12  Описательная статистика",
    "section": "12.5 Меры рассеяния",
    "text": "12.5 Меры рассеяния\n\nНачинающий статистик пытался перейти в брод реку, средняя глубина которой 1 метр. И утонул.\nВ чем была его ошибка? Он не учитывал разброс значений глубины!\n\nМер центральной тенденции недостаточно, чтобы описать выборку. Необходимо знать ее вариабельность.\n\n\n12.5.1 Размах\nСамое очевидное - посчитать размах (range), то есть разницу между минимальным и максимальным значением. В R есть функция для вывода максимального и минимального значений:\n\nrange(weight)\n\n[1]   2 900\n\n\nОсталось посчитать разницу между ними:\n\ndiff(range(weight))\n\n[1] 898\n\n\nЕстественно, крайние значения очень сильно влияют на этот размах, поэтому на практике он не очень-то используется.\n\n\n12.5.2 Дисперсия\nДисперсия (variance) вычисляется по следующей формуле:\n\\[s^2= \\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n}\\]\nПопробуйте превратить это в функцию myvar()!\n\nmyvar <- function(x) mean((x - mean(x))^2)\n\nЕстественно, в R уже есть готовая функция var(). Но, заметьте, ее результат немного отличается от нашего:\n\nmyvar(weight)\n\n[1] 10825.55\n\nvar(weight)\n\n[1] 10847.46\n\n\nДело в том, что встроенная функция var() делит не на \\(n\\), а на \\(n-1\\). Это связано с тем, что эта функция пытается оценить дисперсию в генеральной совокупности, т.е. относится уже к статистике вывода. Про это мы будем говорить в дальнейших занятиях, сейчас нам нужно только отметить то, что здесь есть небольшое различие.\n\n\n12.5.3 Стандартное отклонение\nЕсли вы заметили, значение дисперсии очень большое. Чтобы вернуться к единицам измерения, соответствующих нашим данным используется корень из дисперсии, то есть стандартное отклонение (standard deviation):\n\\[s= \\sqrt\\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n}\\]\nДля этого есть функция sd():\n\nsd(weight)\n\n[1] 104.1511\n\n\nЧто то же самое, что и:\n\nsqrt(var(weight))\n\n[1] 104.1511\n\n\n\n\n12.5.4 Медианное абсолютное отклонение\nПоскольку стандартное отклонение не устойчиво к выбросам, то иногда используют его альтернативу, которая устойчива к выбросам (особенно если эти выбросы нам как раз и нужно удалить) - медианное абсолютное отклонение (median absolute deviation):\n\\[mad= median(|x_{i} - median(x)|)\\]\nДля этого есть функция mad():\n\nmad(weight)\n\n[1] 32.6172\n\n\n\n\n12.5.5 Межквартильный размах\nДругой вариант рабостной оценки вариабельности данных является межквартильный размах (interquartile range, IQR). Это разница между третьим и первым квартилем 1 - значением, которое больше 75% значений в выборке, и значением, которое больше 25% значений в выборке.\n\nIQR(weight)\n\n[1] 47\n\n\n\nНу а второй квартиль - это медиана!"
  },
  {
    "objectID": "210-desc_stats.html#sec-skku",
    "href": "210-desc_stats.html#sec-skku",
    "title": "12  Описательная статистика",
    "section": "12.6 Ассиметрия и эксцесс",
    "text": "12.6 Ассиметрия и эксцесс\n\n12.6.1 Ассиметрия\nАссиметрия (skewness) измеряет симметричность распределения. Положительный показатель ассиметрии (“Right-skewed” или positive skewness) означает, что хвосты с правой части распределения длиннее. Негативный показатель ассиметрии (“Left-skewed” или negative skewness) означает, что левый хвост длиннее.\n\n\nНапример, в психологии положительная ассиметрия встречается очень часто. Например, время реакции: оно ограничено снизу 0 мс (а по факту не меньше 100 мс - быстрее сигнал не успеет по нервной системе пройти до пальцев), а вот с другой стороны оно никак не ограничено. Испытуемый может на полчаса перед монитором затупить, ага.\n\n\n\n12.6.2 Эксцесс\nЭксцесс (kurtosis) - это мера “вытянутости” распределения:\n\nПоложительные показатели эксцесса означают “вытянутое” распределение, а отрицательные - “плоское”.\n\n\n12.6.3 Ассиметрия и эксцесс в R\nК сожалению, в базовом R нет функций для ассиметрии и эксцесса. Зато есть замечательный пакет psych (да-да, специально для психологов).\n\ninstall.packages(\"psych\")\n\n\nlibrary(\"psych\")\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\nВ нем есть функции skew() и kurtosi():\n\nskew(weight)\n\n[1] 3.874557\n\nkurtosi(weight)\n\n[1] 19.45699\n\n\nАссиметрия положительная, это значит что распределение выборки асимметричное, хвосты с правой части длиннее. Эксцесс значительно выше нуля - значит распределение довольно “вытянутое”."
  },
  {
    "objectID": "210-desc_stats.html#sec-summary",
    "href": "210-desc_stats.html#sec-summary",
    "title": "12  Описательная статистика",
    "section": "12.7 А теперь все вместе!",
    "text": "12.7 А теперь все вместе!\nВ базовом R есть функция summary(), которая позволяет получить сразу неплохой набор описательных статистик.\n\nsummary(weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0    61.0    81.0   112.3   108.0   900.0 \n\n\n\nФункция summary() - это универсальная (generic) функция. Это означает, что Вы можете ее применять для разных объектов и получать разные результаты. Попробуйте применить ее к векторам с разными типами данных и даже к дата.фреймам и дата.тейблам. Посмотрите, что получится.\n\nВ пакете psych есть еще и замечательная функция describe(), которая даст Вам еще больше статистик, включая ассиметрию и куртозис:\n\npsych::describe(weight)\n\n   vars   n   mean     sd median trimmed   mad min max range skew kurtosis   se\nX1    1 495 112.25 104.15     81   89.56 32.62   2 900   898 3.87    19.46 4.68\n\n\nДаже усеченное (trimmed) среднее есть (с trim = 0.1)! Все кроме se мы уже знаем. А про этот se узнаем немного позже.\nЭта функция хорошо работает в сочетании с group_by():\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(describe(Weight))\n\n# A tibble: 3 × 14\n  Gender  vars     n  mean    sd median trimmed   mad   min   max range  skew\n  <chr>  <dbl> <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Female     1   142  78.8  77.0     58    60.9  7.41    41   630   589  4.97\n2 Male       1   339 126.  111.      90   103.  23.7      2   900   898  3.76\n3 <NA>       1    14 129.  107.      94   115.  43.0     39   383   344  1.55\n# … with 2 more variables: kurtosis <dbl>, se <dbl>\n\n\nДругой интересный пакет для получения описательных статистик для всего датафрейма — skimr.\n\ninstall.packages(\"skimr\")\n\nЕго основная функция — skim(), выводит симпатичную сводную таблицу для датафрейма.\n\nskimr::skim(heroes)\n\n\nData summary\n\n\nName\nheroes\n\n\nNumber of rows\n734\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n1\n25\n0\n715\n0\n\n\nGender\n29\n0.96\n4\n6\n0\n2\n0\n\n\nEye color\n172\n0.77\n3\n23\n0\n22\n0\n\n\nRace\n304\n0.59\n5\n18\n0\n61\n0\n\n\nHair color\n172\n0.77\n3\n16\n0\n29\n0\n\n\nPublisher\n0\n1.00\n0\n17\n15\n25\n0\n\n\nSkin color\n662\n0.10\n3\n14\n0\n16\n0\n\n\nAlignment\n7\n0.99\n3\n7\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\n…1\n0\n1.00\n366.50\n212.03\n0.0\n183.25\n366.5\n549.75\n733\n▇▇▇▇▇\n\n\nHeight\n217\n0.70\n186.73\n59.25\n15.2\n173.00\n183.0\n191.00\n975\n▇▁▁▁▁\n\n\nWeight\n239\n0.67\n112.25\n104.15\n2.0\n61.00\n81.0\n108.00\n900\n▇▁▁▁▁\n\n\n\n\n\nЗдесь количество и доля пропущенных значений, среднее, стандартное отклонение, минимальное и максимальное значение (p0 и p100 соответственно), квартили. Ну и вишенкой на торте выступает маленькая гистограмма для каждой колонки!\nКроме того, skimr адаптирован под tidyverse. В нем можно выбирать колонки с помощью tidyselect (@ref(tidyselect)) прямо внутри функции skim().\n\nheroes %>%\n  skimr::skim(ends_with(\"color\"))\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n734\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEye color\n172\n0.77\n3\n23\n0\n22\n0\n\n\nHair color\n172\n0.77\n3\n16\n0\n29\n0\n\n\nSkin color\n662\n0.10\n3\n14\n0\n16\n0\n\n\n\n\n\nА еще можно сочетать с группировкой с помощью group_by().\n\nheroes %>%\n  group_by(Gender) %>%\n  skimr::skim(ends_with(\"color\"))\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n734\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\n________________________\n\n\n\nGroup variables\nGender\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nGender\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEye color\nFemale\n41\n0.80\n3\n23\n0\n14\n0\n\n\nEye color\nMale\n121\n0.76\n3\n12\n0\n18\n0\n\n\nEye color\nNA\n10\n0.66\n3\n23\n0\n7\n0\n\n\nHair color\nFemale\n38\n0.81\n3\n16\n0\n18\n0\n\n\nHair color\nMale\n123\n0.76\n3\n16\n0\n23\n0\n\n\nHair color\nNA\n11\n0.62\n4\n14\n0\n10\n0\n\n\nSkin color\nFemale\n186\n0.07\n4\n6\n0\n7\n0\n\n\nSkin color\nMale\n449\n0.11\n3\n14\n0\n14\n0\n\n\nSkin color\nNA\n27\n0.07\n4\n4\n0\n2\n0\n\n\n\n\n\n###Описательных статистик недостаточно {#sec-datasaurus}\nЯ в тайне от Вас загрузил данные в переменную xxx (можете найти этот набор данных здесь, если интересно). Выглядят они примерно так:\n\nhead(xxx)\n\n# A tibble: 6 × 2\n      x     y\n  <dbl> <dbl>\n1  55.4  97.2\n2  51.5  96.0\n3  46.2  94.5\n4  42.8  91.4\n5  40.8  88.3\n6  38.7  84.9\n\nstr(xxx)\n\nspc_tbl_ [142 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ x: num [1:142] 55.4 51.5 46.2 42.8 40.8 ...\n $ y: num [1:142] 97.2 96 94.5 91.4 88.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   x = col_double(),\n  ..   y = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nНадеюсь, Вы уже понимаете, как это интерпретировать - два столбца с 142 числами каждый. Представьте себе, как выглядят эти точки на плоскости, если каждая строчка означают координаты одной точки по осям x и y (это называется диаграмма рассеяния, точечная диаграмма или scatterplot).\n\n\n\n\n\nПрименим разные функции, которые мы выучили:\n\nmean(xxx$x)\n\n[1] 54.26327\n\nmean(xxx$y)\n\n[1] 47.83225\n\nmedian(xxx$x)\n\n[1] 53.3333\n\nmedian(xxx$y)\n\n[1] 46.0256\n\n\nСредние и медианы примерно одинаковые, при этом по х они около 53-54, а по у - примерно 46-47. Попытайтесь представить это. Идем дальше:\n\nsd(xxx$x)\n\n[1] 16.76514\n\nsd(xxx$y)\n\n[1] 26.9354\n\n\nПохоже, разброс по у несколько больше, верно?\n\nskew(xxx$x)\n\n[1] 0.2807568\n\nskew(xxx$y)\n\n[1] 0.2472603\n\nkurtosi(xxx$x)\n\n[1] -0.2854912\n\nkurtosi(xxx$y)\n\n[1] -1.063552\n\n\nПохоже, оба распределения немного право-ассиметричны и довольно “плоские”.\nДавайте еще посчитаем коэффициент корреляции (correlation coefficient). Мы про него будем говорить позже гораздо подробнее. Пока что нам нужно знать, что она говорит о линейной связи двух переменных. Если коэффициент корреляции положительный (максимум равен 1), то чем больше х, тем больше у. Если отрицательный (минимум равен -1), то чем больше х, тем меньше у. Если же коэффициент корреляции равна нулю, то такая линейная зависимость отсутствует.\n\ncor(xxx$x, xxx$y)\n\n[1] -0.06447185\n\n\nКоэффициент корреляции очень близка к нулю (делайте выводы и представляйте).\nДавайте напоследок воспользуемся функцией describe() из psych:\n\npsych::describe(xxx)\n\n  vars   n  mean    sd median trimmed   mad   min   max range skew kurtosis\nx    1 142 54.26 16.77  53.33   53.69 15.97 22.31 98.21 75.90 0.28    -0.29\ny    2 142 47.83 26.94  46.03   46.90 30.79  2.95 99.49 96.54 0.25    -1.06\n    se\nx 1.41\ny 2.26\n\n\n\nskimr::skim(xxx)\n\n\nData summary\n\n\nName\nxxx\n\n\nNumber of rows\n142\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nx\n0\n1\n54.26\n16.77\n22.31\n44.10\n53.33\n64.74\n98.21\n▅▇▇▅▂\n\n\ny\n0\n1\n47.83\n26.94\n2.95\n25.29\n46.03\n68.53\n99.49\n▇▇▇▅▆\n\n\n\n\n\nГотовы узнать, как выглядят эти данные на самом деле?!\n\n\nЖмите сюда если готовы!\n\n\n\n\n\n\n\nИз этого можно сделать важный вывод: не стоит слепо доверять описательным статистикам. Нужно визуализировать данные, иначе можно попасть в такую ситуацию в реальности. По словам знаменитого статитстика Джона Тьюки, величайшая ценность картинки в том, что она заставляет нас заметить то, что мы не ожидали заметить. Поэтому графики — это не просто метод коммуникации — представления ваших результатов сообществу в понятном виде (хотя и это, конечно, тоже), но и сам по себе очень важный метод анализа данных."
  },
  {
    "objectID": "220-base_viz.html",
    "href": "220-base_viz.html",
    "title": "13  Встроенные функции для графиков",
    "section": "",
    "text": "В R есть достаточно мощный встроенный инструмент для визуализации. Я приведу три простых примера. Во-первых, это та самая диаграмма рассеяния. Здесь все просто: функция plot(), вектора x и у, дополнительные параметры для цвета, размера, формы точек.\nДля примера возьмем датасет heroes с Height по оси x и Weight по оси y.\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nplot(heroes$Height, heroes$Weight)\n\n\n\n\n\nМежду прочим, функция plot() - это тоже универсальная (generic) функция, как и summary(). В качестве аргумента можете ей скормить просто один вектор, матрицу, датафрейм. Более того, многие пакеты добавляют новые методы plot() для новых объектов из этих пакетов.\n\nДругая распространенная функция — hist() — гистограмма (histogram):\n\nweight <- heroes %>%\n  drop_na(Weight) %>%\n  pull(Weight)\nhist(weight)\n\n\n\n\nНу и закончим на суперзвезде прошлого века под названием ящик с усами (boxplot with whiskers):\n\nboxplot(Weight ~ Gender, heroes)\n\n\n\n\nЗдесь мы использовали уже знакомый нам класс формул. Они еще будут нам встречаться дальше, обычно они используются следующим образом: слева от ~ находится зависимая переменная, а справа - “предикторы”. Эта интуиция работает и здесь: мы хотим посмотреть, как различается вес в зависимости от пола."
  },
  {
    "objectID": "230-ggplot2.html#sec-grammar_of_graphics",
    "href": "230-ggplot2.html#sec-grammar_of_graphics",
    "title": "14  Грамматика графики ggplot2",
    "section": "14.1 История грамматики графики",
    "text": "14.1 История грамматики графики\nВстроенные возможности для визуализации в R довольно обширны, но дополнительные пакеты значительно ее расширяют. Среди этих пакетов, есть один, который занимает совершенно особенное место – ggplot2.\nggplot2 — это не просто пакет, который рисует красивые графики. Красивые графики можно рисовать и в базовом R. Чтобы понять, почему пакет ggplot2 занимает особенное место среди пакетов для визуализации (и не только среди пакетов для R, а вообще!), нужно расшифровать gg в его названии. gg означает грамматику графики (Grammar of Graphics), язык для описания графиков, изложенный в одноименной книге Леланда Уилкинсона (Wilkinson 2005).\nГрамматика графики позволяет описывать графики не в терминах типологии (вот есть пайчарт, есть барплот, есть гистограмма, а есть ящик с усами), а с помощью специального разработанного языка. Этот язык позволяет с помощью грамматики и небольшого количества “слов” языка описывать и создавать практически любые графики и даже придумывать новые! Это дает огромную свободу в создании именно той визуализации, что необходима для текущей задачи.\nХэдли Уикхэм (да, снова он) немного дополнил идею грамматики графики в статье “A Layered grammar of graphics” (Wickham 2010), которую сопроводил пакетом ggplot2 с реализацией идей Уилкинсона и своих."
  },
  {
    "objectID": "230-ggplot2.html#sec-gg_base",
    "href": "230-ggplot2.html#sec-gg_base",
    "title": "14  Грамматика графики ggplot2",
    "section": "14.2 Основы грамматики графики",
    "text": "14.2 Основы грамматики графики\nКаждый график состоит из одного или нескольких слоев (layers). Если слоев несколько, то они располагаются один над другим, при этом верхние слои “перекрывают” нижние, примерно как это происходит в программах вроде Adobe Photoshop. У каждого слоя есть три обязательных элемента: данные (data), геом (geom), эстетики (aestetics); и два вспомогательных: статистические трансформации (stat). и регулировка положения (position adjustment).\n\n\nДанные (data). Собственно, сами данные в виде датафрейма, используемые в данном слое.\nГеом (geom). Геом — это сокращение от “геометрический объект”. Собственно, в какой геометрический объект мы собираемся превращать данные. Например, в точки, прямоугольники или линии.\nОтображение (mapping). Эстетические отображения или просто эстетики (aestetics) — это набор правил, как различные переменные превращаются в визуальные особенности геометрии. Без эстетик остается непонятно, какие именно колонки в используемом датафрейме превращаются в различные особенности геомов: позицию, размер, цвет и т.д. У каждой геометрии свой набор эстетик, но многие из них совпадают у разных геомов, например, x, y, colour, fill, size. Без некоторых эстетик геом не будет работать. Например, геометрия в виде точек не будет работать без двух координат этих точек (x и y). Другие эстетики необязательны и имеют значения по умолчанию. Например, по умолчанию точки будут черными, но можно сделать их цвет зависимым от выбранной колонки в датафрейме с помощью эстетики colour.\nСтатистические трансформации (stat). Название используемой статистической трансформации (или просто — статистики). Да, статистические трансформации можно делать прямо внутри ggplot2! Это дает дополнительную свободу в выборе инструментов, потому что обычно те же статистические трансформации можно сделать вне ggplot2 в процессе препроцессинга. Формально, статистические трансформации — это обязательный элемент геома, но если вы не хотите преобразовывать данные, то можете выбрать “identity” преобразование, которое оставляет все как есть. В ggplot2 у каждого геома есть статистика по умолчанию, а у каждой статистики - свой геом по умолчанию. И не всегда статистика по умолчанию — это “identity” статистика. Например, для барплота (geom_barplot()) используется статистика “count” 1, которая считает частоты, ведь именно частоты затем трансформируются в высоту барплотов.\n\n\n\nРегулировка положения (position adjustment). Регуляровка положения — это небольшое улучшение позиции геометрий для части элементов. Например, можно добавить немного случайного шума (“jitter”) в позицию точек, чтобы они не перекрывали друг друга. Или “раздвинуть” (“dodge”) два барплота, чтобы один не загораживал другой. Как и в случае со статистическими трансформациями, в большинстве случаев значение по умолчанию — “identity”.\n\nКроме слоев, у графика есть:\n\nКоординатная система (coord). Если мы задали координаты, то нам нужно задать и координатную плоскость, верно? Конечно, в большинстве случаев используется декартова система координат (Cartesian coordinate system) 2, т.е. стандартная прямоугольная система координат, но можно использовать и другие, например, полярную систему координат или картографическую проекцию.\n\n\n\nШкалы (scales). Шкалы задают то, как именно значения превращаются в эстетики. Например, если мы задали, что разные значения в колонке будут влиять на цвет точки, то какая именно палитра будет использоваться? В какие конкретно цвета будут превращаться числовые, логические или строковые значения в колонке? В ggplot2 есть правила по умолчанию для всех эстестик, и они отличные, но самостоятельная настройка шкал может значительно улучшить график.\nФасетки (facets). Фасетки — это одно из нововведений Уикхэма в грамматику графики. Фасетки повзоляют разбить график на множество похожих, задав переменную, по которой график будет разделен. Это очень напоминает использование группировки с помощью group_by().\nТема (theme). Тема — это зрительное оформление “подложки” графика, не относящийся к содержанию графика: размер шрифта, цвет фона, размер и цвет линий на фоне и т.д. и т.п. В ggplot2 есть несколько встроенных тем, а также есть множество пакетов, которые добавляют дополнительные темы. Кроме того, их можно настраивать самостоятельно!\nЗначения по умолчанию (defaults). Если в графике используется несколько слоев, то часто все они используют одни и те же данные и эстетики. Можно задать данные и эстетики по умолчанию для всего графика, чтобы не повторять код."
  },
  {
    "objectID": "230-ggplot2.html#sec-gg_0",
    "href": "230-ggplot2.html#sec-gg_0",
    "title": "14  Грамматика графики ggplot2",
    "section": "14.3 Пример №0: пайчарт с распределение по полу",
    "text": "14.3 Пример №0: пайчарт с распределение по полу\nСейчас мы попробуем сделать простой пример в ggplot2, похожий на пример, который использует в своей книге Леланд Уилкинсон, чтобы показать мощь грамматики графики (Wilkinson 2005). Приготовьтесь, этот пример перевернет ваши представления о графиках!\nНо сначала взглянем на структуру кода в ggplot().\n\nКак видно, код чем-то напоминает стандартный код tidyverse, но с + вместо пайпов. Когда был написан ggplot2, Хэдли Уикхэм еще не знал про %>% из magrittr, хотя по смыслу + означает примерно то же самое.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nИтак, запустим функцию ggplot(), задав наш тиббл heroes в качестве данных.\n\nggplot(data = heroes)\n\n\n\n\nМы ничего не получили! Это естественно, ведь мы задали только данные по умолчанию, но не задали геометрию и эстетики.\nФункция ggplot() не просто отрисовывает график, эта функция создает объект класса ggplot, который можно сохранить и модифицировать в дальнейшем:\n\nalmost_empty_ggplot <- ggplot(data = heroes)\nalmost_empty_ggplot\n\n\n\n\nВозьмем geom_bar() для отрисовки барплота. В качестве эстетик поставим x = Gender и fill = Gender. Поскольку это эстетики, они обозначаются внутри функции параметра mapping = aes() или просто внутри функции aes(). По умолчанию, geom_bar() имеет статистику “count”, что нас полностью устраивает: geom_bar() сам посчитает табличу частот и использует значения Gender для обозначения позиций и заливки, а посчитанные частоты будет использовать для задания высоты столбцов.\n\nggplot(data = heroes) +\n  geom_bar(aes(x = Gender, fill = Gender))\n\n\n\n\nСейчас мы сделаем один хитрый трюк: поставим значение эстетики x = \"\", чтобы собрать все столбики в один.\n\nggplot(data = heroes) +\n  geom_bar(aes(x = \"\", fill = Gender))\n\n\n\n\nПолучилось что-то не очень симпатичное, но вполне осмысленное: доли столбца обозначают относительную частоту.\nМожно настроить общие параметры геома, не зависящие от данных. Это нужно делать вне функции aes(), но внутри функции для геома.\n\nggplot(data = heroes) +\n  geom_bar(aes(x = \"\", fill = Gender), width = .2)\n\n\n\n\n\nКазалось бы, причем здесь Minecraft?\n\nА теперь внимание! Подумайте, какого действия нам не хватает, чтобы из имеющегося графика получить пайчарт?\n\nggplot(data = heroes) +\n  geom_bar(aes(x = \"\", fill = Gender)) +\n  coord_polar(theta = \"y\")\n\n\n\n\nНам нужно было всего-лишь поменять систему координат с декартовой на полярную (круговую)! Иначе говоря, пайчарт - это барплот в полярной системе координат.\nИменно в этом основная сила грамматики графики и ее реализации в ggplot2 — вместо того, чтобы описывать и рисовать огромное количество типов графиков, можно описать практически любой график через небольшой количество элементарных элементов и правила их соединения.\nПолучившийся пайчарт осталось подретушировать, убрав все лишние элементы подложки с помощью самой минималистичной темы theme_void() и добавив название графика:\n\nggplot(data = heroes) +\n  geom_bar(aes(x = \"\", fill = Gender)) +\n  coord_polar(theta = \"y\") +\n  theme_void() +\n  labs(title = \"Gender distributions for superheroes\")\n\n\n\n\nЭто был интересный, но немного шуточный пример. Все-таки пайчарт — это довольно спорный способ визуализировать данные, вызывающий много вполне справедливой критики. Поэтому сейчас мы перейдем к гораздо более реалистичному примеру."
  },
  {
    "objectID": "230-ggplot2.html#sec-gg_1",
    "href": "230-ggplot2.html#sec-gg_1",
    "title": "14  Грамматика графики ggplot2",
    "section": "14.4 Пример №1: Education and IQ meta-analysis",
    "text": "14.4 Пример №1: Education and IQ meta-analysis\nДля этого примера мы возьмем мета-анализ связи количества лет обучения и интеллекта: “How Much Does Education Improve Intelligence? A Meta-Analysis” (Ritchie и Tucker-Drob 2018). Мета-анализ — это группа статистических методов, которые позволяют объединить результаты нескольких исследований с похожим планом исследованием и тематикой, чтобы посчитать средний эффект между несколькими статьями сразу.\nДанные и скрипт для анализа данных в этой статье находятся в открытом доступе: https://osf.io/r8a24/\nПолный текст статьи доступен по ссылке.\nСуществует положительная корреляция между количеством лет, который человек потратил на обучение, и интеллектом. Это может объясняться по-разному: как то, что обучение повышает интеллект, и как то, что люди с высоким интеллекте стремятся получать больше образования. Напрямую в эксперименте это проверить нельзя, поэтому есть несколько квази-экспериментальных планов, которые косвенно указывают на верность той или иной гипотезу. Например, если в стране изменилось количество лет обязательного школьного образования, то повлияло ли это на интеллект целого поколения? Или все-таки дело в Моргенштерне\n\nДанная картинка показывает, насколько размер эффекта (выраженный в баллах IQ) зависит от того, какой средний возраст участвоваших в исследовании испытуемых.\nКаждая точка на этом графике — это отдельное исследование, положение по оси x — средний возраст респондентов, а положение по оси y - средний прирост интеллекта согласно исследованию. Размер точки отражает “точность” исследования (грубо говоря, чем больше выборка, тем больше точка). Два графика обозначают два квазиэкспериментальных плана.\nМы сфокусируемся на нижней картинке с “Policy change” — это как раз исследования, в которых изучается изменения интеллекта в возрастных группах после изменения количества лет обучения в школе.\nМы полностью воспроизведем код построчно, посмотрим, как эта картинка создавалась шаг за шагом.\nЗаметьте, данный датасет использует немного непривычный для нас формат хранения данных. Попытайтесь самостоятельно прочитать его.\n\nlibrary(tidyverse)\ndf <- read_tsv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/meta_dataset.txt\")\n\nRows: 142 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (2): Country, Design\ndbl (15): Study_ID, Data_ID, k, n, outcome_test_cat, Effect_size, SE, Outcom...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nДавайте посмотрим, как устроен датафрейм df:\n\ndf\n\n# A tibble: 142 × 17\n   Study_ID Data_ID     k Country     n Design     outco…¹ Effec…²    SE Outco…³\n      <dbl>   <dbl> <dbl> <chr>   <dbl> <chr>        <dbl>   <dbl> <dbl>   <dbl>\n 1      1         1     4 UK        483 Control P…       0 0.778   0.239    79.1\n 2      1         1     4 UK        290 Control P…       1 0.0771  0.414    83.3\n 3      1         1     4 UK        290 Control P…       1 0.427   0.410    83.3\n 4      1         1     4 UK        288 Control P…       1 0.00519 0.408    83.3\n 5      1         2    13 UK       1017 Control P…       0 1.62    0.327    69.5\n 6      1         2    13 UK       1022 Control P…       1 0.915   0.442    69.5\n 7      1         2    13 UK       1021 Control P…       1 0.305   0.441    69.5\n 8      1         2    13 UK        981 Control P…       1 0.719   0.466    69.5\n 9      1.5       2    13 UK       1024 Control P…       1 1.70    0.403    69.5\n10      1.5       2    13 UK       1023 Control P…       1 1.78    0.400    69.5\n# … with 132 more rows, 7 more variables: quasi_age <dbl>,\n#   cpiq_early_age <dbl>, cpiq_age_diff <dbl>, ses_funnel <dbl>,\n#   published <dbl>, Male_only <dbl>, Achievement <dbl>, and abbreviated\n#   variable names ¹​outcome_test_cat, ²​Effect_size, ³​Outcome_age\n\n\nКаждая строчка — это результат отдельного исследования, при этом одна статья может включать несколько исследований,\nВ дальнейшем мы будем использовать код авторов статьи и смотреть, строчка за строчкой, как он будет работать.\n\ncpiq <- subset(df, subset=(Design==\"Control Prior IQ\"))\npoli <- subset(df, subset=(Design==\"Policy Change\"))\n\nАвторы исследования используют subset(), это функция базового R, принцип которой очень похож на filter() 3.\nИтак, начнем рисовать сам график. Сначала иницируем объект ggplot с данными poli по умолчанию.\n\nggplot(data=poli) \n\n\n\n\nТеперь добавим в качестве эстетик по умолчанию координаты: aes(x=Outcome_age, y=Effect_size).\n\nggplot(aes(x=Outcome_age, y=Effect_size), data=poli) \n\n\n\n\nЧто изменилось? Появилась координатная ось и шкалы. Заметьте, масштаб неслучаен: он строится на основе разброса значений в выбранных колонках. Однако этого недостаточно для отрисовки графика, нехватает геометрии: нужно задать, в какую географическую сущность отобразятся данные.\n\nggplot(aes(x=Outcome_age, y=Effect_size), data=poli) +\n        geom_point() \n\n\n\n\nГотово! Это и есть основа картинки. Добавляем размер:\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point() \n\n\n\n\nПеред нами возникла проблема оверплоттинга: некоторые точки перекрывают друг друга, поскольку имеют очень близкие координат. Авторы графика решают эту проблему очевидным способом: добавляют прозрачности точкам. Заметьте, прозрачность задается для всех точек одним значением, поэтому параметр alpha задается вне функции aes().\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55) \n\n\n\n\nСовершенно так же задается и цвет. Он задается одинаковым для всех точек с помощью HEX-кода.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\")\n\n\n\n\nТеперь добавим регрессионную прямую с доверительными интервалами на график. Это специальный геом geom_smooth() со специальной статистикой, который займет второй слой данного графика.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: size\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nПо умолчанию geom_smooth() строит кривую линию. Поставим method = \"lm\" для прямой.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth(method=\"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: size\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nТеперь нужно поменять цвет: ярко синий цвет, используемый по умолчанию здесь попросту мешает восприятию графика.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: size\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nАвторы графика перекрашивают серую полупрозначную область тоже. В этом случае используется параметр fill =, а не colour =, но цвет используется тот же.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: size\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nРегрессионную линию авторы немного утоньшают с помощью параметра size =.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nЧтобы сместить фокус в сторону точек, авторы добавляют прозрачности для всего geom_smooth().\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nНа шкале присутствует 0, и по умолчанию он никак не обозначен. Это легко исправить с помощью вспомогательного геома geom_hline().\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0) + \n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nОттенить эту линию можно, сделав ее пунктирной.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nАвторы графика вручную задают деления шкалы по оси x.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nС помощью функции guides() убирают легенду с картинки.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25)\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nСледующим этапом авторы добавляют подписи шкал и название картинки. Обратите внимание на \\n внутри подписи к оси y, которая задает перенос на следующую строку.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + ggtitle(\"Policy Change\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nТеперь пришло время сделать график более красивым и понятным с помощью изменения подложки, т.е. работы с темой графика. Здесь тема задается сначала как theme_bw() — встроенная в ggplot2 минималистичная тема, а потом через функцию theme(), через которую можно управлять конкретными элементами темы. Здесь это сделано, чтобы передвинуть название графика к центру.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=poli) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + ggtitle(\"Policy Change\")+ \n        theme(plot.title = element_text(hjust=0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nГотово! Мы полностью воспроизвели график авторов статьи с помощью их открытого кода.\nЕсли вы помните, то в изначальном графике было две картинки. Авторы делают их отдельно, с помощью почти идентичного кода. Нечто похожее можно сделать по-другому, применяя фасетки.\nДля этого мы возьмем неотфильтрованный датасет df, а с помощью колонки Design, на основании которой разделялся датасет для графиков, произведем разделение графиков внутри самого ggplot объекта. Для этого нам понадобится функция facet_wrap(), в которой с помощью формулы можно задать колонки, по которым будут разделены картинки по вертикали (слева от ~) и горизонтально (справа от ~). Пробуем разделить графики горизонтально:\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=df) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + ggtitle(\"Policy Change\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_wrap(~Design)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nЗдесь становится очевидно, почему авторы не включали данные \"School Age Cutoff\" третьим графиком: средний возраст участников этих исследований сильно отличается.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=df %>% filter(Design != \"School Age Cutoff\")) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + ggtitle(\"Policy Change\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_wrap(~Design)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nТеперь поставим два графика друг над другом, поместив Design слева от ~ внутри facet_wrap(). Справа нужно добавить точку.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=df %>% filter(Design != \"School Age Cutoff\")) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + ggtitle(\"Policy Change\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_grid(Design~.)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nТеперь нужно изменить подписи.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2)), data=df %>% filter(Design != \"School Age Cutoff\")) +\n        geom_point(alpha=.55, colour=\"#BA1825\") +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=F) +\n        geom_smooth(method=\"lm\", colour=\"#BA1825\",fill=\"#BA1825\",size=.5, alpha=.25) + \n    ggtitle(\"Effect of education as a function of age at the outcome test\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_grid(Design~.)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nЧтобы акцентировать графики, можно раскрасить их в разные цвета в дополнение к фасеткам. Для этого мы переносим colour = и fill = из параметров соответствующих геомов внутрь эстетик и делаем зависимыми от Design. Поскольку эти эстетики (точнее, colour =) одинаковы заданы для двух геомов (geom_point() и geom_smooth()), то мы спокойно можем вынести их в эстетики по умолчанию — в параметры aes() внутри ggplot().\nПри этом сразу выключим легенды для новых эстетик, потому они избыточны.\n\nggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2), colour = Design, fill = Design), data=df %>% filter(Design != \"School Age Cutoff\")) +\n        geom_point(alpha=.55) +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=FALSE, colour = FALSE, fill = FALSE) +\n        geom_smooth(method=\"lm\", size=.5, alpha=.25) + \n    ggtitle(\"Effect of education as a function of age at the outcome test\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_grid(Design~.)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nСлишком блеклая палитра? Не беда, можно задать палитру вручную! В ggplot2 встроены легендарные Brewer’s Color Palettes, которыми мы и воспользуемся.\nФункции для шкал устроены интересным образом: они состоят из трех слов, первое из которых scale_*_*(), второе — эстетика, например, scale_color_*(), а последнее слово — тип самой шкалы, в некоторых случаях - специальное название для используемой шкалы, как и в случае с scale_color_brewer().\n\nmeta_2_gg <- ggplot(aes(x=Outcome_age, y=Effect_size, size=1/(SE^2), colour = Design, fill = Design), data=df %>% filter(Design != \"School Age Cutoff\")) +\n        geom_point(alpha=.55) +\n        geom_hline(yintercept=0, linetype=\"dotted\") + \n        theme_bw() + \n        scale_x_continuous(breaks=c(20,30,40,50,60,70,80)) +\n        xlab(\"Age at outcome test (years)\") +\n        ylab(\"Gain for 1 year of education\\n(IQ points)\") +\n        guides(size=FALSE, colour = FALSE, fill = FALSE) +\n        geom_smooth(method=\"lm\", size=.5, alpha=.25) + \n    ggtitle(\"Effect of education as a function of age at the outcome test\")+ \n        theme(plot.title = element_text(hjust=0.5)) +\n    facet_grid(Design~.)+\n    scale_colour_brewer(palette = \"Set1\")+\n    scale_fill_brewer(palette = \"Set1\")\nmeta_2_gg\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "230-ggplot2.html#sec-gg_ext",
    "href": "230-ggplot2.html#sec-gg_ext",
    "title": "14  Грамматика графики ggplot2",
    "section": "14.5 Расширения ggplot2",
    "text": "14.5 Расширения ggplot2\nggplot2 стал очень популярным пакетом и быстро обзавелся расширениями - пакетами R, которые являются надстройками над ggplot2. Эти расширения бывают самого разного рода, например, добавляющие дополнительные геомы или просто реализующие отдельные типы графиков на языке ggplot2.\nЯ рекомендую посмотреть самостоятельно галерею расширений ggplot2: https://exts.ggplot2.tidyverse.org/gallery/\nДля примера мы возьмем пакет hrbrthemes, который предоставляет дополнительные темы для ggplot2, компоненты тем и шкалы.\n\ninstall.packages(\"hrbrthemes\")\n\n\nlibrary(hrbrthemes)\nmeta_2_gg +\n  theme_ipsum()\n\n\n\n\n\nRitchie, Stuart, и Elliot Tucker-Drob. 2018. «How Much Does Education Improve Intelligence? A Meta-Analysis». Psychological Science 29 (июнь): 095679761877425. https://doi.org/10.1177/0956797618774253.\n\n\nWickham, Hadley. 2010. «A layered grammar of graphics». Journal of Computational and Graphical Statistics 19 (1): 3–28. https://doi.org/10.1198/jcgs.2009.07098.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics (Statistics and Computing). Berlin, Heidelberg: Springer-Verlag."
  },
  {
    "objectID": "240-dynamic_viz.html#html_w",
    "href": "240-dynamic_viz.html#html_w",
    "title": "15  Динамические визуализации в R",
    "section": "15.1 Интерфейс для JavaScript фреймворков: пакет htmlwidgets",
    "text": "15.1 Интерфейс для JavaScript фреймворков: пакет htmlwidgets\nДо этого мы делали только статические картинки, но в R можно делать динамические визуализации с интерактивными элементами! Делаются такие визуализации на основе JavaScript, в первую очередь, на основе фреймворка D3.js. Существует пакет для R htmlwidgets, который предоставляет интерфейс для работы с JavaScript визуализациями из R и вставлять их в RMarkdown или Quarto HTML-документы и веб-приложения Shiny. htmlwidgets — это пакет, в первую очередь, для разработчиков R пакетов, которые делают на его основе очень простые и удобные в использовании R пакеты для создания динамических визуализаций и прочих динамических элементов."
  },
  {
    "objectID": "240-dynamic_viz.html#sec-plotly",
    "href": "240-dynamic_viz.html#sec-plotly",
    "title": "15  Динамические визуализации в R",
    "section": "15.2 Динамические визуализации в plotly",
    "text": "15.2 Динамические визуализации в plotly\nОдин из самых распространенных средств для динамических визуализаций — это пакет plotly.\n\ninstall.packages(\"plotly\")\n\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nЕсть два базовых способа использовать plotly в R. Первый — это просто оборачивать готовые графики ggplot2 с помощью функции ggplotly().\n\nggplotly(meta_2_gg)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nНе всегда это получается так, как хотелось бы, но простота этого способа подкупает: теперь наведение на курсора на точки открывает небольшое окошко с дополнительной информацией о точке (конечно, если вы читаете эту книгу в PDF или ePUB, то этого не увидите).\nДругой способ создания графиков — создание вручную с помощью plot_ly(). Такой способ частично напоминает ggplot2 использованием пайпов (обычных %>% или |>, а не +), задание эстетик здесь происходит с помощью ~.\n\nplot_ly(poli, \n        x = ~Outcome_age, \n        y = ~Effect_size, \n        size = ~1/(SE^2), \n        color = ~Effect_size, \n        sizes = c(40, 400),\n        text = ~paste(\"N: \", n, '<br>Country:', Country)) %>%\n  add_markers()\n\nWarning: `line.width` does not currently support multiple values."
  },
  {
    "objectID": "240-dynamic_viz.html#sec-html_other",
    "href": "240-dynamic_viz.html#sec-html_other",
    "title": "15  Динамические визуализации в R",
    "section": "15.3 Другие пакеты для динамической визуализации",
    "text": "15.3 Другие пакеты для динамической визуализации\nКроме plotly есть и множество других HTML-виджетов для динамической визуализации. Я рекомендую посмотреть их самостоятельно на http://gallery.htmlwidgets.org/\nВыделю некоторые из них:\n\necharts4r — один из основных конкурентов для plotly. Симпатичный, работает довольно плавно, синтаксис тоже пытается вписаться в логику tidyverse.\nleaflet — основной (но не единственный!) пакет для работы с картами. Leaflet — это очень популярная библиотека JavaScript, используемая во многих веб-приложениях, а пакет leaflet - это довольно понятный интерфейс к ней с широкими возможностями.\nnetworkD3 — пакет для интерактивной визуализации сетей. Подходит для небольших сетей."
  },
  {
    "objectID": "250-rmarkdown.html#sec-rmd_what",
    "href": "250-rmarkdown.html#sec-rmd_what",
    "title": "16  R Markdown",
    "section": "16.1 Что такое R Markdown",
    "text": "16.1 Что такое R Markdown\nПосле подсчета описательных статитистик, создания графиков и, в особенности, интерактивных визуализаций, возникает вопрос о том, как представить полученные результаты.\nR Markdown представляет такую возможность. С помощью R Markdown в документе можно совмещать код, результаты его исполнения и написанный текст. Кроме того, можно вставлять картинки, ссылки, видео и многое другое. В чем-то R Markdown напоминает Jupyter Notebook знакомый всем питоноводом, но это сходство, скорее, функциональное (и то, и то позволяет превращать сухой текст скрипта в красивый документ), их устройство значительно различается.\nR Markdown представляет собой текстовый документ специального формата .Rmd, который можно скомпилировать в самые различные документы:\n\nДокументы в форматах Word, ODT, RTF, PDF (с использованием LaTeX), HTML, в том числе:\n\nОнлайн-книги (bookdown)\nНаучные статьи (papaja)\n\nПрезентации в виде HTML (ioslides, Slidy, revealjs, rmdshower, Beamer)\nВеб-сайты (blogdown)\nДашборды (flexdashboard)\n\nФормат вывода легко настроить и поменять по ходу работы, что позволяет гибко изменять формат документа на выходе."
  },
  {
    "objectID": "250-rmarkdown.html#sec-rmd_begin",
    "href": "250-rmarkdown.html#sec-rmd_begin",
    "title": "16  R Markdown",
    "section": "16.2 Начало работы в R Markdown",
    "text": "16.2 Начало работы в R Markdown\nДля работы с R Markdown у RStudio есть специальные инструменты, которые позволяют не только удобно писать и компилировать R Markdown документы, но и превращают R Markdown в удобную среду для работы с R вместо обычных R-скриптов.\nЧтобы начать работать с R Markdown, нужно создать новый .Rmd файл с помощью File - New File - R Markdown... Перед вами появится меню выбора формата R Markdown документа, названия и имени автора.\n\n\n\nМеню выбора формата R Markdown документа\n\n\nВыбирайте что угодно, все это можно потом изменить вручную.\nЕсли пакет rmarkdown у вас еще не установлен, то он будет автоматически установлен. Кроме того, если вы выбрали в качестве формата PDF (презентацию или документ), то вам понадобится еще установить LaTeX на компьютер. Это тоже можно сделать с помощью специального пакета:\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()  # install TinyTeX\n\n.Rmd файл, который вы создадите таким образом, будет создан из шаблона, который демонстрирует основной функционал R Markdown. В отличие от работы с R скриптом, перед вами будет немного другой набор кнопок. Самая важная из новых кнопок — это кнопка Knit (с клубком и спицей рядом), нажав на которую, начнется “вязание” (knitting) финального документа, то есть его компиляция. Если компиляция завершится успешно, то перед вами появится скомпилированный документ в том формате, который вы выбрали."
  },
  {
    "objectID": "250-rmarkdown.html#sec-rmd_str",
    "href": "250-rmarkdown.html#sec-rmd_str",
    "title": "16  R Markdown",
    "section": "16.3 Структура R Markdown документа",
    "text": "16.3 Структура R Markdown документа\nR Markdown документ состоит из трех базовых элементов:\n\nYAML-шапки 1\nТекста с использованием разметки Markdown\nЧанков (chunks) с кодом\n\nРазберем их по порядку.\n\nYAML-шапка находится в самом верху документа и отделена тремя дефисами (---) сверху и снизу. В нем содержится, во-первых, мета-информация о документе, которая будет отображена на титульном листе/слайде, во-вторых, информация о формате документа, который будет “связан”. Пример YAML-шапки:\n\n\n---\ntitle: \"Классное название для документа\"\nauthor: \"Поздняков Иван\"\ndate: \"15 11 2020\"\noutput: html_document\n---\n\nТекст с использование синтаксиса Markdown идет сразу после YAML-шапки и составляет основную часть .Rmd документа. Markdown (не путать с R Markdown!) — это популярный и очень удобный язык разметки. Markdown используется повсюду: в ReadMe страницах на GitHub, как способ ведения записей во многих программах для заметок и даже в Telegram! Например, вот так можно задавать полужирный шрифт и курсив:\n\n\nВот так мы делаем **полужирный**, а вот так мы делаем *курсив.*\nВ результате мы получим следующую строчку:\nВот так мы делаем полужирный, а вот так мы делаем курсив.\nДалее мы разберем подробнее синтаксис Markdown.\n\nЧанки с кодом содержат в себе код на языке R или другом языке программирования, которые будут исполнены, а результат которых будет отображен прямо под чанком с кодом. Чанк с кодом отделяется ``` с обоих сторон и содержит {r}. Это означает, что внутри находится код на R, который должен быть выполнен:\n\n```{r}\n2+2\n```\nВ итоговом документе чанк будет выглядеть так:\n\n2+2\n\n[1] 4"
  },
  {
    "objectID": "250-rmarkdown.html#sec-chunk",
    "href": "250-rmarkdown.html#sec-chunk",
    "title": "16  R Markdown",
    "section": "16.4 Настройки чанка",
    "text": "16.4 Настройки чанка\nУ чанка с кодом есть набор настроек. Самый важные из них такие:\n\necho: будет ли показан сам код\nmessage и warning: будут ли показаны сообщения и предупреждения, всплывающие во время исполнения кода\neval: будет ли испольняться код внутри чанка\n\n\n16.4.1 Настройка нескольких чанков\nВсе эти настройки можно настроить как для отдельных чанков, так и для все чанков сразу:\n\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n\nЭтот чанк нужно вставлять в начале .Rmd документа, тогда выбранные настройки повлияют на все последующие чанки.\n\n\n16.4.2 Чанки с Python и другими языками программирования\nМожно вставлять чанки с кодом на других языках программирования! Для этого вместо {r} нужно написать {python}.\n\nx = 'hello, python !'\nprint (x.split(\" \"))\n\nВот полный список поддерживаемых языков:\n\nnames(knitr::knit_engines$get())\n\n [1] \"awk\"       \"bash\"      \"coffee\"    \"gawk\"      \"groovy\"    \"haskell\"  \n [7] \"lein\"      \"mysql\"     \"node\"      \"octave\"    \"perl\"      \"php\"      \n[13] \"psql\"      \"Rscript\"   \"ruby\"      \"sas\"       \"scala\"     \"sed\"      \n[19] \"sh\"        \"stata\"     \"zsh\"       \"asis\"      \"asy\"       \"block\"    \n[25] \"block2\"    \"bslib\"     \"c\"         \"cat\"       \"cc\"        \"comment\"  \n[31] \"css\"       \"ditaa\"     \"dot\"       \"embed\"     \"eviews\"    \"exec\"     \n[37] \"fortran\"   \"fortran95\" \"go\"        \"highlight\" \"js\"        \"julia\"    \n[43] \"python\"    \"R\"         \"Rcpp\"      \"sass\"      \"scss\"      \"sql\"      \n[49] \"stan\"      \"targets\"   \"tikz\"      \"verbatim\"  \"ojs\"       \"mermaid\"  \n[55] \"include\"  \n\n\n\n\n16.4.3 Код вне чанков (inline code)\nИногда хочется вставить результат расчетов прямо в текст. Для этого нужно поставить символ ` с обоих краев команды и написать r перед самой командой. В этом случае результат выполнения этой команды будет в тексте вместо этой конструкции.\nЧисло пи равно ` r pi `:\nЧисло пи равно 3.1415927"
  },
  {
    "objectID": "250-rmarkdown.html#sec-md",
    "href": "250-rmarkdown.html#sec-md",
    "title": "16  R Markdown",
    "section": "16.5 Синтаксис Markdown (без R)",
    "text": "16.5 Синтаксис Markdown (без R)\nВ RStudio есть подсказка по синтаксису Markdown, для ее вызова нужно нажать Help - Markdown Quick Reference\n\n16.5.1 Выделение текста\nВыделение текста происходит с помощью обособления текста специальными символами:\n*Курсив* \n_Тоже курсив_\n**Полужирный**\n__Тоже полужирный__\n~~перечеркнутый~~\nиндекс^надстрочный^\nиндекс~подстрочный~\nКурсив Тоже курсив Полужирный Тоже полужирный перечеркнутый индекснадстрочный индексподстрочный\n\n\n16.5.2 Заголовки разных уровней\nС помощью решенточек (#) выделяются заголовки разных уровней.\n# Самый верхний заголовок\n\n## Заголовок второго уровня\n\n### Мне заголовок\n\n#### И моему сыну тоже\n\n##### И моему!\n\n###### Все, дальше опускаться некуда\n\n\n16.5.3 Списки\nСписки можно создавать по-разному, в зависимости от того, является ли список пронумерованным:\n* Первый вариант списка выглядит так:  \n    + Можно и с подсписком\n    + Почему бы и нет?\n\n1. Кому нужен порядок\n2. Тот списки номерует\n\nПервый вариант списка выглядит так:\n\nМожно и с подсписком\nПочему бы и нет?\n\n\n\nКому нужен порядок\nТот списки номерует\n\n\n\n16.5.4 Цитаты\nЦитаты выделяются с помощью знака > в начале строки.\n> Я устал  \n> Который год во мне живет нарвал\n\nЯ устал\nКоторый год во мне живет нарвал\n\n\n\n16.5.5 Таблицы\nТабличные данные имеют особое значение в R, в R Markdown им тоже уделяется особое внимание.\nДля начала подгрузим данные о супергероях:\n\nlibrary(\"tidyverse\")\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nФункция knitr::kable() превращает табличные данные (матрицы, датафреймы) в текст, отформатированный как Markdown-таблицы. Таким образом, вот такая таблица:\n\nknitr::kable(heroes[1:3, 1:4])\n\nПревращается вот в такую, отформатированную с помощью символов -, | и т.п.:\n| X1|name       |Gender |Eye color |\n|--:|:----------|:------|:---------|\n|  0|A-Bomb     |Male   |yellow    |\n|  1|Abe Sapien |Male   |blue      |\n|  2|Abin Sur   |Male   |blue      |\nА эта таблица, в свою очередь, превращается в такую в финальном документе:\n\n\n\nX1\nname\nGender\nEye color\n\n\n\n\n0\nA-Bomb\nMale\nyellow\n\n\n1\nAbe Sapien\nMale\nblue\n\n\n2\nAbin Sur\nMale\nblue\n\n\n\nЕсли вам нужно самостоятельно отформатировать таблицу в Markdown, то для этого есть специальный ресурс.\nПакет knitr является ключевым для R Markdown, поэтому он устанавливается вместе с rmarkdown. А вот для дополнительной настройки вывода таблиц рекомендуется пакет kableExtra."
  },
  {
    "objectID": "250-rmarkdown.html#sec-extra_rmd",
    "href": "250-rmarkdown.html#sec-extra_rmd",
    "title": "16  R Markdown",
    "section": "16.6 Дополнительные возможности R Markdown",
    "text": "16.6 Дополнительные возможности R Markdown\n\n16.6.1 Динамические таблицы\nОдин из самых интересных HTML-виджетов (@ref(htmlwidgets)) — пакет DT для создания интерактивных таблиц прямо внутри HTML-документа.\n\nlibrary(tidyverse)\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\nDT::datatable(heroes)\n\n\n\n\n\n\n\n\n16.6.2 Графики в R Markdown\nВсе создаваемые графики будут появляться под чанком с кодом.\n\nheight_weight_gg <- heroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(aes(colour = Gender), alpha = 0.5) +\n  coord_fixed() +\n  facet_wrap(~Publisher)+\n  theme_minimal()\nheight_weight_gg\n\n\n\n\nЭто так же относится и к динамическим визуализациям с помощью HTML-виджетов (@ref(htmlwidgets)), например, plotly.\n\nlibrary(plotly)\nggplotly(height_weight_gg)\n\n\n\n\n\nКонечно, чтобы эта интерактивность сохранилась, используемый формат итогового документа должен ее поддерживать. Word-документы, так же как и PDF-документы, — статичны, поэтому единственный вариант сохранить интерактивные элементы — это использование HTML-документов или HTML-презентаций.\n\n\n16.6.3 HTML-код\nЕсли вы выбрали HTML форматом итогового документа, то можете использовать все его фишки, включая форматирование с помощью HTML-тегов (в дополнение к обычному Markdown). Еще вы можете вставлять куски HTML-кода, например, вставить видео с YouTube или отдельный пост из Twitter.\n <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5qap5aO4i9A\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5qap5aO4i9A\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
  },
  {
    "objectID": "305-hyp_test.html",
    "href": "305-hyp_test.html",
    "title": "Тестирование статистических гипотез",
    "section": "",
    "text": "Этот раздел будет посвящен статистическим модели и тестам. Но чтобы разобраться с ними, нам для начала придется понять общую логику, которая стоит за ними, которую мы будем разбирать в главе Глава 17.\nВсе последующие главы будут посвящены отдельным группам статистических моделей и тестов, от самых простых до самых сложных."
  },
  {
    "objectID": "310-infer_stats.html#sec-infer_intro",
    "href": "310-infer_stats.html#sec-infer_intro",
    "title": "17  Статистика вывода",
    "section": "17.1 Введение в статистику вывода",
    "text": "17.1 Введение в статистику вывода\nСтатистика вывода (inferential statistics) - это основной раздел статистики, связанный уже не с описанием и суммированием имеющихся данных (описательная статистика), а с попытками сделать вывод о генеральной совокупности (population) на основе имеющихся данных по выборке. Короче говоря, статистика вывода - это о том, как выйти за пределы наших данных. Это именно то, зачем мы проводим исследования - мы не можем собрать информацию обо всей генеральной совокупности, но по тому, что имеем (т.е. по нашей выборке), можем попытаться как-то оценить параметры распределения в генеральной совокупности.\nИтак, еще раз: генеральной совокупности - параметры (Population - Parameters), а у выборки - статистики (Sample - Statistics). Параметры обычно обозначаются греческими буквами: \\(\\mu\\), \\(\\sigma\\) (или большими латинскими: \\(M\\), \\(S\\) ), а статистики - соответствующими латинскими: \\(m\\), \\(s\\)."
  },
  {
    "objectID": "310-infer_stats.html#sec-distributions",
    "href": "310-infer_stats.html#sec-distributions",
    "title": "17  Статистика вывода",
    "section": "17.2 Распределения",
    "text": "17.2 Распределения\nСлучайная переменная (random variable) – это переменная значения которой в зависимости от случая принимают различные значения. Представьте себе машину, которая по требованию выдает какое-то случайное число (или даже несколько). Это и будет случайная переменная. Какие это могут быть значения, какие-то конкретные или любые в каком-то диапазоне? Могут ли какие-то значения выпадать чаще других? Очевидно, случайные переменные могут быть разными в зависимости от закона, который стоит за тем, какие значения она может принимать и с какой частотой. Этот закон называется распределением вероятности.\nЕсли случайная переменная может принимать только какие-то конкретные значения (например, 3, 10, 0.25 или число пи), то случайная переменная имеет дискретное распределение. Если же случайная переменная может принимать любые значения (в каком-то диапазоне или же вообще любые), то такая случайная переменная будет иметь непрерывное распределение. По большей части нас будут интересовать именно непрерывные. Хотя для полного их понимания нужен матан (да, именно тот, который calculus), непрерывные распределения довольно интуитивно понятны.\nМожет ли случайная переменная принимать значения с разной частотой? Если нет, то речь идет о равномерном распределении (uniform distribution). Пример случайной величины с дискретным равномерным распределением – игральный кубик, с вероятностью \\(\\frac{1}{6}\\) возвращает одно из значений: 1, 2, 3, 4, 5 или 6. Однако равномерное распределение может быть как дискретным, так и непрерывным.\nВсе остальные распределения (кроме равномерного распределения) обозначают, что какие-то значения имеют больший шанс выпадения, чем другие. Разные распределения могут быть описаны с помощью функций распределения. В R есть свой набор из трех основных функций для каждого распределения и еще одна функция: генератор случайных чисел из выбранного распределения.\nВот эти функции:\n\nd*() – функция вероятности (probability mass function) для дискретных распределений и функция плотности вероятности для непрерывных распределений.\np*() – функция накопленной плотности распределения (cumulative distribution function; cdf)\nq*() – квантильная функция (quantile function), или обратная функция накопленной плотности распределения (inverse cumulative distribution function)\n\nНу и функция r*() для создания случайных выборок из выбранного распределения.\nВо всех четырех случаях, вместо звездочки нужно поставить название соотвествующего распределения в R. Таким образом, для каждого распределения в R есть четыре функции (с похожими названиями, различающимися первой буквой), и таких семейств функций в базовом R (точнее, во встроенном пакете {stats}) очень много. Вот лишь некоторые из них:\n\nСкоро мы разберем их все.\nВозьмем, например, нормальное распределение, и разберем на его примере все эти функции: dnorm(), pnorm(), qnorm() и rnorm().\nВот формула нормального распределения:\n\\[P(x) = \\frac{e^{-(x - \\mu)^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}\\]\nДля того, чтобы описать нормальное распределение нам нужно всего два параметра - его среднее \\(\\mu\\) и стандартное отклонение \\(\\sigma\\). Если же \\(\\mu = 0\\), а \\(\\sigma = 1\\), то такое нормальное распределение называется стандартным. Заметьте, здесь мы говорим о параметрах распределения в генеральной совокупности, а не о статистиках в конкретной выборке, хотя называются они одинаково.\nЯ думаю, все видели, как выглядит нормальное распределение. Это та самая “колоколообразная кривая”1.\n\nТо, что Вы видите на картинке - это так называемая функция плотности вероятности (probability density function). Это аналог probability mass function для дискретных величин - распределение вероятности того, что случайная величина имеет данное значение. Довольно очевидно, да? Тогда почему аналогичная функция для непрерывных распределений называется по-другому?\nДело в том, что вероятность получения конкретного значения для непрерывных величин равна нулю. Это немного необычный момент, но тем не менее: если распределение непрерывно, то получить точно 0,000000000000 с бесконечным количеством нулей после запятой невозможно, даже если среднее распределения равно нулю. Тем не менее, мы можем посчитать вероятность того, что случайное значение окажется в определенном промежутке. Чтобы посчитать эту вероятность, надо посчитать площадь соответствующего участка. Соответсвенно, площадь под всей функцией плотности вероятности равна 1.\nКонечно, функцию плотности можно получить в R - это функции d*(), где * означает соответствующее распределение. Например, функция dnorm() для нормального распределения.\nФункция dnorm() имеет следующие основные параметры: x = - вектор принимаемых значений, среднее и стандартное отклонение (mean = и sd =). В качестве параметров по умолчанию используются 0 для среднего и 1 для стандартного отклонения, то есть стандартное нормальное распределение. Для других распределений параметры будут отличаться (например, вместо mean = и sd = будет параметр df = – “степени совободы”).\nДавайте посмотрим, как работает эта функция, визуализировав результат ее выполнения на вектор от -3 до 3 с небольшим шагом (0.1). С помощью базовой функции plot() мы построим диаграмму рассеяния, где по оси x используем исходный вектор с последвательностью от -3 до 3 с шагом 0.1, а по оси y – результат применения функции dnorm() на исходном векторе. Каждое отдельное значение – это плотность вероятности для конкретного значения x. Поскольку таких значений много, и они находятся близко друг к другу, то практически получается график кривой линии.\n\nvec <- seq(-3,3, 0.1)\nplot(vec,dnorm(vec))\n\n\n\n\nВот мы и получили то, что называем стандартным нормальным распределением, точнее, функцию плотности вероятности стандартного нормального распределения.\nДавайте теперь возьмем другое нормальное распределение с другими параметрами. Например, среднее будет равно 100, а стандартное отклонение – 15. Это нормы для шкалы IQ:\n\niq <- seq(50,150, 0.1)\nplot(iq, dnorm(iq, mean = 100, sd = 15))\n\n\n\n\n\nШкала IQ — это вообще очень удобная шкала. Поскольку в измерениях интеллекта нет никаких объективных метрик (сантиметров, градусов, килограммов), с которыми его можно было бы сравнить, то единственная возможность дать какую-то оценку величины интеллекта у человека — сравнить его с интеллектом другого человека, например, по количеству решенных заданий за определенное время. Поэтому шкала IQ так сконструирована, чтобы среднее значение количество решенных заданий обозначалось за 100, а стандартное отклонение за 15. Поэтому по баллу IQ (если используется хороший тест, разумеется) можно понять процент людей, которых респондент опережает по интеллекту, по крайней мере, сравнивая с выборкой, на которой был стандартизирован тест. Примерно так же устроены и другие психологические шкалы.\n\nСледующая функция это функция накопленной плотности распределения (cumulative distribution function; cdf) 2. Это функция очень важная, потому что именно на ней основано тестирование уровня значимости нулевой гипотезы, которым мы будем заниматься в дальнейшем. Она означает вероятность того, что полученное случайное значение из распределения будет меньше искомого или равно ему. Для этого используется функция pnorm().\n\nplot(iq, pnorm(iq, mean = 100, sd = 15))\n\n\n\n\nКакова вероятность того, что полученное случайное значение IQ будет меньше или равно 100?\n\npnorm(100, mean = 100, sd = 15)\n\n[1] 0.5\n\n\nА меньше или равно 130?\n\npnorm(130, mean = 100, sd = 15)\n\n[1] 0.9772499\n\n\nСледующая функция — это квантильная функция (quantile function), или обратная функция накопленной плотности распределения (inverse cumulative distribution function):\n\nprob <- seq(0,1, 0.01)\nplot(prob, qnorm(prob, mean = 100, sd = 15))\n\n\n\n\nОбратная функция означает, что если мы применим сначала одну, а потом другую, то (если не берем особо крайних значений) на выходе получим исходные числа 3. Квантильная функция возвращает значение, которое по заданной вероятности случайная переменная не будет превышать. Поскольку квантильная функция – это функция от вероятности, квантильная функция определена на отрезке от 0 до 1.\n\nqnorm(pnorm(-4:4))\n\n[1] -4 -3 -2 -1  0  1  2  3  4\n\n\nНу и последняя важная функция - это rnorm() - просто генерирует выборку значений из данного распределения заданной длины n =:\n\nset.seed(42)\nsamp <- rnorm(100, mean = 100, sd = 15)\nsamp\n\n  [1] 120.56438  91.52953 105.44693 109.49294 106.06402  98.40813 122.67283\n  [8]  98.58011 130.27636  99.05929 119.57304 134.29968  79.16709  95.81817\n [15]  98.00018 109.53926  95.73621  60.15317  63.39300 119.80170  95.40042\n [22]  73.28037  97.42124 118.22012 128.42790  93.54296  96.14096  73.55255\n [29] 106.90146  90.40008 106.83175 110.57256 115.52655  90.86610 107.57433\n [36]  74.24487  88.23311  87.23639  63.78689 100.54184 103.08998  94.58414\n [43] 111.37245  89.09943  79.47578 106.49227  87.82910 121.66152  93.52831\n [50] 109.83472 104.82888  88.24242 123.63591 109.64349 101.34641 104.14826\n [57] 110.18933 101.34749  55.10365 104.27324  94.49148 102.77846 108.72736\n [64] 120.99605  89.09062 119.53814 105.03772 115.57759 113.81093 110.81317\n [71]  84.35322  98.64720 109.35277  85.69715  91.85757 108.71495 111.52268\n [78] 106.95651  86.71336  83.50329 122.69061 103.86882 101.32660  98.18655\n [85]  82.08507 109.17995  96.74290  97.25865 114.00019 112.32660 120.88175\n [92]  92.85739 109.75523 120.86666  83.33817  87.08811  83.02392  78.11179\n [99] 101.19974 109.79807\n\n\n\nset.seed() - это функция, которая позволяет получить нам воспроизводимые результаты при использовании генератора случайных чисел. Короче говоря, если все мы поставим set.seed(42) 4, то одна и та же строчка выдаст нам один и тот же результат на разных компьютерах. Как это вообще возможно, это же случайные числа? Дело в том, что… нет. Они “псевдо-случайные”. На самом деле, используются определенные алгоритмы, чтобы генерировать числа, которые выглядят как случайные. Например, можно брать цифры после запятой в числе пи после, например, 42го знака. Реальные алгоритмы создания псевдо-случайных чисел, конечно, гораздо сложнее, но суть примерно такая. Насколько подобные числа действительно получаются случайными - отдельный сложный математический вопрос. Но для нас этого вполне достаточно.\n\n\nhist(samp, breaks = 10)"
  },
  {
    "objectID": "310-infer_stats.html#sec-estimates",
    "href": "310-infer_stats.html#sec-estimates",
    "title": "17  Статистика вывода",
    "section": "17.3 Оценки",
    "text": "17.3 Оценки\nСамая основа статистики вывода - это оценки. Как мы уже знаем, у распределений есть определенные параметры, которые описывают данное распределение.\nНапример, для того, чтобы описать нормальное распределение нам нужно всего два параметра - его среднее \\(\\mu\\) и стандартное отклонение \\(\\sigma\\).\nНаша цель - как-нибудь оценить эти параметры, потому что обычно мы их не знаем. Допустим, человеческий рост распределен нормально [^isnotnormal]. Какой средний рост в популяции? Какое у него стандартное отклонение? Для этого мы используем разного рода оценки: точечные и интервальные. В качестве оценок параметров часто используются статистики по выборке. Вот здесь легко запутаться, поэтому покажу картинку:\n[^isnotnormal]: На самом деле, “чистое” нормальное распределение, так же как и любое другое “чистое” распределение, в природе встречается достаточно редко. Но довольно многие процессы могут апроксимироваться нормальным распределением благодаря центральной предельной теореме Глава 17.8."
  },
  {
    "objectID": "310-infer_stats.html#sec-sample_estimate",
    "href": "310-infer_stats.html#sec-sample_estimate",
    "title": "17  Статистика вывода",
    "section": "17.4 Точечные оценки",
    "text": "17.4 Точечные оценки\nПредставим, что только что сгенерированные данные с помощью rnorm() - это и есть наша выборка. Перед нами стоит задача оценить IQ популяции по этой выборке. Ну что, давайте попробуем оценить среднее. Здесь все просто и очень очевидно - самой лучшей оценкой среднего в генеральной совокупности будет среднее по выборке.\n\nmean(samp)\n\n[1] 100.4877\n\n\nКонечно, не совсем точно, но лучше оценки не придумаешь. Что есть, то есть. Чем больше выборка, тем в ближе оценка будет к популяционному среднему. То есть чем больше выборка, тем выше точность оценки.\nА что с оценкой стандартного отклонения? Давайте воспользуемся нашей предыдущей формулой.\n\\[s= \\sqrt\\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n}\\]\n\nsqrt(sum((samp - mean(samp))^2)/length(samp))\n\n[1] 15.54206\n\n\nВ данном случае мы несколько промахнулись вверх, но обычно оценка по этой формуле дает небольшое смещение (bias) в меньшую сторону. В отличие от выборочного среднего как оценки среднего в генеральной совокупности, использование выборочного стандартного отклонения по выборке приводит к смещенной оценке! Само по себе это кажется странным, и это нормально. Но этому есть всякие серьезные математические доказательства. Кроме того, есть множество всяких демонстраций, например, от Академии Хана.\n\nОдно из простых объяснений такое: поскольку мы оцениваем стандартное отклонение на основе оценки среднего, среднеквадратичные расстояния счиаются не от реального среднего в генеральной совокупности, а от среднего по выборке, которое немного смещено в ту или иную сторону. Представьте, что так получилось, что в нашей выборке оно оказалось сильно смещено и выборочное среднее получилось около 90 (такое бывает). Это значит, что получилось много довольно низких значений около этого 90, а высчитываться среднеквадратичные разницы будут не от среднего 100 (которое мы не знаем), а от этого 90. Поэтому стандартное отклонение получится сильно меньше, чем должно было получиться.\n\nЧтобы получить несмещенную (unbiased) оценку стандартного отклонения или дисперсии, то нам нужно делить не на \\(n\\), а на \\(n-1\\).\n\\[s= \\sqrt\\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n-1}\\] Заметьте, что именно так делает стандартная функция sd():\n\nsqrt(sum((samp - mean(samp))^2)/(length(samp) - 1))\n\n[1] 15.62035\n\nsd(samp)\n\n[1] 15.62035\n\n\nЭто называется поправкой Бесселя, и она настолько распространена, что именно скорректированное стандартное отклонение обычно называют стандартным отклонением. Поэтому в дальнейшем будет использоваться именно эта формула или же просто функция sd().\nТаким образом, у оценки есть два критерия качества - ее точность и ее несмещенность."
  },
  {
    "objectID": "310-infer_stats.html#sec-interval_estimate",
    "href": "310-infer_stats.html#sec-interval_estimate",
    "title": "17  Статистика вывода",
    "section": "17.5 Интервальные оценки",
    "text": "17.5 Интервальные оценки\nДругой подход к оцениванию параметра распределения в генеральной совокупности заключается в использовании интервалов. Вместо того, чтобы дать одну оценку, которая будет заведома неточна, можно попробовать оценить интервал, в котором находится истинное среднее генеральной совокупности.\nСамая распространенная интервальная оценка называется доверительным интервалом (confidence interval). Цель доверительного интервала - “покрыть” параметр генеральной совокупности с определенной степенью уверенности.\nНапример, 95% доверительный интервал или просто \\(CI95\\%\\) означает, что примерно в 95% случаев подсчитанный на выборках интервал будет ловить значение параметра в популяции. Например, построив \\(CI95\\%\\) по нашей сгенерированной выборке, мы хотим чтобы примерно в 95% случаев выборок, построенных таким способом, этот интервал ловил истинное среднее (в данном случае — 100).\nДля того, чтобы научиться строить такие интервалы, нам нужно разобраться с выборочным распределение (sampling distribution)."
  },
  {
    "objectID": "310-infer_stats.html#sec-sample_dist",
    "href": "310-infer_stats.html#sec-sample_dist",
    "title": "17  Статистика вывода",
    "section": "17.6 Выборочное распределение",
    "text": "17.6 Выборочное распределение\nЧтобы разобраться с тем, что стоит за доверительными интервалами и тестированием уровня значимости нулевой гипотезы (короче говоря, с основными инструментами статистики вывода), нам надо разобраться с очень абстрактной концепцией – выборочными распределениями.\nПредставьте себе, что мы бы выбрали не одну, а сразу много выборок, а потом у каждой выборки посчитали бы среднее. Мы бы получили новый вектор данных - средние выборок из одного распределения. Давайте это сделаем 5.\n\nsamplemeans <- replicate(1000, mean(rnorm(100, mean = 100, sd = 15)))\n\nКаждая выборка состоит из сотни “испытуемых”, всего таких выборок 1000. По каждой мы посчитали среднее.\nКак распределены эти средние?\n\nhist(samplemeans, breaks = 30)\n\n\n\n\nВот это распределение и есть выборочное распределение средних. Точнее, было бы, если бы мы взяли не 1000 выборок, а бесконечное количество выборок. Так что у нас всего лишь апроксимация. При этом мы могли взять другие статистики, не средние выборок, а, например, медианы или стандартные отклонения выборок. Тогда это были бы выборочные распределения медиан и выборочные распределения стандартных отклонений. Но именно выборочное распределение средних обладает уникальными математическими свойствами, про которые мы скоро узнаем.\nСреднее выборочного распределения средних будет близко к популяционному среднему:\n\nmean(samplemeans)\n\n[1] 99.93772\n\n\nА вот чему будет равно стандартное отклонение средних?\n\nsd(samplemeans)\n\n[1] 1.501392\n\n\nОчень похоже на стандартное отклонение IQ, но в 10 раз меньше. В действительности, стандартное отклонение выборочного распределения средних равно стандартному отклонению в генеральной совокупности, деленному на корень из размера выборки.\n\\[\\sigma_{\\overline{x}}= \\frac{\\sigma} {\\sqrt{n}}\\] Как раз это мы и получили: размер нашей выборки - 100, а корень из 100 равен 10.\nСтандартное отклонение выборочного распределения средних (ох, йо) называется еще стандартной ошибкой или standard error of the mean (s.e.m.). Именно стандартную ошибку обычно используют на графиках в качестве error bars. Теперь вы знаете как ее посчитать!\n\nsem <- 15/sqrt(length(samp))\nsem\n\n[1] 1.5\n\n\nНу а если мы не знаем стандартного отклонения в генеральной совокупности (что обычно и бывает в жизни), то можем оценить стандартную ошибку среднего с помощью оценки стандартного отклонения, посчитанного на выборке:\n\\[s_{\\overline{x}}= \\frac{s} {\\sqrt{n}}\\]\n\nsd(samp)/sqrt(length(samp))\n\n[1] 1.562035\n\n\nЭто означает, что стандартная ошибка тем меньше, чем больше выборка. И это довольно логично: чем больше у нас размер выборок, тем меньше будет расброс их средних."
  },
  {
    "objectID": "310-infer_stats.html#sec-nordm_dist_importance",
    "href": "310-infer_stats.html#sec-nordm_dist_importance",
    "title": "17  Статистика вывода",
    "section": "17.7 Важность нормального распределения",
    "text": "17.7 Важность нормального распределения\nВ математике все числа равны, но некоторые все-таки заметно равнее других. Например, есть 0 и 1 - и очевидно, что это очень важные числа. Даже гугл выдает больше страниц по числам 0 и 1, чем по другим числам, например, 8 и 23218974. Не только целые числа могут быть важными. Вот, например, число пи и число Эйлера: они очень часто встречаются в самых разных, подчас неожиданных местах. Например, в тех же формулах распределений. На эти числа завязано очень интересные и важные свойтсва, поэтому такая зацикленность на них неудивительна. Например, число пи связывает радиус круг с длиной его окружности и площадью, поэтому когда перед нами что-то круглое, то и пи появится с большой вероятностью.\nВ статистике тоже есть распределения, которые “главнее” других распределений. Есть, например, равномерное распределение. Например, равномерно распределены исходы одного броска кубика.\nНо есть и распределение, которое смело можно называть королем всех распределений - это уже знакомое нам нормальное распределение.\nНормальное распределение - это что-то в духе единицы из мира распределений. Это не просто одно из распределений, а это фундаментально важная штуковина, которая обладает почти магической силой. И сила эта зовется “Центральная Пределельная Теорема”."
  },
  {
    "objectID": "310-infer_stats.html#sec-clt",
    "href": "310-infer_stats.html#sec-clt",
    "title": "17  Статистика вывода",
    "section": "17.8 Центральная предельная теорема",
    "text": "17.8 Центральная предельная теорема\nДавайте теперь сделаем много выборок не из нормального, а из логнормального распределения. Что-то похожее представляет собой распределение времени реакции на многие задачи (особенно связанные с выбором и когда нужно подумать перед нажатием кнопки). Одна выборка будет распределена примерно так:\n\nhist(rlnorm(10000), breaks = 100)\n\n\n\n\nРаспределение сильно ассиметрично, но его форма примерно понятна.\nА как будут распределены средние многих выборок, взятых из логнормального распределения? Хочется сказать, что так же, но нет!\n\nmany_means <- replicate(1000, mean(rlnorm(10000)))\nhist(many_means, breaks = 100)\n\n\n\n\nУдивительно, но средние по выборкам из логнормального распределения будут выглядеть почти нормально! Более того, для других распределений это тоже будет верно: согласно центральной предельной теореме (ЦПТ, central limit theorem), какой бы ни была форма распределения в генеральной совокупности, выборочное распределение средних будет стремиться к нормальному. При этом чем больше размер выборки, тем ближе выборочное распределение средних будет к нормальному. Это очень важная фишка, на которой основаны многие статистические тесты.\n\nНе верите? Попробуйте сами! Можете поиграться с разными распределениями с помощью кода (можете посмотреть другие распределения в хэлпе: ?Distributions ).\nМожете поиграться с интерактивной Shiny-демонстрацией магии ЦПТ. Я очень и очень рекомендую поиграться с ней. Попробуйте разные значения, посмотрите что будет.\nКак только наиграетесь, то сразу станет понятно, почему именно нормальное распределение занимает такое важное место в статистике.\n\nЕсли выходить за рамки выборочного распределения средних, то центральная предельная теорема говорит нам о том, что сумма слабо зависящих случайных величин, имеющих примерно одинаковое влияние, имеет распределение близкое к нормальному. Например, рост является следствием большого количества генетических и средовых факторов, поэтому он распределен примерно нормально. Однако это нормальное распределение портят такие факторы как пол — он вносит очень сильный вклад в рост, поэтому распределение становится немного “двугорбым”."
  },
  {
    "objectID": "310-infer_stats.html#sec-ci_build",
    "href": "310-infer_stats.html#sec-ci_build",
    "title": "17  Статистика вывода",
    "section": "17.9 Строим доверительный интервал",
    "text": "17.9 Строим доверительный интервал\nТеперь мы знаем достаточно, чтобы построить доверительный интервал своими руками на основе стандартной ошибки. Мы построим самый стандартный вариант - 95% доверительный интервал.\nДавайте еще раз посмотрим на нормальное распределение.\n\nМы хотим поймать симметрично 95% от площади под кривой. Для этого нам нужно отбросить по 2.5% с обоих сторон. Эти 2.5% соответствуют примерно двум стандартным отклонениям от среднего. Если быть точнее, то 1.96. Если быть еще точнее:\n\nqnorm(0.975)\n\n[1] 1.959964\n\n\nПочему 0.975? Потому что мы смотрим квантильную функцию по верхней границе: отсекаем правые 0.025:\n\nqnorm(1 - (1 - 0.95)/2)\n\n[1] 1.959964\n\n\nДавайте сохраним это число. Назовем его zcr:\n\nzcr <- qnorm(1 - (1 - 0.95)/2)\n\nЭто количество стандартных отклонений от среднего в нормальном распределении, которое включает в себя ровно 95% площади нормального распределения. Теперь давайте посчитаем стандартную ошибку. Здесь мы знаем стандартное отклонение в генеральной совокупности (это 15), его поделим на корень из размера выборки:\n\nsem <- 15/sqrt(length(samp))\n\nЧтобы посчитать нижнюю и верхнюю границы доверительного интервала, нам нужно вычесть и прибавить соответственно нужное количество стандартных ошибок:\n\nmean(samp) - sem*zcr #нижняя граница\n\n[1] 97.54778\n\nmean(samp) + sem*zcr #верхняя граница\n\n[1] 103.4277\n\n\nДавайте теперь нарисуем сотню доверительных интервалов с помощью ggplot2! Цветом обозначим интервалы, которые не поймали истинное значение параметра в центральной совокупности.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nsample_size <- 100\nset.seed(42)\nci_simulations <- tibble(\n  m = replicate(sample_size, mean(rnorm(sample_size, mean = 100, sd = 15))),\n  se = 15/sqrt(sample_size),\n  lower = m - se*zcr,\n  higher = m + se*zcr,\n  parameter_inside = lower<100 & higher>100\n)\n\n\nmany_ci_gg <- ggplot(data = ci_simulations, aes(x = 1:sample_size,y = m)) +\n  geom_pointrange(aes(ymin = lower,ymax = higher,colour = parameter_inside))+\n  geom_hline(yintercept = 100)+\n  coord_flip() +\n  theme_minimal()\nmany_ci_gg\n\n\n\n\nПримерно 5% не ловят 100 в 95% доверительный интервал! Примерно это и означает доверительный интервал: где-то в 95% он ловит параметр в генеральной совокупности, а в 5% - нет.\n\nПонятие доверительного интервала вызывает кучу недопонимания и ошибок. Очень многие его интерпретируют, например, как интервал, включающий в себя 95% значений популяции, но это неправильно.\n\nЕще я советую посмотреть вот эту визуализацию:\nДоверительные интервалы сыпятся как из мешка"
  },
  {
    "objectID": "310-infer_stats.html#sec-nhst",
    "href": "310-infer_stats.html#sec-nhst",
    "title": "17  Статистика вывода",
    "section": "17.10 Тестирование значимости нулевой гипотезы",
    "text": "17.10 Тестирование значимости нулевой гипотезы\nТестирование значимости нулевой гипотезы (null hypothesis significance testing) — это основной подход в статистике вывода. Вы про него точно слышали (хотя, возможно, не знали, что он так называется), потому что де-факто он является стандартом в психологии, биологии, медицине и многих других науках.\nМы сейчас детально его проведем на примере одного из самых простых статистических тестов - z-тестов. Однако та же самая логика стоит и за остальными статистическими тестами.\n1. Формулирование нулевой и альтернативной гипотезы.\nСначала мы задаем две гипотезы о параметрах распределения. Одна из них называется нулевой: она обычно включает положение о том, что различий или связи нет или что это различие/связь равно определенному числу. Если мы хотим применить тестирование значимости к нашей “выборке”, то нулевую гипотезу можно будет сформулировать так: \\[H_0: \\mu = 100\\]. Альтернативная или ненулевая гипотеза либо говорит о том, что среднее в генеральной совокупности на самом деле не равно какому-то конкретному числу (в нашем случае — 100) или что две выборки взяты из групп с различным средним и т.п.\n\\[H_1: \\mu \\ne 100\\]\nТестирование нулевой гипотезы предполагает подсчет какой-то статистики, а потом вычисление того, какова вероятность получить такой или более радикальный результат при условии, что верна нулевая гипотеза.\nЗаметьте, мы формулируем гипотезу не про статистики в выборке, а про параметры в генеральной совокупности, поэтому пользуемся греческими (или большими латинскими) буквами.\nВся дальнейшая логика расчетов будет строиться именно на нулевой гипотезе: мы будем пытаться понять, насколько реалистичны наши результаты при верности нулевой гипотезы, которую мы заранее обозначили. Это похоже на “доказательство от обратного” в геометрии: мы исходим из того, что эффекта не существует и пытаемся прийти к противоречию с данными, чтобы отбросить эту нулевую гипотезу и принять альтернативную гипотезу.\n2. Подсчет тестовой статистики по выборке\nСледующий этап тестирования значимости нулевой гипотезы — подсчет тестовой статистики. Тестовые статистики по своей сути не отличаются от описательных статистик, с которыми мы уже познакомились, но имеют другую функцию. Как и в случае описательных статистик, мы пытаемся выразить информацию о выборке в виде одного числа, но делаем это для того, чтобы сравнить это значение с другими возможными значениями, которые мы могли бы получить, если бы наша нулевая гипотеза была верна.\nЕсли мы знаем стандартное отклонение в генеральной совокупности, то можем посчитать \\(z\\)-статистику по формуле:\n\\[z = \\frac{\\overline{x} - \\mu} {\\sigma / \\sqrt{N}} \\]\n\nm <- mean(samp)\nsem <- 15/sqrt(length(samp))\nz <- (m - 100)/sem\nz\n\n[1] 0.3251482\n\n\n\\(z\\)-статистика — это выборочное среднее, из которого вычтено среднее в генеральной совокупносности согласно нашей гипотезе. Получившуюся разницу мы делим на стандартную ошибку.\n3. Расчет p-value\nИ вот мы подобрались к самому важному этапу – расчет p-value. p-value – это вероятность получить такую и более отклоняющуюся тестовую статистику при условии верности нулевой гипотезы. Очень важно понять, как именно оно расчитывается, потому что на этом основывается сама идея тестирования значимости нулевой гипотезы! Для этого нам нужно вернуться к идее выборочного распределения, только теперь уже не среднего, а \\(z\\)-статистики. Впрочем, выглядеть оно будет абсолютно так же – нормально! Благодаря тому, что мы вычли среднее и поделили на стандартное отклонение, среднее этого нормального распределения будет равно 0, а стандартное отклонение – 1. То есть перед нами снова стандартное нормальное распределение.\nБлагодаря ЦПТ, даже если распределение в генеральной совокупности несколько отличается от нормального, а выборка достаточно большая, то выборочное распределение z-статистик при верности нулевой гипотезы будет (примерно) нормальным.\nТеперь нам нужно соотнести нашу \\(z\\)-статистику с теоретическим выборочным распределением \\(z\\)-статистик. Это позволит нам оценить вероятность получить такие и более отличающиеся результаты при допущении верности нулевой гипотезы, т.е. p-value.\nКакая вероятность получить \\(z\\)-статистику 0.3251482, если на самом деле нулевая гипотеза верна? Это вопрос с подвохом: как мы выяснили ранее, для непрерывных распределений вероятность получить отдельное число равна 0. Но мы можем посчитать, какая вероятность получить такую же или большую \\(z\\)-статистику!\nГрафически эту вероятность можно представить как площадь под кривой функции плотности распределения от полученной \\(z\\)-статистики до плюс бесконечности или от минус бесконечности до полученной \\(z\\)-статистики, если \\(z\\)-статистика отрицательная.\n Или же можем воспользоваться функцией накопленной плотности распределения. Для нормального распределения это можно сделать с помощью уже знакомой нам функции pnorm():\n\npnorm(z)\n\n[1] 0.6274655\n\n\npnorm() считает от минус бесконечности до заданного числа, а нам нужно наоборот — от заданного числа до плюс бесконечности, потому что \\(z\\) отличается от 0 в большую сторону. Этого можно добиться вычетанием из 1 6:\n\n1 - pnorm(z)\n\n[1] 0.3725345\n\n\nОбычно это число еще и умножают на 2, потому что мы заранее не знаем, в какую сторону будет отклоняться среднее по нашей выборке. Вернемся к шагу 1: мы сформулировали ненулевую гипотезу таким образом, что среднее генеральной совокупности не равно 100:\n\\[H_1: \\mu \\ne 100\\]\nЭто означает, что \\(H_1\\) включает в себя как случаи, когда среднее отклоняется в большую сторону, так и случаи когда среднее отклоняется в меньшую сторону.\n\np <- (1 - pnorm(z))*2\np\n\n[1] 0.7450689\n\n\nВот эта число и есть p-value — вероятность получения такого же и более экстремального значения тестовой статистики при условии, что нулевая гипотеза верна.\n4. Принятие решения о гипотезах\nОтлично, мы посчитали p-value. В данном конкретном случае он оказался равен 0.7450689. Это много или мало? Фактически это означает, что если нулевая гипотеза верна, то в большинстве случаев мы будем получать z-статистики больше нашей. Короче говоря, это вполне реалистичный случай, если нулевая гипотеза верна.\nЗначит ли это, что нулевая гипотеза верна? Нет, не значит. При тестировании значимости нулевой гипотезы мы в принципе ничего не можем сказать про верность альтернативной гипотезы. Например, возможно, настоящее среднее в генеральной совокупности, из которой мы взяли выборку, очень мало отличается от 100.\nПоэтому если p-value достаточно большой, мы не можем сделать выводов про верность нулевой и альтернативной гипотезы. Мы можем лишь сказать, что у нас нет оснований отклонить нулевую гипотезу.\nЕсли же p-value очень маленький, то здесь у нас появляется больше однозначности. Например, если p-value равен .02, мы можем сказать, что ситуация малореалистичная: такие и более сильные отклонения от среднего мы можем получить только раз в 50 случаев, если \\(H_0\\) верна. Поэтому мы отклоняем \\(H_0\\) и принимаем \\(H_1\\).\nНасколько маленьким должен быть p-value, чтобы отклонить нулевую гипотезу? Критическое значение p-value, при котором отклоняют нулевую гипотезу, называется уровнем \\(\\alpha\\). Это максимальный уровень ошибки, который мы допускаем в исследовании.\nТак получилось исторически, что стандартный уровень \\(\\alpha\\) равен .05. Нужно помнить, что .05 — это просто общепринятая условность, за этим числом не стоит никакого сакрального знания. Просто так получилось.\nОчевидно, что такой статистический подход к принятию решений будет периодически приводить к нас ошибкам. Если \\(H_0\\) на самом деле верна, а мы ее отвергли и приняли \\(H_1\\), то это ошибка первого рода (type I error). Вероятность этой ошибки и есть наше критическое значение \\(\\alpha\\). Однако есть вероятность ошибиться и в другую сторону, т.е. ошибочно не отклонить \\(H_0\\) — это ошибка второго рода (type II error), эта вероятность обозначается буквой \\(\\beta\\).\n\n\n\n\n\n\n\n\nПринятое решение  Реальность\n\\(H_0\\) верна\n\\(H_1\\) верна\n\n\n\n\nНе отклоняем \\(H_0\\)\nВерный пропуск\nОшибка 2 рода (type II error)\n\n\nОтклоняем \\(H_0\\)\nОшибка 1 рода (type I error)\nВерное попадание"
  },
  {
    "objectID": "320-ttest.html#sec-one_ttest",
    "href": "320-ttest.html#sec-one_ttest",
    "title": "18  t-тест",
    "section": "18.1 Одновыборочный t-тест",
    "text": "18.1 Одновыборочный t-тест\nМы научились делать z-тест. Однако на практике он не используется, потому что предполагает, что мы откуда-то знаем стандартное отклонение в генеральной совокупности. На практике это обычно не так, поэтому мы оцениваем стандартное отклонение в генеральной совокупности на основе стандартного отклонения по выборке. Это приводит к тому, что тестовая статистика уже не распределена нормально, а распределена согласно t-распределению. Ну и статистика уже называется t-статистикой.\n\\[t = \\frac{\\overline{x} - \\mu} {s_x / \\sqrt{N}} \\]\n\nИногда это t-распределение называют t-распределением Стьюдента, а соответствующий статистический тест - критерий Стьюдента. Дело в том, что его открыл сотрудник пивоварни Гиннесс Уильям Госсет. Сотрудникам Гиннесса было запрещено публиковать научные работы под своим именем, поэтому он написал свою знаменитую работу про t-распределение под псевдонимом “Ученик” (Student).\n\nФорма этого распределения очень похожа на форму нормального распределения, но имеет более тяжелые “хвосты” распределения. При этом эта форма зависит от размера выборки: чем больше выборка, тем ближе распределение к нормальному. Этот параметр распределения называется степенями свободы (degrees of freedom) и вычисляется как \\(N - 1\\), где \\(N\\) - это размер выборки.\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\n\nКак видите, чем больше выборка (и количество степеней свободы соответственно), тем ближе t-распределение к стандартному нормальному распределению. При 100 степенях свободы они уже почти не различимы! Поэтому на больших выборках разница между t-тестом и z-тестом будет минимальна, тогда как на маленьких выборках разница может быть значительной.\nДавайте посчитаем t-статистику на тех же симулированных данных:\n\nset.seed(42)\nsamp <- rnorm(100, 100, 15)\nm <- mean(samp)\nsem <- sd(samp)/sqrt(length(samp))\nt <- (m - 100)/sem\nt\n\n[1] 0.3122351\n\n\nДавайте для сравнения еще раз посчитаем z-статистику:\n\n(m - 100) / (15/sqrt(100))\n\n[1] 0.3251482\n\n\nКак видите, расчет довольно схожий, разница только в том, откуда мы берем стандартное отклонение. Для z-статистики у нас был заранее известный параметр генеральной совокупности (что обычно не так), для t-статистики мы оценивали стандартное отклонение по выборке.\nДавайте теперь посчитаем p-value. Мы будем пользоваться не функцией pnorm(), а функцией pt(), а в качестве параметра распределения указать количество степеней свобод в df =\n\npt(t, df = length(samp) - 1)\n\n[1] 0.6222407\n\n\nФункция pt() считает от минус бесконечности до \\(t\\), а нам нужно от \\(t\\) до плюс бесконечности, потому что \\(t\\) больше 0:\n\n1 - pt(t, df = length(samp) - 1)\n\n[1] 0.3777593\n\n\nИ не забываем умножать на 2, если мы хотим сделать двусторонний тест.\n\n(1 - pt(t, df = length(samp) - 1))*2\n\n[1] 0.7555186\n\n\nВ отличие от z-теста, t-тест есть в базовом R.\n\nt.test(samp, mu = 100)\n\n\n    One Sample t-test\n\ndata:  samp\nt = 0.31224, df = 99, p-value = 0.7555\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n  97.38831 103.58714\nsample estimates:\nmean of x \n 100.4877 \n\n\nДа, конечно, мы могли сразу запустить эту функцию и получить результаты. Обычно именно так вы и будете делать. Зато теперь вы знаете, что стоит за всеми числами в результате выполнения функции t.test(). Здесь можно увидеть выборочное среднее как оценку среднего в генеральной совокупности, 95% доверительный интервал для оценки среднего в генеральной совокупности, t-статистику, степени свобод и p-value."
  },
  {
    "objectID": "320-ttest.html#sec-two_ttest",
    "href": "320-ttest.html#sec-two_ttest",
    "title": "18  t-тест",
    "section": "18.2 Двухвыборочный t-тест",
    "text": "18.2 Двухвыборочный t-тест\nОдна из наиболее часто встречающихся задач при анализе данных - это сравнение средних двух выборок. Для этого нам тоже понадобится t-тест, но теперь \\(H_0\\) нужно сформулировать по-другому: что две генеральные совокупности (из которых взяты соответствующие выборки) имеют одинаковое среднее. \\[H_0: \\mu_1 = \\mu_2\\]\nНу а альтернативная гипотеза, что эти две выборки взяты из распределений с разным средним в генеральной совокупности. \\[H_1: \\mu_1 \\ne \\mu_2\\]\nЕсть две разновидности двухвыборочного t-теста: зависимый t-тест и независимый t-тест. Различие между зависимыми и независимыми тестами принципиальное, мы с ним еще будем сталкиваться.\nЗависимые тесты предполагают, что каждому значению в одной выборке мы можем поставить соответствующее значение из другой выборки. Обычно это повторные измерения какого-либо признака в разные моменты времени. В независимых тестах нет возможности сопоставить одно значение с другим. Мы уже не можем напрямую соотнести значения в двух выборках друг с другом, более того, размер двух выборок может быть разным!\nИспользование зависимых и независимых тестов связано с использованием внутрииндивидуального и межиндивидуального экспериментальных дизайнов в планировании научных экспериментов. Даже если вы не планируете в дальнейшем заниматься проведением экспериментов, понимание различий между двумя видами дизайнов поможет вам понять разницу между зависимыми и независимыми тестами.\nНапример, мы хотим исследовать влияние кофеина на скорость реакции. Можно поступить по-разному:\n\nНабрать выборку, каждому испытуемому дать либо кофеин (например, в виде раствора небольшого количества кофеина в воде), либо обычную воду. Что именно получит испытуемый получит определяется случайным образом. Испытуемый не должен знать, что ему дают (слепое тестирование), а в идеале этого должен не знать даже экспериментатор, который дает напиток и измеряет показатели (двойное слепое тестирование). Посчитать скорость выполнения выбранной задачи, отправить домой. Это межинидивидуальный экспериментальный дизайн, для анализа результатов которого нам понадобится независимый t-тест.\nНабрать выборку, каждому испытуемому дать и обычную воду, и воду с кофеином, записывать скорость решения задач после употребления простой воды и после употребления воды с кофеином, соответственно. В данном случае будет случайным образом варьироваться порядок предъявления: одни испытуемые сначала получат обычную воду, а потом воду с кофеином, другие испытуемые — наоборот. Для такого эксперимента понадобится меньше участников, но оно будет дольше для каждого участника. Более того, в этом случае мы учтем межиндивидуальные различия участников: одни участники в среднем решают задачи быстрее других. Это внутриинидивидуальный экспериментальный дизайн, для анализа результатов которого нам понадобится зависимый t-тест.\n\n\n\n\nВнутрииндивидуальный план\nМежиндивидуальный план\n\n\n\n\nЗависимый t-тест\nНезависимый t-тест\n\n\n\nИтак, с тем, когда использовать зависимый, а когда независимый t-тест, более-менее разобрались, давайте опробуем их!\n\n18.2.1 Двухвыборочный зависимый t-тест\nДвухвыборочный зависимый t-тест — это то же самое, что и одновыборочный t-тест, только для разницы между связанными значениями. Поскольку наша нулевая гипотеза звучит, что средние должны быть равны,\n\\[H_0: \\mu_1 = \\mu_2\\]\nто при верности нулевой гипотезы \\[\\mu_1 - \\mu_2 = 0\\].\nТогда вместо \\(x\\) подставим \\(d\\) — разницу (вектор разниц) между парами значений. Получаем вот что:\n\\[t = \\frac{\\overline{x} - \\mu} {s_x / \\sqrt{N}} = \\frac{\\overline{d} - (\\mu_1 - \\mu_2)} {s_d / \\sqrt{N}} = \\frac{\\overline{d} - 0} {s_d / \\sqrt{N}}  = \\frac{\\overline{d}} {s_d / \\sqrt{N}}\\]\nМы будем использовать данные с курса по статистике Университета Шеффилда про эффективность диет. Мы вытащим оттуда данные по диете номер 1 и посмотрим, действительно ли она помогает сбросить вес.\n\nlibrary(tidyverse)\ndiet <- readr::read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv\")\n\nRows: 78 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): Person, gender, Age, Height, pre.weight, Diet, weight6weeks\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndiet1 <- diet %>%\n  filter(Diet == 1)\n\nПровести двухвыборочный t-тест можно в R двумя базовыми способами. Первый вариант - это дать два вектора значений. Это удобно в случае широкого формата данных.\n\nt.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  diet1$pre.weight and diet1$weight6weeks\nt = 7.2168, df = 23, p-value = 2.397e-07\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.354069 4.245931\nsample estimates:\nmean difference \n            3.3 \n\n\nВторой вариант - используя формулы. Это удобно при длинном формате данных:\n\ndiet1_long <- diet1 %>%\n  pivot_longer(\n  cols = c(pre.weight, weight6weeks),\n  names_to = \"when\",\n  values_to = \"weight\"\n  )\n  \n\nt.test(weight ~ when, data = diet1_long, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  weight by when\nt = 7.2168, df = 23, p-value = 2.397e-07\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.354069 4.245931\nsample estimates:\nmean difference \n            3.3 \n\nt.test(diet1_long$weight ~ diet1_long$when, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  diet1_long$weight by diet1_long$when\nt = 7.2168, df = 23, p-value = 2.397e-07\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.354069 4.245931\nsample estimates:\nmean difference \n            3.3 \n\n\nВ обоих вариантах мы использовали paired = TRUE , чтобы обозначить использование именно зависимого (т.е. парного) t-теста.\n\n\n\nВнутрииндивидуальный план\nМежиндивидуальный план\n\n\n\n\nЗависимый t-тест\nНезависимый t-тест\n\n\nt.test(..., paired = TRUE)\nt.test(..., paired = FALSE)\n\n\n\n\n\n18.2.2 Двухвыборочный независимый t-тест\nВ случае независимого t-теста формула отличается. Однако гипотеза остается такой же и логика примерна та же.\nУ двух выборок могут различаться стандартные отклонения, поэтому для подсчет стандартной ошибки разницы средних для независимых выборок нужно сначала посчитать объединенное стандартное отклонение (pooled standard deviation):\n\\[s^2_{pool} = \\frac {(n_1-1)s^2_1 + (n_2-1)s^2_2} {(n_1 - 1) + (n_2 -1)}\\]\nТогда стандартная ошибка разницы средних считается следующим образом:\n\\[se_{m_1 - m_2} = \\sqrt {(s^2_{pool}) (\\frac {1} {n_1} + \\frac {1}{n_2} )}\\]\nВыглядит сложно, но по своей сути это что-то вроде усредненного стандартного отклонения (с учетом размеров выборок). Ну а t-статистика затем считается просто:\n\\[t = \\frac {(m_1 - m_2) - (\\mu_1 - \\mu_2)} {se_{m_1 - m_2}} = \\frac {(m_1 - m_2) - 0} {se_{m_1 - m_2}} = \\frac {m_1 - m_2} {se_{m_1 - m_2}}\\]\nДавайте теперь опробуем независимый t-тест для сравнения веса испытуемых двух групп после диеты. Мы снова воспользуемся функцией t.test(), но теперь уже поставим paired = FALSE:\n\ndiet12 <- diet %>%\n  filter(Diet %in% 1:2)\nt.test(weight6weeks ~ Diet, data = diet12, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  weight6weeks by Diet\nt = 0.5711, df = 48.724, p-value = 0.5706\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -3.753268  6.732897\nsample estimates:\nmean in group 1 mean in group 2 \n       69.57500        68.08519 \n\n\nЕсли присмотритесь, то увидите, что со степенями свободы что-то странное. Они дробные! Дело в том, что мы провели не совсем “настоящий” t-тест, а его очень близкую альтернативу под названием тест Уэлча (Welch test), который иногда называют поправкой Уэлча к t-тесту. Эта поправка позволяет тесту лучше справляться с выборками с разной дисперсией. Даже если у нас нет проблем с разной дисперсией, то от поправки Уэлча хуже не будет, поэтому это вариант по умолчанию в R.\nНо если его хочется отключить, то нужно поставить var.equal = TRUE.\n\nt.test(weight6weeks ~ Diet, data = diet12, paired = FALSE, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  weight6weeks by Diet\nt = 0.5645, df = 49, p-value = 0.575\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -3.813769  6.793399\nsample estimates:\nmean in group 1 mean in group 2 \n       69.57500        68.08519"
  },
  {
    "objectID": "320-ttest.html#sec-assumptions_ttest",
    "href": "320-ttest.html#sec-assumptions_ttest",
    "title": "18  t-тест",
    "section": "18.3 Допущения t-теста",
    "text": "18.3 Допущения t-теста\nЧтобы подсчет p-value был корректным, некоторые допущения должны быть выполнены.\n\nНормальное распределение. Это самое известное допущение, но чуть ли не наименее важное. Часто утверждается, что выборки должны быть взяты из нормального распределения. Это не совсем так: да, верно, это достаточное условие, но не необходимое. В первую очередь, важно именно выборочное распределение (средних разниц или разниц средних), которое достигается за счет центральной предельной теоремы (Глава 17.8) особенно при большой выборке ?sec-normality. Отсюда и все правила в духе “для t-теста распределение должно быть нормальным, но если n > 30, то это необязательно”. Откуда именно 30? Да ниоткуда, просто. Как и со всеми точными числами в статистике.\n\nДля проверки на нормальность существуют различные статистические тесты. Самый известный из них — тест Шапиро-Уилка. Его можно провести в R при помощи функции shapiro.test().\n\nshapiro.test(samp)\n\n\n    Shapiro-Wilk normality test\n\ndata:  samp\nW = 0.98122, p-value = 0.1654\n\n\nВ нашем случае p-value больше 0.05, что логично: мы взяли эту выборку именно из нормального распределения. Если p-value меньше уровня \\(\\alpha\\), который у нас стандартно 0.05, то мы можем отвергнуть нулевую гипотезу о том, что выборка взята из нормального распределения. Если это так, то нам нужно, по идее, отказаться от t-теста и использовать непараметрический тест, который не имеет требований к распределению исследуемой переменной.\nОднако проведения теста на нормальность для проверки допущения о нормальности — вещь довольно бессмысленная. Дело в том, что тест Шапиро-Уилка — это такой же статистический тест, как и все прочие: чем больше выборка, тем с большей вероятностью он “поймает” отклонения от нормальности, чем меньше выборка, тем с меньшей вероятностью он обнаружит даже серьезные отклонения от нормальности. А нам-то нужно наоборот! При большой выборке отклонения от нормальности нам не особо страшны, а при маленькой тест все равно ничего не обнаружит. Более того, идеально нормальных распределений в природе вообще почти не существует! А это значит, что при достаточно большой выборке тест Шапиро-Уилка практически всегда будет находить отклонения от нормальности. Все это делает его малоинформативным при тестировании допущения о нормальности. Это же верно и для других тестов на нормальность.\nДругой способ проверять допущение о нормальности — это проверять визуально с помощью гистограммы или Q-Q plot (см. @ref(lm_a))\n\nДля двувыборочного независимого t-теста выборки должны быть взяты из распределения с одинаковыми дисперсиями. Однако это не так критично с применением поправки Уэлча.\nНезависимость значений (или пар) в выборке. Типичным примером нарушения независимости является случай, когда t-тест применяется на неусредненных (например, по испытуемому) значениях. Еще один пример нарушения независимости — использование одного наблюдения несколько раз или использование одного и того же испытуемого несколько раз. Определить независимость можно следующим мысленным экспериментом: могу ли я хоть как-нибудь предсказать следующее значение в выборке? Например, в случае с несколькими значениями от одного испытуемого я могу ориентироваться на его предыдущие результаты и предсказать последующие результаты лучше, чем на основе простого среднего по всем остальным значениям. Это значит, что допущение о независимости нарушено."
  },
  {
    "objectID": "320-ttest.html#sec-nonparam_ttest",
    "href": "320-ttest.html#sec-nonparam_ttest",
    "title": "18  t-тест",
    "section": "18.4 Непараметрические аналоги t-теста",
    "text": "18.4 Непараметрические аналоги t-теста\nЕсли выборка не очень большая и взята из сильно ассиметричного распределения или выборка представляет собой порядковые данные, то можно воспользоваться непараметрическими альтернативами для t-теста.\nНепараметрические тесты не имеют допущений о распределении, что делает их более универсальными. Большинство подобных тестов подразумевает превращение данных в ранги, т.е. внутри этих тестов происходит преобразование в ранговую шкалу. Такое преобразование может снизить статистическую мощность теста и привести к повышению вероятности ошибки второго рода.\n\n18.4.1 Тест Уилкоксона\nНепараметрический аналог двустороннего зависимого t-теста называется тестом Уилкоксона. Функция для него называется wilcox.test(), и она имеет такой же синтаксис, как и t.test().\n\nwilcox.test(weight ~ when, data = diet1_long, paired = TRUE)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  weight by when\nV = 299, p-value = 2.203e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nНе пугайтесь, когда видите сообщение “Есть совпадающие значения: не могу высчитать точное p-значение”. Это означает, что в ваших данных есть повторяющиеся значения, поэтому расчет p-value в данном случае — это некоторая апроксимация, но в большинстве случаев это не играет серьезной роли.\n\n\n\n18.4.2 Тест Манна-Уитни\nНепараметрическим аналогом двустороннего независимого t-теста является тест Манна-Уитни. Для него тоже используется функция wilcox.test(), только в данном случае с параметром paired = FALSE.\n\nwilcox.test(weight ~ when, data = diet1_long, paired = FALSE)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  weight by when\nW = 357.5, p-value = 0.1546\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\n\n\n\nВнутрииндивидуальный план\nМежиндивидуальный план\n\n\n\n\nЗависимый t-тест:\nНезависимый t-тест:\n\n\nt.test(..., paired = TRUE)\nt.test(..., paired = FALSE)\n\n\nТест Уилкоксона:\nТест Манна-Уитни:\n\n\nwilcox.test(..., paired = TRUE)\nwilcox.test(..., paired = FALSE)"
  },
  {
    "objectID": "330-cov_cor.html#sec-cov",
    "href": "330-cov_cor.html#sec-cov",
    "title": "19  Ковариация и корреляция",
    "section": "19.1 Ковариация",
    "text": "19.1 Ковариация\nСамая простая мера связи между двумя переменными — это ковариация. Если ковариация положительная, то чем больше одна переменная, тем больше другая переменная. При отрицательной ковариации все наоборот: чем больше одна переменная, тем меньше другая.\n\nФормула ковариации:\n\n\\[\\sigma_{xy} = cov(x, y) = \\frac{\\sum_{i = 1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{n}\\]\n\nОценка ковариации по выборке:\n\n\\[\\hat{\\sigma}_{xy} = \\frac{\\sum_{i = 1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\]\nКовариация переменной самой с собой — дисперсия.\nВ R есть функция cov() для подсчета ковариации. На самом деле, функция var() делает то же самое. Обе эти функции считают сразу матрицу ковариаций для всех сочетаний колонок на входе:\n\nback %>%\n  select(body_kg, backpack_kg) %>%\n  cov()\n\n               body_kg backpack_kg\nbody_kg     177.807700    6.601954\nbackpack_kg   6.601954    6.838333\n\nback %>%\n  select(body_kg, backpack_kg) %>%\n  var()\n\n               body_kg backpack_kg\nbody_kg     177.807700    6.601954\nbackpack_kg   6.601954    6.838333\n\n\nНу а по углам этой матрицы – дисперсии!\nОднако у ковариации есть серьезное ограничение – ее размер привязан к исходной шкале, поэтому сложно оценить, насколько ковариация большая или маленькая. Поэтому на практике гораздо больше используются коэффициенты корреляции."
  },
  {
    "objectID": "330-cov_cor.html#sec-cor",
    "href": "330-cov_cor.html#sec-cor",
    "title": "19  Ковариация и корреляция",
    "section": "19.2 Корреляция",
    "text": "19.2 Корреляция\nКорреляцией обычно называют любую связь между двумя переменными, это просто синоним слова “ассоциация”. Если вдруг слово “корреляция” вам еще непривычно, то попробуйте мысленно заменять “корреляцию” на “ассоциацию”, а “коррелирует” на “связано”. Коэффициент корреляции — это уже конкретная математическая формула, которая позволяет посчитать эту связь и принимает значения от -1 до 1.1\n\nЕсли коэффициент корреляции положительный, то чем больше значения в одной переменной, тем больше значения в другой переменной.\nЕсли коэффициент корреляции отрицательный, то чем больше значения в одной переменной, тем меньше значения в другой переменной.\nЕсли коэффициент корреляции равен 0, то изменения одной переменной не связано с изменениями в другой переменной.\n\n\n19.2.1 Коэффициент корреляции Пирсона\nСамый известный коэффициент корреляции - коэффициент корреляции Пирсона:\n\\[\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y} = \\frac{\\sum_{i = 1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i = 1}^n(x_i - \\overline{x})^2}\\sqrt{\\sum_{i = 1}^n(y_i - \\overline{y})^2}} = \\frac{1}{n}\\sum_{i = 1}^n z_{x,i} z_{y, i}\\]\nОценка коэффициента корреляции Пирсона по выборке: \\[r_{xy} = \\frac{\\hat{\\sigma}_{xy}}{\\hat{\\sigma}_x \\hat{\\sigma}_y} = \\frac{\\sum_{i = 1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i = 1}^n(x_i - \\overline{x})^2}\\sqrt{\\sum_{i = 1}^n(y_i - \\overline{y})^2}} = \\frac{1}{n - 1}\\sum_{i = 1}^n z_{x,i} z_{y, i}\\]\nКоэффициент корреляции Пирсона можно понимать по-разному. С одной стороны, это просто ковариация, нормированная на стандартное отклонение обоих переменных. С другой стороны, можно понимать это как среднее произведение z-оценок.\nКорреляцию в R можно посчитать с помощью функции cor():\n\nback %>%\n  select(body_kg, backpack_kg) %>%\n  cor()\n\n              body_kg backpack_kg\nbody_kg     1.0000000   0.1893312\nbackpack_kg 0.1893312   1.0000000\n\n\nДля тестирования уровня значимости нулевой гипотезы для корреляции есть функция cor.test(). В случае с коэффициентами корреляции, нулевая гипотеза формулируется как отсутствие корреляции (т.е. она равна нулю) в генеральной совокупности.\n\ncor.test(back$backpack_kg, back$body_kg)\n\n\n    Pearson's product-moment correlation\n\ndata:  back$backpack_kg and back$body_kg\nt = 1.9088, df = 98, p-value = 0.05921\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.007360697  0.371918344\nsample estimates:\n      cor \n0.1893312 \n\n\nРезультат выполнения этой функции очень похож на то, что мы получали при проведении t-теста.\n\n\n19.2.2 Непараметрические коэффициенты корреляции\nУ коэффициента корреляции Пирсона, как и у t-теста, есть свои непараметрические братья: коэффициент корреляции Спирмена и коэффициент корреляции Кэнделла. Из них чаще используется коэффициент корреляции Спирмена. Посчитать его можно с помощью той же функции cor.test(), задав соответствующее значение параметра method =:\n\ncor.test(back$backpack_kg, back$body_kg, method = \"spearman\")\n\nWarning in cor.test.default(back$backpack_kg, back$body_kg, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  back$backpack_kg and back$body_kg\nS = 131520, p-value = 0.03527\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2108001 \n\ncor.test(back$backpack_kg, back$body_kg, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  back$backpack_kg and back$body_kg\nz = 2.083, p-value = 0.03725\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.1478736 \n\n\n\nЗаметьте, в данном случае два метода хотя и привели к схожим размерам корреляции, но в одном случае p-value оказался больше 0.05, а в другом случае - меньше 0.05. Выбирать тест a posteriori на основе того, какие результаты вам нравятся больше, — плохая практика (@ref(bad_practice)). Не надо так делать."
  },
  {
    "objectID": "330-cov_cor.html#sec-cor_mat",
    "href": "330-cov_cor.html#sec-cor_mat",
    "title": "19  Ковариация и корреляция",
    "section": "19.3 Корреляционная матрица",
    "text": "19.3 Корреляционная матрица\nВозможно, вы нашли что-то более интересное для проверки гипотезы о корреляции. Например, вы еще хотите проверить гипотезу о связи количества учебных кредитов и массе рюкзака: логично предположить, что чем больше студент набрал себе курсов, тем тяжелее его рюкзак (из-за большего количества учебников). Или что студенты к старшим курсам худеют и становятся меньше. Или что те, кто набрал себе много курсов, меньше питаются и от того меньше весят. В общем, хотелось бы прокоррелировать все интересующие нас переменные со всеми. Это можно сделать с помощью функции cor():\n\nback %>%\n  select(body_kg, backpack_kg, Units, Year) %>%\n  cor()\n\n                body_kg backpack_kg       Units        Year\nbody_kg      1.00000000  0.18933115 -0.23524088 -0.09301727\nbackpack_kg  0.18933115  1.00000000  0.09438453  0.05762194\nUnits       -0.23524088  0.09438453  1.00000000 -0.02946373\nYear        -0.09301727  0.05762194 -0.02946373  1.00000000\n\n\nНо функция cor()не позволяет посчитать p-value для этих корреляций! Функция cor.test() позволяет получить p-value, но только для одной пары переменных.\nНа помощь приходит пакет psych с функцией corr.test():\n\nback %>%\n  select(body_kg, backpack_kg, Units, Year) %>%\n  psych::corr.test()\n\nCall:psych::corr.test(x = .)\nCorrelation matrix \n            body_kg backpack_kg Units  Year\nbody_kg        1.00        0.19 -0.24 -0.09\nbackpack_kg    0.19        1.00  0.09  0.06\nUnits         -0.24        0.09  1.00 -0.03\nYear          -0.09        0.06 -0.03  1.00\nSample Size \n[1] 100\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n            body_kg backpack_kg Units Year\nbody_kg        0.00        0.30  0.11    1\nbackpack_kg    0.06        0.00  1.00    1\nUnits          0.02        0.35  0.00    1\nYear           0.36        0.57  0.77    0\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\nТем не менее, если у вас много гипотез для тестирования, то у вас появляется проблема: вероятность выпадения статистически значимых результатов сильно повышается. Даже если эти переменные никак не связаны друг с другом.\nЭта проблема называется проблемой множественных сравнений (multiple comparisons problem) 2. Если мы проверяем сразу несколько гипотез, то у нас возрастает групповая вероятность ошибки первого рода (Family-wise error rate) — вероятность ошибки первого рода для хотя бы одной из множества гипотез.\nНапример, если вы коррелируете 10 переменных друг с другом, то вы проверяете 45 гипотез о связи. Пять процентов из этих гипотез, т.е. в среднем 2-3 гипотезы у вас будут статистически значимыми даже если никаких эффектов на самом деле нет!\nПоэтому если вы проверяете сразу много гипотез, то необходимо применять поправки на множественные сравнения (multiple testing correction). Эти поправки позволяют контролировать групповую вероятность ошибки первого рода на желаемом уровне. Самая простая и популярная поправка на множественные сравнения — поправка Бонферрони (Bonferroni correction). Она считается очень просто: мы просто умножаем p-value на количество проверяемых гипотез!\n\nback %>%\n  select(body_kg, backpack_kg, Units, Year) %>%\n  psych::corr.test(adjust = \"bonferroni\")\n\nCall:psych::corr.test(x = ., adjust = \"bonferroni\")\nCorrelation matrix \n            body_kg backpack_kg Units  Year\nbody_kg        1.00        0.19 -0.24 -0.09\nbackpack_kg    0.19        1.00  0.09  0.06\nUnits         -0.24        0.09  1.00 -0.03\nYear          -0.09        0.06 -0.03  1.00\nSample Size \n[1] 100\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n            body_kg backpack_kg Units Year\nbody_kg        0.00        0.36  0.11    1\nbackpack_kg    0.06        0.00  1.00    1\nUnits          0.02        0.35  0.00    1\nYear           0.36        0.57  0.77    0\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\nЭто очень “дубовая” и излишне консервативная поправка. Да, она гарантирует контроль групповую вероятности ошибки первого рода, но при этом сильно повышает вероятность ошибки второго рода — вероятность пропустить эффект, если он на самом деле существует. Поэтому по умолчанию в R используется более либеральная поправка на множественные сравнения под названием поправка Холма или поправка Холма-Бонферрони (Holm-Bonferroni correction), которая, тем не менее, тоже гарантирует контроль групповой вероятности ошибки первого рода.\nАльтернативный подход к решению проблемы множественных сравнений — это контроль средней доли ложных отклонений (False Discovery Rate; FDR) на на уровне не выше уровня \\(\\alpha\\). Это более либеральный подход: в данном случае мы контролируем, что ложно-положительных результатов у нас не больше, например, 5%. Такой подход применяется в областях, где происходит масштабное множественное тестирование. Попытка контролировать групповую вероятность ошибки первого уровня не выше уровня \\(\\alpha\\) привела бы к чрезвычайно низкой вероятности обнаружить хоть какие-нибудь эффекты (т.е. к низкой статистической мощности).\nСамая известная поправка для контроля средней доли ложных отклонений — это поправка Бенджамини — Хохберга (Benjamini-Hochberg correction).\n\nback %>%\n  select(body_kg, backpack_kg, Units, Year) %>%\n  psych::corr.test(adjust = \"BH\")\n\nCall:psych::corr.test(x = ., adjust = \"BH\")\nCorrelation matrix \n            body_kg backpack_kg Units  Year\nbody_kg        1.00        0.19 -0.24 -0.09\nbackpack_kg    0.19        1.00  0.09  0.06\nUnits         -0.24        0.09  1.00 -0.03\nYear          -0.09        0.06 -0.03  1.00\nSample Size \n[1] 100\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n            body_kg backpack_kg Units Year\nbody_kg        0.00        0.18  0.11 0.54\nbackpack_kg    0.06        0.00  0.54 0.68\nUnits          0.02        0.35  0.00 0.77\nYear           0.36        0.57  0.77 0.00\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\nВсе перечсиленные поправки (и еще несколько других) доступны не только в функции corr.test(), но и в базовом R с помощью функции p.adjust(). Эта функция принимает вектор из p-value и возвращает результат применения поправок.\n\np_vec <- seq(0.0001, 0.06, length.out = 10)\np_vec\n\n [1] 0.000100000 0.006755556 0.013411111 0.020066667 0.026722222 0.033377778\n [7] 0.040033333 0.046688889 0.053344444 0.060000000\n\np.adjust(p_vec) #по умолчанию используется поправка Холма-Бонферрони\n\n [1] 0.0010000 0.0608000 0.1072889 0.1404667 0.1603333 0.1668889 0.1668889\n [8] 0.1668889 0.1668889 0.1668889\n\np.adjust(p_vec, method = \"bonferroni\")\n\n [1] 0.00100000 0.06755556 0.13411111 0.20066667 0.26722222 0.33377778\n [7] 0.40033333 0.46688889 0.53344444 0.60000000\n\np.adjust(p_vec, method = \"BH\")\n\n [1] 0.00100000 0.03377778 0.04470370 0.05016667 0.05344444 0.05562963\n [7] 0.05719048 0.05836111 0.05927160 0.06000000"
  },
  {
    "objectID": "330-cov_cor.html#sec-hitmap_cor",
    "href": "330-cov_cor.html#sec-hitmap_cor",
    "title": "19  Ковариация и корреляция",
    "section": "19.4 Хитмэп корреляций",
    "text": "19.4 Хитмэп корреляций\nКак видите, почти все коррелирует друг с другом, даже с учетом поправок. Такие множественные корреляции лучше всего смотреть с помощью хитмап-визуализации.\nВ качестве примера возьмем встроенный датасет mtcars, в котором есть множество количественных переменных.\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nДля визуализации возьмем пакет {corrplot}.\n\ninstall.packages(\"corrplot\")\n\nДля начала нам нужно построить матрицу корреляций. Уже знакомая нам функция cor() для это вполне подойдет:\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncor(mtcars)\n\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n\n\nОсновная функция пакета {corrplot} – функция corrplot(). Давайте теперь попробуем ее применить на нашей матрице корреляций.\n\ncorrplot(cor(mtcars))\n\n\n\n\nПо умолчанию значение корреляций кодируется цветом и размером круга. У функции corrplot() есть множество параметров, позволяющих довольно тонко настраивать хитмэп корреляций. Например, можнокодировать только цветом, а переменные сгруппировать на основе кластеризации.\n\ncorrplot(cor(mtcars), method = \"color\", order = \"hclust\")"
  },
  {
    "objectID": "330-cov_cor.html#матрица-корреляций-в-виде-графа",
    "href": "330-cov_cor.html#матрица-корреляций-в-виде-графа",
    "title": "19  Ковариация и корреляция",
    "section": "19.5 Матрица корреляций в виде графа",
    "text": "19.5 Матрица корреляций в виде графа\n\ninstall.packages(\"corrr\")\n\n\nlibrary(corrr)\n\nФункционал пакета {corrr} позволяет работать с корреляционными матрицами в духе tidyverse, возвращая тиббл вместо матрицы.\n\ncorrelate(mtcars)\n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\n\n# A tibble: 11 × 12\n   term     mpg    cyl   disp     hp    drat     wt    qsec     vs      am\n   <chr>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1 mpg   NA     -0.852 -0.848 -0.776  0.681  -0.868  0.419   0.664  0.600 \n 2 cyl   -0.852 NA      0.902  0.832 -0.700   0.782 -0.591  -0.811 -0.523 \n 3 disp  -0.848  0.902 NA      0.791 -0.710   0.888 -0.434  -0.710 -0.591 \n 4 hp    -0.776  0.832  0.791 NA     -0.449   0.659 -0.708  -0.723 -0.243 \n 5 drat   0.681 -0.700 -0.710 -0.449 NA      -0.712  0.0912  0.440  0.713 \n 6 wt    -0.868  0.782  0.888  0.659 -0.712  NA     -0.175  -0.555 -0.692 \n 7 qsec   0.419 -0.591 -0.434 -0.708  0.0912 -0.175 NA       0.745 -0.230 \n 8 vs     0.664 -0.811 -0.710 -0.723  0.440  -0.555  0.745  NA      0.168 \n 9 am     0.600 -0.523 -0.591 -0.243  0.713  -0.692 -0.230   0.168 NA     \n10 gear   0.480 -0.493 -0.556 -0.126  0.700  -0.583 -0.213   0.206  0.794 \n11 carb  -0.551  0.527  0.395  0.750 -0.0908  0.428 -0.656  -0.570  0.0575\n# … with 2 more variables: gear <dbl>, carb <dbl>\n\n\nНас же интересует в первую очередь представление матрицы корреляций в виде графа.\nДелается это следующим образом: мы устанавливаем минимальное значение для корреляций с помощью параметра min_cor =, которые будут отображены в качестве связи между переменными. Если мы этого не сделаем, то мы просто получим полностью связанный граф, потому что все переменные хотя бы немного коррелируют со всеми. По умолчанию этот параметр равен 0.3, но мы можем изменить это значение на собственное усмотрение. В данном случае установим min_cor = 0.7, потому что в нашей матрице очень много сильных корреляций.\n\ncorrelate(mtcars) %>%\n  corrr::network_plot(min_cor = 0.7)\n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'"
  },
  {
    "objectID": "340-lm.html#sec-lm_func",
    "href": "340-lm.html#sec-lm_func",
    "title": "20  Линейная регрессия",
    "section": "20.1 Функция lm()",
    "text": "20.1 Функция lm()\nДавайте посчитаем линейную регрессию функцией lm().\n\nmodel <- lm(backpack_kg ~ body_kg, data = back)\nmodel\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg, data = back)\n\nCoefficients:\n(Intercept)      body_kg  \n    2.71125      0.03713  \n\n\nprint(model) или просто model выводит коэфициенты линейной регрессии - это коэффициенты прямой, которая лучше всего подогнанна к данным. Как измеряется качество этой подгонки? В расстоянии точек исходных точек до прямой. По идее, расстояние до прямой нужно было бы считать просто по модулю. И так делают, хоть и очень редко. Обычно в линейной регрессии используются квадратичные расстояния точек до прямой для оценки расстояния (метод наименьших квадратов - ordinary least squares). Это дает кучу клевых математических свойств, например, возможность легко аналитически найти коэффициенты прямой линейной регрессии.\nДавайте теперь нарисуем регрессионную прямую поверх диаграммы рассеяния:\n\nggplot(data = back,aes(x = body_kg, y = backpack_kg))+\n  geom_point(alpha = 0.3)+\n  geom_abline(slope = model$coefficients[2], intercept = model$coefficients[1])\n\n\n\n\nФункция predict() позволяет скормить модели новые данные и получить предсказания для новых значений предикторов. Попробуем поиграть с этим немного. Допустим, предскажем вес рюкзака для студента весом в 100 кг:\n\npredict(model, newdata = data.frame(body_kg = 100))\n\n       1 \n6.424229 \n\n\nМы можем даже попробовать какие-нибудь экстремальные значения для предикторов. Например, сколько будет весить рюкзак студента весом 1000 кг?\n\npredict(model, newdata = data.frame(body_kg = 1000))\n\n     1 \n39.841 \n\n\nОчевидно, что в этом не очень много смысла: студент весом 1000 кг не сможет ходить на занятия, поэтому и про вес рюкзака как-то не имеет смысл спрашивать. Это проблема экстрополяции: линейная регрессия позволяет более-менее достоверно предсказывать значения внутри диапазона значений, на которых была построена модель. Еще один “странный” пример - студент весом 0 кг.\n\npredict(model, newdata = data.frame(body_kg = 0))\n\n       1 \n2.711255 \n\n\nЗдесь бессмысленность происходящего еще очевиднее. Конечно, вес студента не может быть равен нулю, иначе это не студент вовсе. Однако это позволяет понять, что такое intercept модели - это значение зависимой переменой в случае, если предиктор равен нулю. А коэффициент предиктора означает, насколько килограммов увеличивается вес рюкзака при увеличении веса студента на 1 кг: на 0.0371297. Не очень много!"
  },
  {
    "objectID": "340-lm.html#sec-interpret_lm",
    "href": "340-lm.html#sec-interpret_lm",
    "title": "20  Линейная регрессия",
    "section": "20.2 Интерпретация вывода линейной регрессии",
    "text": "20.2 Интерпретация вывода линейной регрессии\nГораздо более подробные результаты мы получим, если применим уже известную нам generic функцию summary() на нашу модель.\n\nsummary(model)\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg, data = back)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.4853 -1.7629 -0.4681  1.2893  9.8803 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  2.71125    1.37483   1.972   0.0514 .\nbody_kg      0.03713    0.01945   1.909   0.0592 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.581 on 98 degrees of freedom\nMultiple R-squared:  0.03585,   Adjusted R-squared:  0.02601 \nF-statistic: 3.644 on 1 and 98 DF,  p-value: 0.05921\n\n\nТеперь мы понимаем, что это за коэффициенты. Однако это всего лишь их оценка. Это значит, что мы допускаем, что в реальности есть некие настоящие коэффициенты линейной регрессии, а каждый раз собирая новые данные, они будут посчитаны как немного разные. Короче говоря, эти коэффициенты - те же статистики, со своим выборочным распределением и стандартными ошибками. На основе чего и высчитывается p-value для каждого коэффициента - вероятность получить такой и более отклоняющийся от нуля коэффициент при верности нулевой гипотезы - независимости зависимой переменной от предиктора.\nКроме p-value, у линейной регрессии есть \\(R^2\\) - доля объясненной дисперсии. Как ее посчитать? Для начала давайте сохраним как отдельные колонки ошибки (необъясненную часть модели) и предсказанные значения (они означают объясненную часть модели). Можно убедиться, что сумма предсказанных значений и ошибок будет равна зависимой переменной.\n\nhead(model$residuals)\n\n         1          2          3          4          5          6 \n-0.7341441 -2.3666602 -0.1963429 -2.6001743 -2.1140337 -4.4853169 \n\nback$residuals <- residuals(model)\nback$fitted <-  fitted(model)\n\nback %>%\n  transmute(backpack_kg - (fitted + residuals))\n\n    backpack_kg - (fitted + residuals)\n1                         0.000000e+00\n2                         0.000000e+00\n3                         0.000000e+00\n4                        -4.440892e-16\n5                         4.440892e-16\n6                        -4.440892e-16\n7                         0.000000e+00\n8                         2.220446e-16\n9                         4.440892e-16\n10                        1.110223e-16\n11                       -4.440892e-16\n12                        0.000000e+00\n13                        0.000000e+00\n14                        0.000000e+00\n15                       -8.881784e-16\n16                        0.000000e+00\n17                        0.000000e+00\n18                        4.440892e-16\n19                        0.000000e+00\n20                       -4.440892e-16\n21                        0.000000e+00\n22                        0.000000e+00\n23                        0.000000e+00\n24                        0.000000e+00\n25                       -8.881784e-16\n26                        0.000000e+00\n27                        4.440892e-16\n28                        4.440892e-16\n29                        0.000000e+00\n30                       -4.440892e-16\n31                        0.000000e+00\n32                        0.000000e+00\n33                        0.000000e+00\n34                       -4.440892e-16\n35                        0.000000e+00\n36                        0.000000e+00\n37                        0.000000e+00\n38                        0.000000e+00\n39                       -2.220446e-16\n40                        0.000000e+00\n41                       -4.440892e-16\n42                        0.000000e+00\n43                        0.000000e+00\n44                        0.000000e+00\n45                        0.000000e+00\n46                       -4.440892e-16\n47                        0.000000e+00\n48                        4.440892e-16\n49                        0.000000e+00\n50                        8.881784e-16\n51                        0.000000e+00\n52                       -4.440892e-16\n53                        0.000000e+00\n54                        0.000000e+00\n55                        0.000000e+00\n56                        0.000000e+00\n57                        0.000000e+00\n58                        0.000000e+00\n59                        0.000000e+00\n60                        0.000000e+00\n61                        0.000000e+00\n62                        8.881784e-16\n63                        0.000000e+00\n64                       -4.440892e-16\n65                        0.000000e+00\n66                        0.000000e+00\n67                        0.000000e+00\n68                        8.881784e-16\n69                       -3.330669e-16\n70                       -4.440892e-16\n71                        4.440892e-16\n72                        0.000000e+00\n73                        8.881784e-16\n74                       -8.881784e-16\n75                        4.440892e-16\n76                        0.000000e+00\n77                        1.110223e-16\n78                       -4.440892e-16\n79                        0.000000e+00\n80                        0.000000e+00\n81                        0.000000e+00\n82                        0.000000e+00\n83                       -4.440892e-16\n84                        0.000000e+00\n85                        0.000000e+00\n86                        0.000000e+00\n87                        0.000000e+00\n88                       -8.881784e-16\n89                        0.000000e+00\n90                        0.000000e+00\n91                        0.000000e+00\n92                        0.000000e+00\n93                        0.000000e+00\n94                        0.000000e+00\n95                        0.000000e+00\n96                        0.000000e+00\n97                        0.000000e+00\n98                        0.000000e+00\n99                        0.000000e+00\n100                       0.000000e+00\n\n\nСоответственно, вся сумма объясненной дисперсии разделяется на объясненую и необъясненную. Полная дисперсия (total sum of squares = TSS) может быть посчитана как сумма квадратов разниц со средним. Необъясненная дисперсия - это сумма квадратов ошибок - residual sum of squares (RSS).\n\nrss <- sum(back$residuals^2)\nrss\n\n[1] 652.7272\n\ntss <- sum((back$backpack_kg - mean(back$backpack_kg))^2)\ntss\n\n[1] 676.995\n\n1- rss/tss\n\n[1] 0.03584628\n\n\nЭто очень мало, мы объяснили всего 3.5846285% дисперсии. Собственно, и p-value больше, чем 0.05.\n\nsummary(model)\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg, data = back)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.4853 -1.7629 -0.4681  1.2893  9.8803 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  2.71125    1.37483   1.972   0.0514 .\nbody_kg      0.03713    0.01945   1.909   0.0592 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.581 on 98 degrees of freedom\nMultiple R-squared:  0.03585,   Adjusted R-squared:  0.02601 \nF-statistic: 3.644 on 1 and 98 DF,  p-value: 0.05921\n\n\nПри этом p-value тот же, что и при коэффициенте корреляции Пирсона. Это не случайно: \\(R^2\\) - это квадрат коэффициента корреляции Пирсона, если речь идет только об одном предикторе. Давайте это проверим:\n\ncor.test(back$body_kg, back$backpack_kg)$estimate^2\n\n       cor \n0.03584628"
  },
  {
    "objectID": "340-lm.html#sec-lm_a",
    "href": "340-lm.html#sec-lm_a",
    "title": "20  Линейная регрессия",
    "section": "20.3 Допущения линейной регрессии",
    "text": "20.3 Допущения линейной регрессии\nКак и в случае с другими параметрическими методами, линейная регрессия имеет определенные допущения относительно используемых данных. Если они не соблюдаются, то все наши расчеты уровня значимости могут некорректными.\n\nОчень важно ставить вопрос о том, насколько результаты будут некорректными. Как сильно нарушения допущений будет влиять на модель? Ответ на этот вопрос может быть контринтуитивен. Например, достаточно большие отклонения от нормальности нам обычно не страшны при условии того, что выборка достаточно большая.\n\nДопущения линейной регрессии связаны с ошибками: они должны быть нормально распределены, а разброс ошибок должен не уменьшаться и не увеличиваться в зависимости от предсказанных значений. Это то, что называется гомоскедастичностью или гомогенностью (когда все хорошо) и гетероскедастичностью или гетерогенностью (когда все плохо).\nЕсли мы применим функцию plot(), то получим 4 скаттерплота:\n\nЗависимость ошибок от предсказанных значений. На что здесь смотреть? На симметричность относительно нижней и верхней части графика, на то, что разброс примерно одинаковый слева и справа.\nQ-Q plot. Здесь все довольно просто: если ошибки являются выборкой из нормального распределения, то они выстраиваются в прямую линию. Если это мало похоже на прямую линию, то имеет место отклонение от нормальности.\nScale-Location plot. Этот график очень похож на график 1, только по оси у используются квадратные корни модуля ошибки. Еще один способ исследовать гетеро(гомо)скедастичность и находить выбросы.\nResiduals-Leverage plot. Здесь по оси х - расстояние Кука, а по оси у - стандартизированный размер выбросов. Расстояние Кука показывает high-leverage points - точки, которые имеют экстремальные предсказанные значения, то есть очень большие или очень маленькие значения по предикторам. Для линейной регрессии такие значения имеют большее значение, чем экстремальные точки по предсказываемой переменной. Особенно сильное влияние имеют точки, которые имеют экстремальные значения и по предикторам, и по предсказываемой переменной. Одна такая точка может поменять направление регрессионной прямой! Расстояние Кука отражает уровень leverage, а стандартизированные ошибки отражают экстремальные значения по у (вернее, экстремальные отклонения от предсказанных значений). В этом графике нужно смотреть на точки с правой стороны графика, особенно если они находятся высоко или низко по оси у.\n\n\nplot(model)"
  },
  {
    "objectID": "340-lm.html#sec-outliers_lm",
    "href": "340-lm.html#sec-outliers_lm",
    "title": "20  Линейная регрессия",
    "section": "20.4 Влияние выбросов на линейную модель",
    "text": "20.4 Влияние выбросов на линейную модель\nДавайте теперь попробуем посмотреть, как изменится модель, если выкинуть high leverage points (экстремальные значения по предиктору - body) и что будет, если выкинуть экстремальные значения по у. Обычная линия - регрессионная прямая для модели со всеми точками, штрихованная линия - регрессионная прямая для модели без экстремальных значений по предиктору, пунктирная линия - регрессионная прямая для модели без экстремальных значений по предсказываемой переменной.\n\nis_outlier <- function(x, n = 2, centr = mean, vary = sd) {\n  (x > centr(x) + n * vary(x)) | (x < centr(x) - n * vary(x))\n}\n\nback <- back %>%\n  mutate(body_outlier = is_outlier(body_kg),\n         backpack_outlier = is_outlier(backpack_kg))\n\nmodel_without_outliers_by_x <- back %>%\n  filter(!body_outlier) %>%\n  lm(formula = backpack_kg ~ body_kg)\nsummary(model_without_outliers_by_x)\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6526 -1.7471 -0.3773  1.1699  9.0854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  0.48577    1.65749   0.293  0.77011   \nbody_kg      0.07128    0.02413   2.953  0.00397 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.548 on 94 degrees of freedom\nMultiple R-squared:  0.08491,   Adjusted R-squared:  0.07517 \nF-statistic: 8.722 on 1 and 94 DF,  p-value: 0.003971\n\nmodel_without_outliers_by_y <- back %>%\n  filter(!backpack_outlier) %>%\n  lm(formula = backpack_kg ~ body_kg)\nsummary(model_without_outliers_by_y)\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7843 -1.4343 -0.1363  1.4296  4.9122 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  3.60560    1.13144   3.187  0.00196 **\nbody_kg      0.01915    0.01610   1.190  0.23716   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.087 on 93 degrees of freedom\nMultiple R-squared:  0.01499,   Adjusted R-squared:  0.004402 \nF-statistic: 1.416 on 1 and 93 DF,  p-value: 0.2372\n\nggplot(data = back, aes(x = body_kg, y = backpack_kg,\n                        shape = body_outlier, colour = backpack_outlier))+\n  geom_point(alpha = 0.3)+\n  geom_abline(intercept = model$coefficients[1], slope = model$coefficients[2])+\n  geom_abline(intercept= model_without_outliers_by_x$coefficients[1], \n              slope = model_without_outliers_by_x$coefficients[2], linetype = \"dashed\")+\n  geom_abline(intercept= model_without_outliers_by_y$coefficients[1], \n              slope = model_without_outliers_by_y$coefficients[2], linetype = \"dotted\")+\n  theme_minimal()\n\n\n\n\nТаким образом, именно экстремальные значения по предиктору, а не по объяснияемой переменной имеют особенно сильное значение на регрессионную модель."
  },
  {
    "objectID": "340-lm.html#sec-lm_mult",
    "href": "340-lm.html#sec-lm_mult",
    "title": "20  Линейная регрессия",
    "section": "20.5 Множественная линейная регрессия",
    "text": "20.5 Множественная линейная регрессия\nВ множественной линейной регрессионной регрессии у нас появляется несколько предикторов. Какая модель лучше: где есть много предикторов или где мало предикторов? С одной стороны, чем больше предикторов, тем лучше: каждый новый предиктор может объяснить чуть больше необъясненной дисперсиии. С другой стороны, если эта прибавка маленькая (а она всегда будет не меньше нуля), то, возможно, новый предиктор просто объясняет “случайный шум”. В действительности, если у нас будет достаточно много предикторов, то мы сможем объяснить любые данные! Парадоксальным образом такая модель будет давать очень хорошие результаты на той выборке, по которой мы считаем коэффициенты, но делать очень плохие предсказания на новой выборке - это то, что в машинном обучении называют переобучением (overfitting). Идеальная модель будет включать минимум предикторов, которые лучше всего объясненяют исследуемую переменную. Это что-то вроде бритвы Оккама в статистике.\nПоэтому часто используются показатели качества модели, которые “наказывают” модель за большое количество предикторов. Например, adjusted R2:\n\\[R_{adj} = 1 - (1 - R^2) \\frac{n -1}{n - p - 1}\\]\nЗдесь n - это количество наблюдений, p - количество параметров.\nИтак, добавим новый предиктор - Units. Это количество кредитов, которые студенты взяли в четверти1. Можно предположить, что чем больше у студента набрано кредитов, тем более тяжелый у нее/него рюкзак. Давайте добавим это как второй предиктор. Для этого нужно просто записать второй предиктор в формуле через плюс.\n\nmodel_mult <- lm(backpack_kg ~ body_kg + Units, data = back)\nsummary(model_mult)\n\n\nCall:\nlm(formula = backpack_kg ~ body_kg + Units, data = back)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6221 -1.8347 -0.5023  1.2519 10.0623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.28481    2.16170   0.132   0.8955  \nbody_kg      0.04391    0.01990   2.207   0.0297 *\nUnits        0.13703    0.09456   1.449   0.1505  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.566 on 97 degrees of freedom\nMultiple R-squared:  0.05628,   Adjusted R-squared:  0.03682 \nF-statistic: 2.892 on 2 and 97 DF,  p-value: 0.06025\n\n\nМножественная линейная регрессия имеет еще одно допущение: отсутствие мультиколлинеарности. Это значит, что предикторы не должны коррелировать друг с другом.\nДля измерения мультколлинеарности существует variance inflation factor (VIF-фактор). Считается он просто: для предиктора \\(i\\) считается линейная регрессия, где все остальные предикторы предсказывают предиктор \\(i\\).\nСам VIF-фактор считается на основе полученного R2 регрессии:\n\\[VIF_i = \\frac{1}{1 - R_i^2}\\]\nЕсли Ri2 большой, то и VIFi выходит большим. Это означает, что предиктор сам по себе хорошо объясняется другими предикторами. Какой VIF считать большим? Здесь нет единого мнения, но если он выше 3 и особенно если он выше 10, то с этим нужно что-то делать.\n\ncar::vif(model_mult)\n\nbody_kg   Units \n1.05858 1.05858 \n\n\nВ нашем случае это не так. Но если бы VIF был большим для какого-либо предиктора, то можно было бы либо попробовать его выкинуть или же использовать анализ главных компонент (см. @ref(pca)), о котором пойдет речь в один из следующих дней."
  },
  {
    "objectID": "350-anova.html#sec-anova_nhst",
    "href": "350-anova.html#sec-anova_nhst",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.1 Тестирование значимости нулевой гипотезы в ANOVA.",
    "text": "21.1 Тестирование значимости нулевой гипотезы в ANOVA.\nКак и в случае с другими статистическими тестами, мы можем выделить 4 этапа в тестировании значимости нулевой гипотезы в ANOVA:\n\nФормулирование нулевой и альтернативной гипотезы. Нулевая гипотеза говорит, что между средними в генеральной совокупности нет различий:\n\n\\[H_0:\\mu_1 = \\mu_2 = ... = \\mu_n\\] Можно было бы предположить, что ненулевая гипотеза звучит как “все средние не равны”, но вообще-то это не так. Альтернативная гипотеза в дисперсионном анализе звучит так:\n\\[H_1: \\text{Не все средние равны}\\]\n\nПодсчет статистики. Как мы уже видели раньше, в дисперсионном анализе используется новая для нас статистика F. Впрочем, мы ее видели, когда смотрели на аутпут функции lm(), когда делали линейную регрессию. Чтобы считать F (если вдруг мы хотим сделать это вручную), нужно построить талбицу ANOVA (ANOVA table).\n\n\n\n\n\n\n\n\n\n\n\nТаблица ANOVA\nСтепени свободы\nСуммы квадратов\nСредние квадраты\nF-статистика\n\n\n\n\nМежгрупповые\n\\(df_{b}\\)\n\\(SS_{b}\\)\n\\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\)\n\\(F=\\frac{MS_{b}}{MS_{w}}\\)\n\n\nВнутригрупповые\n\\(df_{w}\\)\n\\(SS_{w}\\)\n\\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\)\n\n\n\nОбщие\n\\(df_{t}\\)\n\\(SS_{t}= SS_{b} + SS_{w}\\)\n\n\n\n\n\nИменно эту таблицу мы видели, когда использовали функцию aov():\n\nsummary(aov_model)\n\n            Df Sum Sq Mean Sq F value Pr(>F)   \nDietf        2   60.5  30.264   5.383 0.0066 **\nResiduals   73  410.4   5.622                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nВот как это все считается:\n\n\n\n\n\n\n\n\n\n\nТаблица ANOVA\nСтепени свободы\nСуммы квадратов\nСредние квадраты\nF-статистика\n\n\n\n\nМежду\n\\(df_{b}=J-1\\)\n\\(SS_{b}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (\\overline{x_j}-\\overline{x})^2\\)\n\\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\)\n\\(F=\\frac{MS_{b}}{MS_{w}}\\)\n\n\nВнутри\n\\(df_{w}=N-J\\)\n\\(SS_{w}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x_j})^2\\)\n\\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\)\n\n\n\nОбщие\n\\(df_{t}=N-1\\)\n\\(SS_{t}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2\\)\n\n\n\n\n\n\\(J\\) означает количество групп, \\(N\\) - общее количество наблюдений во всех группах, \\(n_j\\) означает количество наблюдений в группе j, а \\(x_{ij}\\) - наблюдение под номером \\(i\\) в группе \\(j\\).\nВариабельность обозначается \\(SS\\) и означает “сумму квадратов” (sum of squares) - это то же, что и дисперсия, только мы не делим вме в конце на количество наблюдений (или количество наблюдений минус один): \\[SS = \\sum\\limits_{i=1}^{n_j} (x_{i}-\\overline{x})^2\\]\nЗдесь много формул, но суть довольно простая: мы разделяем вариабельность зависимой переменной на внутригрупповую и межгрупповую, считаем их соотношение, которое и будет F. В среднем, F будет равен 1 при верности нулевой гипотезы. Это означает, что и межгрупповая вариабельность, и внутригрупповая вариабельность - это просто шум. Но если же межгрупповая вариабельность - это не просто шум, то это соотношение будет сильно больше единицы.\n\nПодсчет p-value. В t-тесте мы смотрели, как статистика распределена при условии верности нулевой гипотезы. То есть что будет, если нулевая гипотеза верна, мы будем повторять эксперимент с точно таким же дизайном (и размером выборок) бесконечное количество раз и считать F.\n\n\nbetweendf <- 2\nwithindf <- 73\nf <- summary(aov_model)[[1]]$F[1]\n\nv <- seq(0.1,10, 0.01)\nfdist <- data.frame(fvalues = v, pdf = df(v, betweendf, withindf))\n\nlibrary(ggplot2)\n\nlabel <- paste0(\"F(\", betweendf, \", \", withindf, \") = \", round(f, 3))\n\nggplot(fdist, aes(x = fvalues, y = pdf))+\n  geom_line()+\n  geom_vline(xintercept = f)+\n  annotate(\"text\", x = f+1, y = 0.2, label = label)+\n  scale_y_continuous(expand=c(0,0)) + \n  theme_minimal()+\ntheme(axis.line.y = element_blank(),\n      axis.ticks.y = element_blank(),\n      axis.text.y = element_blank(),\n      axis.title.y = element_blank())  \n\n\n\n\nF-распределение при верности нулевой гипотезы (см. детали в тексте)\n\n\n\n\nЗаметьте, распределение F несимметричное2. Это значит, что мы всегда считаем считаем площадь от F до плюс бесконечности (без умножения на 2, как мы это делали в t-тесте):\n\n1 - pf(f, betweendf, withindf)\n\n[1] 0.006595853\n\n\nЭто и есть наш p-value!\n\nСравнение p-value с уровнем \\(\\alpha\\). Самый простой этап: если наш p-value меньше, чем \\(\\alpha\\) (который обычно равен 0.05), то мы отвергаем нулевую гипотезу. Если нет - не отвергаем.\n\nВ нашем случае это 0.0065959, что, очевидно, меньше, чем 0.05. Отвергаем нулевую гипотезу (о том, что нет различий), принимаем ненулевую (о том, что различия есть). Все!"
  },
  {
    "objectID": "350-anova.html#sec-anova_posthoc",
    "href": "350-anova.html#sec-anova_posthoc",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.2 Post-hoc тесты",
    "text": "21.2 Post-hoc тесты\nТем не менее, дисперсионного анализа недостаточно, чтобы решить, какие именно группы между собой различаются. Для этого нужно проводить post-hoc тесты (апостериорные тесты).\nPost-hoc переводится с латыни как “после этого”. Post-hoc тесты или просто “пост-хоки” проводятся, если в результате ANOVA была отвергнута нулевая гипотеза. Собственно, пост-хоки никак не связаны с дисперсионным анализом на уровне расчетов - это абсолютно независимые тесты, но исторически так сложилось, что они известны именно как дополнительный этап ANOVA.\nСамый простой вариант пост-хок теста - это попарные т-тесты 3 с поправками на множественные сравнения:\n\npairwise.t.test(diet$weight.loss, diet$Dietf)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  diet$weight.loss and diet$Dietf \n\n  A     B    \nB 0.962 -    \nC 0.017 0.017\n\nP value adjustment method: holm \n\n\nВторой подход связан с использованием специализированных тестов, таких как тест Тьюки (Tukey Honest Significant Differences = Tukey HSD). Для этого в R есть функция TukeyHSD(), которую нужно применять на объект aov:\n\nTukeyHSD(aov_model)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = weight.loss ~ Dietf, data = diet)\n\n$Dietf\n         diff       lwr        upr     p adj\nB-A  0.032000 -1.589085  1.6530850 0.9987711\nC-A -1.848148 -3.439554 -0.2567422 0.0188047\nC-B -1.880148 -3.454614 -0.3056826 0.0152020"
  },
  {
    "objectID": "350-anova.html#sec-aov_as_lm",
    "href": "350-anova.html#sec-aov_as_lm",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.3 ANOVA и т-тест как частные случаи линейной регрессии",
    "text": "21.3 ANOVA и т-тест как частные случаи линейной регрессии\nКак мы уже видели, если применить lm() или aov() на одних и тех же данных с одной и той же формулой, то результат будет очень похожим. Но есть одно но: lm() создает из одного фактора две переменных-предиктора:\n\nsummary(lm(weight.loss ~ Dietf, diet))\n\n\nCall:\nlm(formula = weight.loss ~ Dietf, data = diet)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7000 -1.6519 -0.1759  1.4420  5.3680 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.3000     0.4840  -6.818 2.26e-09 ***\nDietfB        0.0320     0.6776   0.047  0.96246    \nDietfC       -1.8481     0.6652  -2.778  0.00694 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.371 on 73 degrees of freedom\nMultiple R-squared:  0.1285,    Adjusted R-squared:  0.1047 \nF-statistic: 5.383 on 2 and 73 DF,  p-value: 0.006596\n\n\nДело в том, что мы не можем просто так загнать номинативную переменную в качестве предиктора в линейную регрессию. Мы можем это легко сделать, если у нас всего два уровня в номинативном предикторе. Тогда один из уровней можно обозначить за 0, другой - за 1. Такие переменные иногда называются “бинарными”. Тогда это легко использовать в линейной регрессии:\n\nsummary(lm(weight.loss ~ gender, diet))\n\n\nCall:\nlm(formula = weight.loss ~ gender, data = diet)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1848 -1.7264  0.2041  1.6846  5.9930 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.8930     0.3846 -10.123  1.3e-15 ***\ngender       -0.1221     0.5836  -0.209    0.835    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.522 on 74 degrees of freedom\nMultiple R-squared:  0.0005914, Adjusted R-squared:  -0.01291 \nF-statistic: 0.04379 on 1 and 74 DF,  p-value: 0.8348\n\n\nМожно ли так делать? Вполне! Допущения линейной регрессии касаются остатков, а не переменных самих по себе. Разве что это немного избыточно: линейная регрессия с бинарным предиктором - это фактически независимый t-тест:\n\nt.test(weight.loss ~ gender, diet, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  weight.loss by gender\nt = 0.20925, df = 74, p-value = 0.8348\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.040810  1.285067\nsample estimates:\nmean in group 0 mean in group 1 \n      -3.893023       -4.015152 \n\n\nКак видите, p-value совпадают! А t статистика в квадрате - это F (при двух группах):\n\nt.test(weight.loss ~ gender, diet, var.equal = TRUE)$statistic^2\n\n         t \n0.04378592 \n\n\nБолее того, те же самые результаты можно получить и с помощью коэффициента корреляции Пирсона:\n\ncor.test(diet$gender, diet$weight.loss)\n\n\n    Pearson's product-moment correlation\n\ndata:  diet$gender and diet$weight.loss\nt = -0.20925, df = 74, p-value = 0.8348\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2484113  0.2022466\nsample estimates:\n        cor \n-0.02431772 \n\n\nТеперь должно быть понятно, почему все эти функции делают вроде бы разные статистические тесты, но выдают такой похожий результат - это фактически один и тот же метод! Все эти методы (и некоторые из тех, что будем рассматривать далее) можно рассматривать как разновидности множественной линейной регрессии. 4"
  },
  {
    "objectID": "350-anova.html#sec-dummy",
    "href": "350-anova.html#sec-dummy",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.4 Dummy coding",
    "text": "21.4 Dummy coding\nТем не менее, вопрос остается открытым: как превратить номинативную переменную в количественную и загнать ее в регрессию? Для этого можно использовать “фиктивное кодирование” (dummy coding):\n\ndiet <- diet %>%\n  mutate(isA = as.numeric(Dietf == \"A\"),\n         isB = as.numeric(Dietf == \"B\"),\n         isC = as.numeric(Dietf == \"C\"))\n\ndiet %>%\n  group_by(Dietf) %>%\n  slice(1:2) %>%\n  select(Dietf, isA:isC)\n\n# A tibble: 6 × 4\n# Groups:   Dietf [3]\n  Dietf   isA   isB   isC\n  <fct> <dbl> <dbl> <dbl>\n1 A         1     0     0\n2 A         1     0     0\n3 B         0     1     0\n4 B         0     1     0\n5 C         0     0     1\n6 C         0     0     1\n\n\nЗаметьте, что такое кодирование избыточно. Если мы знаем, что диет 3, а данная диета - это не диета В и не диета С, то это диета А. Значит, одна из созданных нами колонок - “лишняя”:\n\ndiet$isA <- NULL\n\nИспользуем новую колонки для линейной регрессии и сравним результаты:\n\nsummary(lm(weight.loss ~ isB + isC, diet))\n\n\nCall:\nlm(formula = weight.loss ~ isB + isC, data = diet)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7000 -1.6519 -0.1759  1.4420  5.3680 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.3000     0.4840  -6.818 2.26e-09 ***\nisB           0.0320     0.6776   0.047  0.96246    \nisC          -1.8481     0.6652  -2.778  0.00694 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.371 on 73 degrees of freedom\nMultiple R-squared:  0.1285,    Adjusted R-squared:  0.1047 \nF-statistic: 5.383 on 2 and 73 DF,  p-value: 0.006596\n\nsummary(lm(weight.loss ~ Dietf, diet))\n\n\nCall:\nlm(formula = weight.loss ~ Dietf, data = diet)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7000 -1.6519 -0.1759  1.4420  5.3680 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.3000     0.4840  -6.818 2.26e-09 ***\nDietfB        0.0320     0.6776   0.047  0.96246    \nDietfC       -1.8481     0.6652  -2.778  0.00694 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.371 on 73 degrees of freedom\nMultiple R-squared:  0.1285,    Adjusted R-squared:  0.1047 \nF-statistic: 5.383 on 2 and 73 DF,  p-value: 0.006596\n\n\nТо же самое!"
  },
  {
    "objectID": "350-anova.html#sec-aova",
    "href": "350-anova.html#sec-aova",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.5 Допущения ANOVA",
    "text": "21.5 Допущения ANOVA\n\nНормальность распределения ошибок:\n\n\nhist(residuals(aov_model))\n\n\n\n\nКак мы видим, распределение не сильно далеко от нормального - этого вполне достаточно. ANOVA - это метод достаточно устойчивый к отклонениям от нормальности.\n\nГомогенность дисперсий.\n\nТо есть их равенство. Можно посмотреть на распределение остатков:\n\ndiet$residuals <- residuals(aov_model)\nggplot(diet, aes(x = Dietf, y = residuals))+ geom_jitter(width = 0.1, alpha = 0.5)\n\n\n\n\nВсе выглядит неплохо: нет какой-то одной группы, у которой разброс сильно больше или меньше. Есть и более формальные способы проверить равенство дисперсий. Например, с помощью теста Ливиня (Levene’s test). Для того, чтобы его провести, мы воспользуемся новым пакетом ez (читать как “easy”). Этот пакет сильно упрощает проведение дисперсионного анализа, особенно для более сложных дизайнов.\n\ninstall.packages(\"ez\")\n\nСинтаксис довольно простой: нужно указать, данные, зависимую переменную, переменную с ID, факторы. Необходимо прописать фактор в between = или within =. В данном случае - в between =.\n\nlibrary(ez)\nez_model <- ezANOVA(data = diet,\n        dv= weight.loss,\n        wid = Person, \n        between = Dietf,\n        detailed = T, \n        return_aov = T)\n\nWarning: You have removed one or more Ss from the analysis. Refactoring\n\"Person\" for ANOVA.\n\n\nWarning: Data is unbalanced (unequal N per group). Make sure you specified a\nwell-considered value for the type argument to ezANOVA().\n\n\nCoefficient covariances computed by hccm()\n\nez_model\n\n$ANOVA\n  Effect DFn DFd      SSn      SSd        F           p p<.05       ges\n1  Dietf   2  73 60.52701 410.4018 5.383104 0.006595853     * 0.1285269\n\n$`Levene's Test for Homogeneity of Variance`\n  DFn DFd      SSn      SSd         F         p p<.05\n1   2  73 2.040419 160.8859 0.4629076 0.6312856      \n\n$aov\nCall:\n   aov(formula = formula(aov_formula), data = data)\n\nTerms:\n                   Dietf Residuals\nSum of Squares   60.5270  410.4018\nDeg. of Freedom        2        73\n\nResidual standard error: 2.371064\nEstimated effects may be unbalanced\n\n\nЕсли при проведении теста Ливиня мы получаем p < .05, то мы отбрасываем нулевую гипотезу о равенстве дисперсий. В данном случае мы не можем ее отбросить и поэтому принимаем 5\nПолученный объект (если поставить return_aov = T) содержит еще и объект aov() - на случай, если у Вас есть функции, которые работают с этим классом:\n\nTukeyHSD(ez_model$aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = formula(aov_formula), data = data)\n\n$Dietf\n         diff       lwr        upr     p adj\nB-A  0.032000 -1.589085  1.6530850 0.9987711\nC-A -1.848148 -3.439554 -0.2567422 0.0188047\nC-B -1.880148 -3.454614 -0.3056826 0.0152020\n\n\n\nПримерно одинаковое количество испытуемых в разных группах. Здесь у нас все в порядке:\n\n\ndiet %>%\n  count(Dietf)\n\n# A tibble: 3 × 2\n  Dietf     n\n  <fct> <int>\n1 A        24\n2 B        25\n3 C        27\n\n\nНебольшие различия в размерах групп - это ОК, тем более, что на практике такое очень часто случается: кого-то пришлось выкинуть из анализа, для какой-то строчки были потеряны данные и т.д. Однако больших различий в размерах групп стоит избегать. Самое плохое, когда группы различаются значительно по размеру (более чем в 2 раза) и вариабельность внутри групп отличается значительно (более чем в 2 раза)."
  },
  {
    "objectID": "350-anova.html#sec-fact_aov",
    "href": "350-anova.html#sec-fact_aov",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.6 Многофакторный дисперсионный анализ (Factorial ANOVA)",
    "text": "21.6 Многофакторный дисперсионный анализ (Factorial ANOVA)\nНа практике можно встретить One-Way ANOVA (однофакторную ANOVA) довольно редко. Обычно в исследованиях встречается многофакторный дисперсионный анализ, в котором проверяется влияние сразу нескольких факторов. В научных статьях это обозначается примерно так: “3х2 ANOVA”. Это означает, что был проведен двухфакторный дисперсионный анализ, причем в одном факторе было три уровня, во втором - два. В нашем случае это будут факторы “Диета” и “Пол”. Это означает, что у нас две гипотезы: о влиянии диеты на потерю веса и о влиянии пола на потерю веса. Кроме того, появляется гипотеза о взаимодействии факторов - то есть о том, что разные диеты по разному влияют на потерю веса для разных полов.\nВзаимодействие двух факторов хорошо видно на графике с линиями: если две линии параллельны, то взаимодействия нет. Если они не параллельны (пересекаются, сходятся, расходятся), то взаимодействие есть.\n\ndiet <- diet %>%\n  mutate(genderf = factor(gender, labels = c(\"ж\", \"м\"))) #превращаем в бинарную переменную в фактор\n\nsem <- function(x) sd(x)/sqrt(length(x)) #пишем функцию для стандартной ошибки\npd = position_dodge(0.05) #немного раздвигаем положение точек на будущем графике\n\ndiet %>%\n  group_by(Dietf, genderf) %>%\n  summarise(meanloss = mean(weight.loss),\n            se = sem(weight.loss)) %>%\n  ggplot(aes(x = Dietf, \n             y = meanloss, \n             colour = genderf)) +\n  geom_line(aes(group = genderf), position = pd) +\n  geom_pointrange(aes(ymin = meanloss - se, \n                      ymax = meanloss + se), position = pd) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'Dietf'. You can override using the\n`.groups` argument.\n\n\n\n\n\nКак видно по картинке, разница в эффективности диеты С по сравнению с другими видна только для женщин.\n\nezANOVA(data = diet,\n        dv= weight.loss,\n        wid = Person, \n        between = .(Dietf, gender),\n        detailed = T, \n        return_aov = T)\n\nWarning: You have removed one or more Ss from the analysis. Refactoring\n\"Person\" for ANOVA.\n\n\nWarning: \"gender\" will be treated as numeric.\n\n\nWarning: Data is unbalanced (unequal N per group). Make sure you specified a\nwell-considered value for the type argument to ezANOVA().\n\n\nCoefficient covariances computed by hccm()\n\n\nWarning: At least one numeric between-Ss variable detected, therefore no\nassumption test will be returned.\n\n\n$ANOVA\n        Effect DFn DFd        SSn     SSd          F          p p<.05\n1        Dietf   2  70 60.4172197 376.329 5.61902602 0.00545568     *\n2       gender   1  70  0.1686958 376.329 0.03137868 0.85990976      \n3 Dietf:gender   2  70 33.9040683 376.329 3.15320438 0.04884228     *\n          ges\n1 0.138334829\n2 0.000448066\n3 0.082645860\n\n$aov\nCall:\n   aov(formula = formula(aov_formula), data = data)\n\nTerms:\n                   Dietf   gender Dietf:gender Residuals\nSum of Squares   60.5270   0.1687      33.9041  376.3290\nDeg. of Freedom        2        1            2        70\n\nResidual standard error: 2.318648\nEstimated effects may be unbalanced\n\n\nИтак, теперь мы проверяем три гипотезы вместо одной. Действительно, взаимодействие диеты и пола оказалось значимым, как и ожидалось."
  },
  {
    "objectID": "350-anova.html#sec-rm_aov",
    "href": "350-anova.html#sec-rm_aov",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.7 Дисперсионный анализ с повторными измерениями (Repeated-measures ANOVA)",
    "text": "21.7 Дисперсионный анализ с повторными измерениями (Repeated-measures ANOVA)\nЕсли обычный дисперсионный анализ - это аналог независимого т-теста для нескольких групп, то дисперсионный анализ с повторными измерениями - это аналог зависимого т-теста. В функции ezANOVA() для проведения дисперсионного анализа с повторными измерениями нужно просто поставить нужным параметром внутригрупповую переменную. Это означает, что в данном случае мы должны иметь данные в длинном формате, для чего мы воспользуемся функцией pivot_longer():\n\ndietlong <- diet %>%\n  pivot_longer(cols = c(pre.weight, weight6weeks),\n               names_to = \"time\",\n               values_to = \"weight\")\ndietlongC <- dietlong %>%\n          filter(Dietf == \"C\") %>%\n          droplevels()\n\n\nezANOVA(dietlongC,\n        dv = weight, \n        wid = Person,\n        within = time)\n\nWarning: Converting \"time\" to factor for ANOVA.\n\n\n$ANOVA\n  Effect DFn DFd        F            p p<.05       ges\n2   time   1  26 124.6949 2.030459e-11     * 0.0986036"
  },
  {
    "objectID": "350-anova.html#sec-mixed_aov",
    "href": "350-anova.html#sec-mixed_aov",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.8 Смешанный дисперсионный анализ (Mixed between-within subjects ANOVA)",
    "text": "21.8 Смешанный дисперсионный анализ (Mixed between-within subjects ANOVA)\nНам никто не мешает совмещать и внутригруппоdые, и межгрупповые факторы вместе. В ezANOVA() это делается просто с помощью прописывания разных факторов в нужных переменных: between = и within =.\n\nezANOVA(dietlong,\n        dv = weight, \n        wid = Person,\n        within = time,\n        between = Dietf)\n\nWarning: You have removed one or more Ss from the analysis. Refactoring\n\"Person\" for ANOVA.\n\n\nWarning: Converting \"time\" to factor for ANOVA.\n\n\nWarning: Data is unbalanced (unequal N per group). Make sure you specified a\nwell-considered value for the type argument to ezANOVA().\n\n\n$ANOVA\n      Effect DFn DFd           F            p p<.05         ges\n2      Dietf   2  73   0.8280758 4.409507e-01       0.021710057\n3       time   1  73 210.5004045 3.346036e-23     * 0.059209996\n4 Dietf:time   2  73   5.3831045 6.595853e-03     * 0.003208607\n\n\nЗдесь нас интересует взаимодействие между факторами. Результаты, полученные для этой гипотезы, идентичны результатам по обычному дисперсионному анализу на разницу до и после - по сути это одно и то же."
  },
  {
    "objectID": "350-anova.html#sec-nonparam_aov",
    "href": "350-anova.html#sec-nonparam_aov",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.9 Непараметрические аналоги ANOVA",
    "text": "21.9 Непараметрические аналоги ANOVA\nКак было описано выше, ANOVA довольно устойчив к разным отклонениям от нормальности и некоторой гетероскедастичности (разным дисперсиям в выборках). Но если уж у Вас данные ну совсем-совсем ненормальные, несимметричные, а от преобразований шкалы Вы по каким-то причинам отказались, то стоит упомянуть о непараметрических аналогах ANOVA.\n\n21.9.1 Тест Краскела-Уоллеса\nЭто тест Краскела-Уоллеса - обобщение теста Манна-Уитни на несколько выборок (т.е. аналог межгруппового ANOVA):\n\nkruskal.test(weight.loss ~ Dietf, diet)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  weight.loss by Dietf\nKruskal-Wallis chi-squared = 9.4159, df = 2, p-value = 0.009023\n\n\n\n\n21.9.2 Тест Фридмана\nДля зависимых выборок есть тест Фридмана - непараметрический аналог дисперсионного анализа с повторными измерениями:\n\nfriedman.test(weight ~ time | Person, dietlongC)\n\n\n    Friedman rank sum test\n\ndata:  weight and time and Person\nFriedman chi-squared = 27, df = 1, p-value = 2.035e-07"
  },
  {
    "objectID": "350-anova.html#sec-aov_final",
    "href": "350-anova.html#sec-aov_final",
    "title": "21  Дисперсионный анализ (ANOVA)",
    "section": "21.10 Заключение",
    "text": "21.10 Заключение\nМы разобрали много разных вариантов дисперсионного анализа. Зачем так много? ANOVA - один из самых распространенных методов как в психологии, так и во многих других областях. Естественно, это отнюдь не все методы, используемые в той же психологии. Более того, некоторые вопросы остались за бортом. Постараюсь коротко их перечислить:\n\nмногомерный ANOVA (Multivariate ANalysis Of Variance; MANOVA) - расширение ANOVA для ситуации нескольких зависимых переменных. Это довольно редкая разновидность ANOVA, который берет во внимание ковариации между зависимыми переменными.\nтестирование сферичности для дисперсионного анализа с повторноми измерениями с помощью теста сферичности Моучли (Mauchly’s sphericity test). Этот тест проверяет использует матрицу ковариаций разниц каждого условия с каждым: дисперсии разниц между условиями должны быть примерно одинаковыми. Если нулевая гипотеза о сферичности может быть отброшена (p-value < \\(\\alpha\\)), то нужно проводить специальные поправки, обычно это поправки Гринхауса-Гейсера (Greenhouse-Geisser corrections). Мы этого не делали, потому что в ситуации RM-ANOVA с всего двумя условиями эта сферичность никогда не нарушается: у нас всего одна дисперсия разниц между условиями, которую просто-напросто не с чем сравнивать. Тест сферичности Моучли вместе с поправками Гринхауса-Гейсера проводятся автоматически для RM-ANOVA с тремя или более группами при использовании функции ezANOVA(), так что особо париться над этим не стоит. Правда, нужно помнить, что как и все подобные статистические тесты допущений, они обладают проблемами, связанными с тем, что это статистические тесты: на маленьких выборках они не заметят даже серьезных отклонений от сферичности, на больших - даже маленькие отклонения, а \\(p-value < 0.05\\), по сути, не может интерпретироваться как верность нулевой гипотезы. Тем не менее, это довольно стандартная процедура.\nКак правильно репортить результаты дисперсионного анализа. Здесь все, конечно, зависит от стиля, используемого конкретным журналом. В психологии и близких к ней дисциплинам фактическим lingua franca является стиль Американской Психологической Ассоциации (APA). И тут у меня есть для Вас хорошие новости: есть куча пакетов в R, которые позволяют репортить результаты статистических тестов в APA-стиле! Спасибо дотошным авторам руководства APA по офромлению статей, что этот стиль настолько точно прописывает, как нужно описывать результаты исследований, что это можно запрограммировать. Я лично пользуюсь пакетом apa, он весьма удобен:\n\n\ninstall.packages(\"apa\")\n\n\nlibrary(apa)\nanova_apa(ez_model)\n\n  Effect                                            \n1  Dietf F(2, 73) = 5.38, p = .007, petasq = .13 ** \n\n\nВ тексте это будет выглядеть это будет вот так:\nDietf: F(2, 73) = 5.38, p = .007, \\(\\eta^2_p\\) = .13\nЕще есть пакеты apaStyle и papaja, которые могут даже сразу делать весь документ в APA-формате! Если же Вы описываете результаты самостоятельно вручную, то нужно помнить: ни в коем случае не описывайте только p-value. Обязательно прописывайте значение \\(F\\) и степени свободы, желательно с размером эффекта. Для post-hoc теста часто репортятся только p-value (зачастую только для статистически значимых сравнений), но обязательно нужно прописывать какие именно post-hoc тесты проводились, какой показатель размера эффекта использовался (если использовался), применялись ли тест сферичности Моучли вместе с поправками Гринхауса-Гейсера для дисперсионного анализа с повторными измерениями.\n\nМодели со смешанными эффектами (mixed-effects models) / иерархическая регрессия (hierarchical regression) / многоуровневое моделирование (multilevel modelling). очень популярный нынче метод, которому повезло иметь много названий - в зависимости от области, в которой он используется. В экспериментальной психологии обычно он называется “модели со смешанными эффектами” и позволяет включать в линейную регрессию не только фиксированные эффекты (fixed effects), но и случайные эффекты (random effects). Для экспериментальной психологии это интересно тем, что в таких моделях можно не усреднять показатели по испытуемым, а учитывать влияние группирующей переменной “испытуемый” как случайный эффект. Подобные модели используются в самых разных областях. Для их использования в R есть два известных пакета: nlme и lme4."
  },
  {
    "objectID": "360-glm.html#sec-general_linear_model",
    "href": "360-glm.html#sec-general_linear_model",
    "title": "22  Общая линейная модель и ее расширения",
    "section": "22.1 Общая линейная модель",
    "text": "22.1 Общая линейная модель\nОбобщением множественной линейной регрессии можно считать общую линейную модель (general linear model). Общая линейная модель может предсказывать не одну, а сразу несколько объясняемых переменных в отличие от множественной линейной регрессии.\n\\[Y = XB\\] где \\(Y\\) — матрица объясняемых переменных, \\(X\\) — матрица предикторов, \\(B\\) — матрица параметров.\nПочти все пройденные нами методы можно рассматривать как частный случай общей линейной модели: t-тесты, коэффициент корреляции Пирсона, линейная регрессия, ANOVA."
  },
  {
    "objectID": "360-glm.html#sec-glm_model",
    "href": "360-glm.html#sec-glm_model",
    "title": "22  Общая линейная модель и ее расширения",
    "section": "22.2 Обобщенная линейная модель",
    "text": "22.2 Обобщенная линейная модель\nОбобщенная линейная модель (generalized linear model) была придумана как обобщение линейной регрессии и ее сородичей: логистической регрессии и пуассоновской регрессии.\nОбщая линейная модель задается формулой \\[Y = XB\\]\nОбобщенная оборачивает предиктор \\(XB\\) связывающей функцией (link function), которая различается для разных типов регрессионных моделей.\nДавайте попробуем построить модель, в которой объясняемой переменной будет то, является ли супергерой хорошим или плохим.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\n\nNew names:\n• `` -> `...1`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 734 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): name, Gender, Eye color, Race, Hair color, Publisher, Skin color, A...\ndbl (3): ...1, Height, Weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nheroes$good <- heroes$Alignment == \"good\"\n\nОбычная линейная модель нам не подходит, если распределение наших ошибок далеко от нормального. А это значит, что мы не можем использовать общую линейную модель с бинарной объясняемой переменной. Эту проблему решает логистическая регрессия, которая является частным случаем обобщенной линейной модели.\nДля этого нам понадобится функция glm(), а не lm() как раньше. Ее синтаксис очень похож, но нам теперь нужно задать еще один важный параметр family = для выбора связывающей функции (в данном случае это логит-функция, которая является связующей функцией по умолчанию для биномиального семейства функций в glm()).\n\nheroes_good_glm <- glm(good ~ Weight + Gender, heroes, family = binomial()) \nsummary(heroes_good_glm)\n\n\nCall:\nglm(formula = good ~ Weight + Gender, family = binomial(), data = heroes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8674  -1.3103   0.6334   0.9155   2.4007  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.763917   0.235410   7.493 6.73e-14 ***\nWeight      -0.004253   0.001124  -3.783 0.000155 ***\nGenderMale  -0.760310   0.245851  -3.093 0.001984 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 605.22  on 477  degrees of freedom\nResidual deviance: 570.88  on 475  degrees of freedom\n  (256 observations deleted due to missingness)\nAIC: 576.88\n\nNumber of Fisher Scoring iterations: 4\n\n\nРезультат очень похож по своей структуре на glm(), однако вместо \\(R^2\\) перед нами AIC. AIC расшифровывается как информационный критерий Акаике (Akaike information criterion) — это критерий использующийся для выбора из нескольких моделей. Чем он меньше, тем лучше модель. Как и Adjusted R2, AIC “наказывает” за большое количество параметров в модели.\nПоскольку AIC — это относительный показатель качества модели, нам нужно сравнить его с AIC другой, более общей модели. Можно сравнить с моделью без веса супергероев.\n\nheroes_good_glm_noweight <- glm(good ~ Gender, heroes, family = binomial()) \nsummary(heroes_good_glm_noweight)\n\n\nCall:\nglm(formula = good ~ Gender, family = binomial(), data = heroes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8082  -1.4164   0.6586   0.9559   0.9559  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.4178     0.1785   7.944 1.95e-15 ***\nGenderMale   -0.8716     0.2012  -4.332 1.48e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 873.81  on 698  degrees of freedom\nResidual deviance: 853.24  on 697  degrees of freedom\n  (35 observations deleted due to missingness)\nAIC: 857.24\n\nNumber of Fisher Scoring iterations: 4\n\n\nAIC стал больше, следовательно, мы выберем модель с весом супергероев."
  },
  {
    "objectID": "360-glm.html#sec-lme_model",
    "href": "360-glm.html#sec-lme_model",
    "title": "22  Общая линейная модель и ее расширения",
    "section": "22.3 Модель со смешанными эффектами",
    "text": "22.3 Модель со смешанными эффектами\nМодели со смешанными эффектами (mixed-effects models) — это то же самое, что и иерархическая регрессия (hierarchical regression) или многоуровневое моделирование (multilevel modelling). Этому методу повезло иметь много названий - в зависимости от области, в которой он используется. Модели со смешанными эффектами позволяет включать в линейную регрессию не только фиксированные эффекты (fixed effects), но и случайные эффекты (random effects).\nДля экспериментальных дисциплин это интересно тем, что в таких моделях можно не усреднять показатели по испытуемым или образцам, а учитывать влияние соотвествующей группирующей переменной как случайный эффект. В отличие от обычного фактора как в линейной регрессии или дисперсионном анализе (здесь он называется фиксированным), случайный эффект не интересует нас сам по себе, а его значения считаются случайной переменной.\nСмешанные модели используются в самых разных областях. Они позволяют решить проблему зависимости наблюдений без усреднения значений по испытуемым или группам, что повышает статистическую мощность.\nДля работы со смешанными моделями в R есть два известных пакета: nlme и более современный lme4.\n\ninstall.packages(\"lme4\")\n\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nДля примера возьмем данные исследования влияния депривации сна на время реакции.\n\ndata(\"sleepstudy\")\n\nДанные представлены в длинном формате: каждая строчка — это усредненное время реакции для одного испытуемого в соответствующий день эксперимента.\n\nsleepstudy %>%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 0:9) +\n  facet_wrap(~Subject) +\n  theme_minimal()\n\n\n\n\nМожно заметить, что, в среднем, время реакции у испытуемых повышается от первого к последнему дню. С помощью смешанных моделей мы можем проверить, различается ли скорость возрастания времени реакции от дня к дню у разных испытуемых.\nДля этого мы сравниваем две модели, одна из которых является “вложенной” в другую, то есть усложненной версией более общей модели. В данном случае, более общая модель предполагает, что время реакции увеличивается у всех испытуемых одинаково, а испытуемые различаются только средним временем реакции.\n\nsleep_lme0 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy)\nsleep_lme1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\n\nВизуализируем предсказания двух моделей:\n\nsleepstudy$predicted_by_sleep_lme0 <- predict(sleep_lme0)\nsleepstudy$predicted_by_sleep_lme1 <- predict(sleep_lme1)\n\n\nsleepstudy %>%\n  rename(observed_reaction_time = Reaction) %>%\n  pivot_longer(cols = c(observed_reaction_time, predicted_by_sleep_lme0, predicted_by_sleep_lme1), names_to = \"model\", values_to = \"Reaction\") %>%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_line(aes(colour = model)) +\n  #geom_line(aes(y = predicted_by_M1), colour = \"orange\") + \n  #geom_line(aes(y = predicted_by_M2), colour = \"purple\") +   \n  geom_point(data = sleepstudy, alpha = 0.4) +\n  scale_x_continuous(breaks = 0:9) +\n  facet_wrap(~Subject) +\n  theme_minimal()\n\n\n\n\nЗеленая линия (нулевая модель) имеет везде один и тот же наклон, а синяя (альтернативная модель) имеет разный наклон у всех испытуемых.\nЕсть несколько способов сравнивать модели, например, уже знакомый нам AIC. Кроме того, можно сравнить две модели с помощью теста хи-квадрат, восполльзовавшись функцией anova().\n\nanova(sleep_lme0, sleep_lme1)\n\nrefitting model(s) with ML (instead of REML)\n\n\nData: sleepstudy\nModels:\nsleep_lme0: Reaction ~ Days + (1 | Subject)\nsleep_lme1: Reaction ~ Days + (Days | Subject)\n           npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nsleep_lme0    4 1802.1 1814.8 -897.04   1794.1                         \nsleep_lme1    6 1763.9 1783.1 -875.97   1751.9 42.139  2  7.072e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nМодель со случайным наклоном прямой оказалась лучше, о чем нам говорят как более низкие AIC и BIC, так и тестирование с помощью хи-квадрат."
  },
  {
    "objectID": "370-multivariate.html#анализ-главных-компонент",
    "href": "370-multivariate.html#анализ-главных-компонент",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.1 Анализ главных компонент",
    "text": "23.1 Анализ главных компонент"
  },
  {
    "objectID": "370-multivariate.html#pca",
    "href": "370-multivariate.html#pca",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.2 Анализ главных компонент (Principal component analysis)",
    "text": "23.2 Анализ главных компонент (Principal component analysis)\nАнализ главных компонент (АГК) известен как метод “уменьшения размерности”. Представьте многомерное пространство, где каждая колонка — это отдельная ось, а каждая строка задает координаты одной точки в этом пространстве. Мы получим многомерную диаграмму рассеяния.\nМногомерную диаграмму рассеяния, к сожалению, нельзя нарисовать, поэтому нарисуем несколько двухмерных диаграмм рассеяния для отображения сочетания всех колонок набора данных iris со всеми.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nplot(iris %>% select(!Species), col=iris$Species)\n\n\n\n\nСуть АГК в том, чтобы повернуть оси этого пространства таким образом, чтобы первые оси объясняли как можно больший разброс данных, а последние - как можно меньший. Тогда мы могли бы отбросить последние оси и не очень-то многое потерять в данных.\nДля двух осей это выглядит вот так:\n\n\n\nПервая ось должна минимизировать красные расстояния. Вторая ось будет просто перпендикулярна первой оси.\n\nМатематически, АГК - это нахождение собственных векторов и собственных значений матрицы корреляций или ковариаций. Собственные вектора - это такие особенные вектора матрицы, умножив которые на данную матрицу, можно получить тот же самый вектор (т.е. того же направления), но другой длины. А вот коэффициент множителя длины нового вектора - это собственное значение. В контексте АГК, собственные вектора - это новые оси (т.е. те самые новые компоненты), а собственные значения - это размер объясняемой дисперсии с помощью новых осей. Собственные вектора, ранжированные по их собственным значениям от большего к меньшему, — это и есть главные компоненты в искомом порядке.\n\nИтак, для начала нам нужно центрировать и нормировать данные - вычесть среднее и поделить на стандартное отклонение, т.е. посчитать z-оценки (@ref(z_scores)). Это нужно для того, чтобы сделать все шкалы равноценными. Это особенно важно делать когда разные шкалы используют несопоставимые единицы измерения. Скажем, одна колонка - это масса человека в килограммах, а другая - рост в метрах. Если применять АГК на этих данных, то ничего хорошего не выйдет: вклад роста будет слишком маленьким. А вот если мы сделаем z-преобразование, то приведем и вес, и рост к “общему знаменателю”.\nВ базовом R уже есть инструменты для АГК princomp() и prcomp(), считают они немного по-разному. Возьмем более рекомендуемый вариант, prcomp(). Эта функция умеет самостоятельно поводить z-преобразования, для чего нужно поставить center = TRUE и scale. = TRUE.\n\niris_pr <- iris %>%\n  select(!Species) %>%\n  prcomp(center = TRUE, scale. = TRUE)\n\nУже много раз встречавшаяся нам функция summary(), примененная на результат проведения АГК, выдаст информацию о полученных компонентах. Наибольший интерес представляют строчки “Proportion of Variance” и “Cumulative Proportion”, которые показывают долю дисперсию, объясненную компонентной, и кумулятивную долю объясненной дисперсии.\n\nsummary(iris_pr)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4\nStandard deviation     1.7084 0.9560 0.38309 0.14393\nProportion of Variance 0.7296 0.2285 0.03669 0.00518\nCumulative Proportion  0.7296 0.9581 0.99482 1.00000\n\n\nФункция plot() повзоляет визуализировать соотношение разных компонент.\n\nplot(iris_pr)\n\n\n\n\nКак мы видим, первый компонент объясняет большую часть дисперсии, второй компонент заметно меньше, остальные два практически не имеют влияния, то есть, скорее всего, они репрезентируют некоторый шум в данных.\nТеперь мы можем визуализировать первые два компонента. Это можно сделать с помощью базовых инструментов R.\n\nplot(iris_pr$x[,1:2], col=iris$Species)\n\n\n\n\nОднако пакет {factoextra} представляет гораздо более широкие возможности для визуализации.\n\ninstall.packages(\"factoextra\")\n\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_pca_ind(iris_pr,\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\n\n\n\n\n\nfviz_pca_var(iris_pr,\n             col.var = \"contrib\", # Color by contributions to the PC\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\n\n\n\n\n\nfviz_pca_biplot(iris_pr, repel = TRUE,\n                col.var = \"#2E9FDF\", # Variables color\n                col.ind = \"#696969\"  # Individuals color\n                )\n\n\n\n\n\nlibrary(ggfortify)\nautoplot(iris_pr, data = iris, colour = \"Species\", loadings = TRUE, loadings.label = TRUE) +\n  theme_bw()"
  },
  {
    "objectID": "370-multivariate.html#tsne",
    "href": "370-multivariate.html#tsne",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.3 tSNE",
    "text": "23.3 tSNE"
  },
  {
    "objectID": "370-multivariate.html#эксплораторный-факторный-анализ",
    "href": "370-multivariate.html#эксплораторный-факторный-анализ",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.4 Эксплораторный факторный анализ",
    "text": "23.4 Эксплораторный факторный анализ"
  },
  {
    "objectID": "370-multivariate.html#конфирматорный-факторный-анализ",
    "href": "370-multivariate.html#конфирматорный-факторный-анализ",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.5 Конфирматорный факторный анализ",
    "text": "23.5 Конфирматорный факторный анализ"
  },
  {
    "objectID": "370-multivariate.html#кластерный-анализ",
    "href": "370-multivariate.html#кластерный-анализ",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.6 Кластерный анализ",
    "text": "23.6 Кластерный анализ\n\niris_3means <- kmeans(iris %>% select(!Species), centers = 3)\ntable(iris$Species, iris_3means$cluster)\n\n            \n              1  2  3\n  setosa      0 50  0\n  versicolor  2  0 48\n  virginica  36  0 14\n\nplot(iris %>% select(!Species), col = iris$Species, pch = iris_3means$cluster)"
  },
  {
    "objectID": "370-multivariate.html#многомерное-шкалирование",
    "href": "370-multivariate.html#многомерное-шкалирование",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.7 Многомерное шкалирование",
    "text": "23.7 Многомерное шкалирование"
  },
  {
    "objectID": "370-multivariate.html#сетевой-анализ",
    "href": "370-multivariate.html#сетевой-анализ",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.8 Сетевой анализ",
    "text": "23.8 Сетевой анализ"
  },
  {
    "objectID": "370-multivariate.html#другие-методы-многомерного-анализа-данных",
    "href": "370-multivariate.html#другие-методы-многомерного-анализа-данных",
    "title": "23  Многомерные методы анализа данных",
    "section": "23.9 Другие методы многомерного анализа данных",
    "text": "23.9 Другие методы многомерного анализа данных"
  },
  {
    "objectID": "410-planning.html#sec-quest_practices",
    "href": "410-planning.html#sec-quest_practices",
    "title": "24  Планирования научного исследования",
    "section": "24.1 Спорные исследовательские практики",
    "text": "24.1 Спорные исследовательские практики\nЕсли Вы откроете какой-нибудь более-менее классический учебник по психологии, то увидите там много результатов исследований, которые в дальнейшем не удалось воспроизвести. Эта проблема накрыла академическое психологическое сообщество относительно недавно и стала, пожалуй, самой обсуждаемой темой среди ученых-психологов. Действительно, о чем еще говорить, если половина фактов твоей науки попросту неверна? Об историческом смысле методологического кризиса, конечно же. Получается, у теорий нет никакого подтверждения, а в плане знаний о психологических фактах мы находимся примерно там же, где и психологи, которые закупали метрономы и тахистоскопы почти полтора века назад.\nОказалось, что то, как устроена академическая наука, способствует публикации ложноположительных результатов. Если теоретическая гипотеза подтверждается, то это дает ученому больше плюшек, чем если гипотеза не подтверждается. Да и сами ученые как-то неосознанно хотят оказаться правыми. Ну а перепроверка предыдущих достижений в психологии оказалась не в почете: всем хочется быть первопроходцами и открывать новые неожиданные феномены, а не скрупулезно перепроверять чужие открытия. Все это привело психологию к тому, что в ней (да и не только в ней) закрепилось какое-то количество спорных исследовательских практик (questionable research practices). Спорные практики на то и спорные, что не все они такие уж плохие, многие ученые даже считают, что в них нет ничего плохого. В отличие, например, от фальсификации данных - это, очевидно, совсем плохо.\nВот некоторые распространенные спорные исследовательские практики:\n\nВыбор зависимых переменных пост-фактум. По своей сути, это проблема скрытых множественных сравнений: если у нас много зависимых переменных, то можно сделать вид, что измерялось только то, на чем нашли эффект. Поэтому стоит задуматься, если возникает идея измерять все подряд на всякий случай - что конкретно предполагается обнаружить? Если конкретной гипотезы нет, то нужно так и написать, делая соответствующие поправки при анализе.\nОбсуждение неожиданных результатов как ожидаемых. Возможно, Вам это покажется смешным, но очень часто результаты оказываются статистически значимыми, но направлены в другую сторону, чем предполагалось в гипотезе. И в таких случаях исследователи часто пишут, как будто бы такие результаты и ожидались изначально! Приходится, правда, немного подкрутить теоретические построения.\nОстановка набора испытуемых при достижении уровня значимости (Optional stopping). Представьте себе, что Вы не обнаружили значимых результатов, но p-value болтается около 0.05. Тогда Вам захочется добрать парочку испытуемых. А потом еще. И еще немного. Проблема с таким подходом в том, что рано или поздно Вы получите статистически значимые результаты. В любом случае, даже если эффекта нет. На самом деле, эта проблема не так сильно влияет на результаты как может показаться, но это все-таки достаточно плохая практика, а ее применение увеличивает количество опубликованных ложно-положительных результатов.\nНеправильное округление до .05. Всякий раз, когда видите p = .05 будьте внимательны: вообще-то он не может быть равен именно .05. Либо автор не очень этого понимает, либо просто p больше, а не меньше .05. Например, .054, что потом округляется до .05 и преподносится как статистически значимые результаты.\nИспользование односторонних тестов для сравнения средних. Эта практика похожа на предыдущую: исследователь получил p > .05, но меньше, чем .1. Недобросовестный исследователь, который хочет опубликоваться проводит односторонний т-тест вместо двустороннего, т.е. фактически просто делит р на 2. Совсем недобросовестные даже не пишут, что они использовали односторонний т-тест, хотя по умолчанию все используют двусторонний.\n\nДанный список не претендует на полноту. Этих практик стоит избегать и других от этого отучать. Ну а если Вы думаете, что никто не заметит, если Вы так сделаете, то это не так.\nНапример, последние две практики можно легко обнаружить с помощью сайта http://statcheck.io. Этот сайт делает магию: нужно кинуть ему статью, он распознает в ней статистические тесты и пересчитывает их. На самом деле, ничего сложного, а это сайт сделан с помощью R и уже знакомых нам инструментов: с помощью специальных пакетов из файлов вытаскивается текст, в тексте с помощью регулярных выражений находятся паттерны вроде “t(18) = -1.91, p = .036” - в большинстве журналов используется очень похожее форматирование статистических результатов. Зная степени свободы и т-статистику, можно пересчитать p-value. В данном случае это можно посчитать вот так:\n\npt(-1.91, df = 18)*2 #умножаем на 2, потому что двусторонний тест\n\n[1] 0.07219987\n\n\nНу а дальше остается сравнить это с тем, что написали авторы. Например, бывает как в данном случае, что пересчитанный p-value в два раза больше того, что написали авторы. Это означает, скорее всего, что авторы использовали односторонний критерий. Если они об этом нигде не сказали, то это очень плохо."
  },
  {
    "objectID": "410-planning.html#sec-reproducible",
    "href": "410-planning.html#sec-reproducible",
    "title": "24  Планирования научного исследования",
    "section": "24.2 Вопроизводимые исследования",
    "text": "24.2 Вопроизводимые исследования\nОчевидно, что перечисленных практик стоит избегать. Однако недостаточно просто сказать “ребята, давайте вы не будете пытаться во что бы то ни стало искать неожиданные результаты и публиковать их”. Поэтому сейчас предлагаются потенциальные решения пробоемы воспроизводимости исследований, которые постепенно набирают все большую популярность. Самое распространенное решение - это использование пререгистраций. Все просто: исследователь планирует исследование, какую выборку он хочет собрать, как будет обрабатывать данные, какие результаты он будет принимать как соответствующие гипотезе, а какие - нет. Получается что-то вроде научной статьи без результатов и их обсуждения, хотя можно и в более простом виде все представить: главное, есть доказательство, что исследование вы планировали провести именно так, а не подменяли все на ходу для красивых выводов. Другой способ добиться большей воспроизводимости результатов (и защиты от фальсификации) - это увеличение прозрачности в публикации данных и методов анализа. Существуют ученые (к счастью, такое встречается все реже), которые будут раздражаться, если их попросить дать вам данные. Мол, ну как же так, я их столько собирал, это же мои данные, а вот вы украдете у меня их и сделаете что-нибудь на них, опубликуете свою статью. Нет уж, мол, сами собирайте свои данные. Я терпел, и вы терпите. Очевидно, что наука - не забивание гвоздей, а ценность научной работы не обязательно пропорциональна количеству задействованных испытуемых. Собранные данные в некоторых случаях можно использовать в других исследованиях, а если все могут посмотреть исходные данные и проверить анализ, то это вообще круто и может защитить от ошибок.\nКонечно, не все готовы к таким разворотам в исследовательской практике. Но лучше быть готовым, потому что в какой-то момент может оказаться, что новые практики станут обязательными. И тут R будет весьма кстати: можно выкладывать данные c RMarkdown документом, который будет сразу собирать из этого статью и графики. Данные со скриптами можно выкладывать на GitHub - это удобно для коллективной работы над проектом. Другой вариант - выкладывать данные и скрипты для анализа на сайте osf.io. Это сайт специально сделанный как платформа для публикации данных исследований и скриптов для них."
  },
  {
    "objectID": "410-planning.html#sec-stat_power",
    "href": "410-planning.html#sec-stat_power",
    "title": "24  Планирования научного исследования",
    "section": "24.3 Статистическая мощность",
    "text": "24.3 Статистическая мощность\nЧтобы избежать optional stopping, нужно определять размер выборки заранее. Как это сделать? Наиболее корректный способ предполагает использование анализа статистической мощности (statistical power analysis). Для этого понадобится пакет pwr.\n\ninstall.packages(\"pwr\")\n\nЭтот пакет предоставляет семейство функций для расчета мощности, размера эффекта, уровня значимости или нужного размера выборки для разных статистических тестов.\nСтатистическая мощность - вероятность обнаружить статистически значимый эффект, если он действительно есть. Размер эффекта - собственно, размер эффекта в исследовании, обычно в универсальных единицах. Например, размер различия средних обычно измеряется в стандартных отклонениях. Это позволяет сравнивать эффекты в разных исследованиях и даже эффекты в разных областях науки.\nЕсли задать 3 из 4 чисел (статистическая мощность - стандартно это .8, уровень значимости - стандартно .05, размер эффекта, размер выборки), то функция выдаст недостающее число.\nЯ очень советую поиграться с этим самостоятельно. Например, если размер эффекта в единицах стандартных отклонений Cohen’s d = 2, то сколько нужно испытуемых, чтобы обнаружить эффект для двухвыборочного т-теста с вероятностью .8?\n\nlibrary(pwr)\npwr.t.test(d = 2, power = 0.8, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 5.089995\n              d = 2\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nВсеего 6 в каждой группе (округляем в большую сторону)!\n\npwr.t.test(d = 2, power = 0.8, type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 4.220726\n              d = 2\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nЕще меньше, если использовать within-subject дизайн исследования и зависимый т-тест.\nА если эффект маленький - всего d = .2?\n\npwr.t.test(d = .2, power = 0.8, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 393.4057\n              d = 0.2\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n394 испытуемых в каждой группе!\nМожно проверить такие расчеты самостоятельно с помощью симуляции данных.\n\nmean(replicate(1000, t.test(rnorm(394, 100, 15), rnorm(394, 103, 15))$p.value < 0.05))\n\n[1] 0.818\n\n\nДействительно, если много раз делать случайные выборки из двух нормальных распределений с средними, отличающимися на 0.2 стандартных отклонения, то примерно в 80% случаев вы получите статистически значимые различия!"
  },
  {
    "objectID": "910-tasks.html#sec-task_begin",
    "href": "910-tasks.html#sec-task_begin",
    "title": "25  Задания",
    "section": "25.1 Начало работы в R",
    "text": "25.1 Начало работы в R\n\nРазделите 9801 на 9.\n\n\n\n[1] 1089\n\n\n\nПосчитайте логарифм от 2176782336 по основанию 6.\n\n\n\n[1] 12\n\n\n\nТеперь натуральный логарифм 10 и умножьте его на 5.\n\n\n\n[1] 11.51293\n\n\n\nС помощью функции sin() посчитайте \\(\\sin (\\pi), \\sin \\left(\\frac{\\pi}{2}\\right), \\sin \\left(\\frac{\\pi}{6}\\right)\\).\n\n\nЗначение \\(\\pi\\) - зашитая в R константа (pi).\n\n\n\n[1] 1.224647e-16\n\n\n[1] 1\n\n\n[1] 0.5"
  },
  {
    "objectID": "910-tasks.html#sec-task_new_vecs",
    "href": "910-tasks.html#sec-task_new_vecs",
    "title": "25  Задания",
    "section": "25.2 Создание векторов",
    "text": "25.2 Создание векторов\n\nСоздайте вектор из значений 2, 30 и 4000.\n\n\n\n[1]    2   30 4000\n\n\n\nСоздайте вектор от 1 до 20.\n\n\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nСоздайте вектор от 20 до 1.\n\n\n\n [1] 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1\n\n\nФункция sum() возвращает сумму элементов вектора на входе. Посчитайте сумму первых 100 натуральных чисел (т.е. всех целых чисел от 1 до 100).\n\n\n[1] 5050\n\n\n\nСоздайте вектор от 1 до 20 и снова до 1. Число 20 должно присутствовать только один раз!\n\n\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 19 18 17 16 15\n[26] 14 13 12 11 10  9  8  7  6  5  4  3  2  1\n\n\n\nСоздайте вектор значений 5, 4, 3, 2, 2, 3, 4, 5:\n\n\n\n[1] 5 4 3 2 2 3 4 5\n\n\n\nСоздайте вектор 2, 4, 6, … , 18, 20.\n\n\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\n\nСоздайте вектор 0.1, 0.2, 0.3, …, 0.9, 1.\n\n\n\n [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n2020 год – високосный. Следующий високосный год через 4 года – это будет 2024 год. Составьте календарь всех високосных годов XXI века, начиная с 2020 года.\n\n\n2100 год относится к XXI веку, а не к XXII.\n\n\n\n [1] 2020 2024 2028 2032 2036 2040 2044 2048 2052 2056 2060 2064 2068 2072 2076\n[16] 2080 2084 2088 2092 2096 2100\n\n\n\nСоздайте вектор, состоящий из 20 повторений “Хэй!”.\n\n\n\n [1] \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\"\n[11] \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\"\n\n\n\nКак я и говорил, многие функции, работающие с одним значением на входе, так же прекрасно работают и с целыми векторами. Попробуйте посчитать квадратный корень чисел от 1 до 10 с помощью функции sqrt() и сохраните результат в векторе roots. Выведите содержание вектора roots в консоль.\n\n\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\n\n\n*Создайте вектор из одной единицы, двух двоек, трех троек, …. , девяти девяток.\n\n\n\n [1] 1 2 2 3 3 3 4 4 4 4 5 5 5 5 5 6 6 6 6 6 6 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 9 9\n[39] 9 9 9 9 9 9 9"
  },
  {
    "objectID": "910-tasks.html#sec-task_coer",
    "href": "910-tasks.html#sec-task_coer",
    "title": "25  Задания",
    "section": "25.3 Приведение типов",
    "text": "25.3 Приведение типов\n\nСделайте вектор vec1, в котором соедините 3, а также значения \"Мой\" и \"вектор\".\n\n\n\n[1] \"3\"      \"Мой\"    \"вектор\"\n\n\n\nПопробуйте вычесть TRUE из 10.\n\n\n\n[1] 9\n\n\n\nСоедините значение 10 и TRUE в вектор vec2.\n\n\n\n[1] 10  1\n\n\n\nСоедините вектор vec2 и значение \"r\":\n\n\n\n[1] \"10\" \"1\"  \"r\" \n\n\n\nСоедините значения 10, TRUE, \"r\" в вектор.\n\n\n\n[1] \"10\"   \"TRUE\" \"r\""
  },
  {
    "objectID": "910-tasks.html#sec-task_vec_ion",
    "href": "910-tasks.html#sec-task_vec_ion",
    "title": "25  Задания",
    "section": "25.4 Векторизация",
    "text": "25.4 Векторизация\n\nСоздайте вектор p, состоящий из значений 4, 5, 6, 7, и вектор q, состоящий из 0, 1, 2, 3.\n\n\n\n[1] 4 5 6 7\n\n\n[1] 0 1 2 3\n\n\n\nПосчитайте поэлементную сумму векторов p и q:\n\n\n\n[1]  4  6  8 10\n\n\n\nПосчитайте поэлементную разницу p и q:\n\n\n\n[1] 4 4 4 4\n\n\n\nПоделите каждый элемент вектора p на соответствующий ему элемент вектора q:\n\n\nО, да, Вам нужно делить на 0!\n\n\n\n[1]      Inf 5.000000 3.000000 2.333333\n\n\n\nВозведите каждый элемент вектора p в степень соответствующего ему элемента вектора q:\n\n\n\n[1]   1   5  36 343\n\n\n\nУмножьте каждое значение вектора p на 10.\n\n\n\n[1] 40 50 60 70\n\n\n\nСоздайте вектор квадратов чисел от 1 до 10:\n\n\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\nСоздайте вектор 0, 2, 0, 4, … , 18, 0, 20.\n\n\n\n [1]  0  2  0  4  0  6  0  8  0 10  0 12  0 14  0 16  0 18  0 20\n\n\n\nСоздайте вектор 1, 0, 3, 0, 5, …, 17, 0, 19, 0.\n\n\n\n [1]  1  0  3  0  5  0  7  0  9  0 11  0 13  0 15  0 17  0 19  0\n\n\n\n*Создайте вектор, в котором будут содержаться первые 20 степеней двойки.\n\n\n\n [1]       2       4       8      16      32      64     128     256     512\n[10]    1024    2048    4096    8192   16384   32768   65536  131072  262144\n[19]  524288 1048576\n\n\n\n*Создайте вектор из чисел 1, 10, 100, 1000, 10000:\n\n\n\n[1]     1    10   100  1000 10000\n\n\n\n*Посчитать сумму последовательности \\(\\frac{1}{1 \\cdot 2}+\\frac{1}{2 \\cdot 3}+\\frac{1}{3 \\cdot 4}+\\ldots+\\frac{1}{50 \\cdot 51}\\).\n\n\n\n[1] 0.9803922\n\n\n\n*Посчитать сумму последовательности \\(\\frac{1}{2^{0}}+\\frac{1}{2^{1}}+\\frac{1}{2^{2}}+\\frac{1}{2^{3}}+\\ldots \\frac{1}{2^{20}}\\).\n\n\n\n[1] 1.999999\n\n\n\n*Посчитать сумму последовательности \\(1+\\frac{4}{3}+\\frac{7}{9}+\\frac{10}{27}+\\frac{13}{81}+\\ldots+\\frac{28}{19683}\\).\n\n\n\n[1] 3.749174\n\n\n\n*Сколько чисел из последовательности \\(1+\\frac{4}{3}+\\frac{7}{9}+\\frac{10}{27}+\\frac{13}{81}+\\ldots+\\frac{28}{19683}\\) больше чем 0.5?\n\n\n\n[1] 3"
  },
  {
    "objectID": "910-tasks.html#sec-task_vec_ind",
    "href": "910-tasks.html#sec-task_vec_ind",
    "title": "25  Задания",
    "section": "25.5 Индексирование векторов",
    "text": "25.5 Индексирование векторов\n\nСоздайте вектор troiki со значениями 3, 6, 9, …, 24, 27.\n\n\n\n[1]  3  6  9 12 15 18 21 24 27\n\n\n\nИзвлеките 2, 5 и 7 значения вектора troiki.\n\n\n\n[1]  6 15 21\n\n\n\nИзвлеките предпоследнее значение вектора troiki.\n\n\n\n[1] 24\n\n\n\nИзвлеките все значения вектора troiki кроме предпоследнего:\n\n\n\n[1]  3  6  9 12 15 18 21 27\n\n\nСоздайте вектор vec3, скопировав следующий код:\n\nvec3 <- c(3, 5, 2, 1, 8, 4, 9, 10, 3, 15, 1, 11)\n\n\nНайдите второй элемент вектора vec3.\n\n\n\n[1] 5\n\n\n\nВерните второй и пятый элемент вектора vec3.\n\n\n\n[1] 5 8\n\n\n\nПопробуйте извлечь сотое значение вектора vec3:\n\n\n\n[1] NA\n\n\n\nВерните все элементы вектора vec3 кроме второго элемента.\n\n\n\n [1]  3  2  1  8  4  9 10  3 15  1 11\n\n\n\nВерните все элементы вектора vec3 кроме второго и пятого элемента.\n\n\n\n [1]  3  2  1  4  9 10  3 15  1 11\n\n\n\nНайдите последний элемент вектора vec3.\n\n\n\n[1] 11\n\n\n\nВерните все значения вектора vec3 кроме первого и последнего.\n\n\n\n [1]  5  2  1  8  4  9 10  3 15  1\n\n\n\nНайдите все значения вектора vec3, которые больше 4.\n\n\n\n[1]  5  8  9 10 15 11\n\n\n\nНайдите все значения вектора vec3, которые больше 4, но меньше 10.\n\n\nЕсли хотите сделать это в одну строчку, то вам помогут логические операторы!\n\n\n\n[1] 5 8 9\n\n\n\nНайдите все значения вектора vec3, которые меньше 4 или больше 10.\n\n\n\n[1]  3  2  1  3 15  1 11\n\n\n\nВозведите в квадрат каждое значение вектора vec3.\n\n\n\n [1]   9  25   4   1  64  16  81 100   9 225   1 121\n\n\n\n*Возведите в квадрат каждое значение вектора на нечетной позиции и извлеките корень из каждого значения на четной позиции вектора vec3.\n\n\nИзвлечение корня - это то же самое, что и возведение в степень 0.5.\n\n\n\n [1]  9.000000  2.236068  4.000000  1.000000 64.000000  2.000000 81.000000\n [8]  3.162278  9.000000  3.872983  1.000000  3.316625\n\n\n\nСоздайте вектор 2, 4, 6, … , 18, 20 как минимум 2 новыми способами.\n\n\nЗнаю, это задание может показаться бессмысленным, но это очень базовая операция, с помощью которой можно, например, разделить данные на две части. Чем больше способов Вы знаете, тем лучше!\n\n\n\n [1]  2  4  6  8 10 12 14 16 18 20"
  },
  {
    "objectID": "910-tasks.html#sec-task_na",
    "href": "910-tasks.html#sec-task_na",
    "title": "25  Задания",
    "section": "25.6 Работа с пропущенными значениями",
    "text": "25.6 Работа с пропущенными значениями\n\nСоздайте вектор vec4 со значениями 300, 15, 8, 2, 0, 1, 110, скопировав следующий код:\n\n\nvec4 <- c(300, 15, 8, 20, 0, 1, 110)\nvec4\n\n[1] 300  15   8  20   0   1 110\n\n\n\nЗамените все значения vec4, которые больше 20 на NA.\n\n\nПроверьте полученный вектор vec4:\n\n\n\n[1] NA 15  8 20  0  1 NA\n\n\n\nПосчитайте сумму vec4 с помощью функции sum(). Ответ NA не считается!\n\n\n\n[1] 44"
  },
  {
    "objectID": "910-tasks.html#sec-task_matrix",
    "href": "910-tasks.html#sec-task_matrix",
    "title": "25  Задания",
    "section": "25.7 Матрицы",
    "text": "25.7 Матрицы\n\nСоздайте матрицу 4х4, состоящую из единиц. Назовите ее M1.\n\n\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    1    1    1\n[2,]    1    1    1    1\n[3,]    1    1    1    1\n[4,]    1    1    1    1\n\n\n\nПоменяйте все некрайние значения матрицы M1 (то есть значения на позициях [2,2], [2,3], [3,2] и [3,3]) на число 2.\n\n\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    1    1    1\n[2,]    1    2    2    1\n[3,]    1    2    2    1\n[4,]    1    1    1    1\n\n\n\nВыделите второй и третий столбик из матрицы M1.\n\n\n\n     [,1] [,2]\n[1,]    1    1\n[2,]    2    2\n[3,]    2    2\n[4,]    1    1\n\n\n\nСравните (==) вторую колонку и вторую строчку матрицы M1.\n\n\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n*Создайте таблицу умножения (9х9) в виде матрицы. Сохраните ее в переменную mult_tab.\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n [1,]    1    2    3    4    5    6    7    8    9\n [2,]    2    4    6    8   10   12   14   16   18\n [3,]    3    6    9   12   15   18   21   24   27\n [4,]    4    8   12   16   20   24   28   32   36\n [5,]    5   10   15   20   25   30   35   40   45\n [6,]    6   12   18   24   30   36   42   48   54\n [7,]    7   14   21   28   35   42   49   56   63\n [8,]    8   16   24   32   40   48   56   64   72\n [9,]    9   18   27   36   45   54   63   72   81\n\n\n\n*Из матрицы mult_tab выделите подматрицу, включающую в себя только строчки с 6 по 8 и столбцы с 3 по 7.\n\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   18   24   30   36   42\n[2,]   21   28   35   42   49\n[3,]   24   32   40   48   56\n\n\n\n*Создайте матрицу с логическими значениями, где TRUE, если в этом месте в таблице умножения (mult_tab) двузначное число и FALSE, если однозначное.\n\n\nМатрица - это почти вектор. К нему можно обращаться с единственным индексом.\n\n\n\n       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]\n [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [2,] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [3,] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [4,] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [5,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [6,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [7,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [8,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [9,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\n*Создайте матрицу mult_tab2, в которой все значения tab меньше 10 заменены на 0.\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n [1,]    0    0    0    0    0    0    0    0    0\n [2,]    0    0    0    0   10   12   14   16   18\n [3,]    0    0    0   12   15   18   21   24   27\n [4,]    0    0   12   16   20   24   28   32   36\n [5,]    0   10   15   20   25   30   35   40   45\n [6,]    0   12   18   24   30   36   42   48   54\n [7,]    0   14   21   28   35   42   49   56   63\n [8,]    0   16   24   32   40   48   56   64   72\n [9,]    0   18   27   36   45   54   63   72   81"
  },
  {
    "objectID": "910-tasks.html#sec-task_list",
    "href": "910-tasks.html#sec-task_list",
    "title": "25  Задания",
    "section": "25.8 Списки",
    "text": "25.8 Списки\nДан список list1:\n\nlist1 = list(numbers = 1:5, letters = letters, logic = TRUE)\nlist1\n\n$numbers\n[1] 1 2 3 4 5\n\n$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$logic\n[1] TRUE\n\n\n\nНайдите первый элемент списка list1. Ответ должен быть списком длиной один.\n\n\n\n$numbers\n[1] 1 2 3 4 5\n\n\n\nТеперь найдите содержание первого элемента списка list1 двумя разными способами. Ответ должен быть вектором.\n\n\n\n[1] 1 2 3 4 5\n\n\n[1] 1 2 3 4 5\n\n\n\nТеперь возьмите первый элемент содержания первого элемента списка list1. Ответ должен быть вектором.\n\n\n\n[1] 1\n\n\n\nСоздайте список list2, содержащий в себе два списка list1. Один из них будет иметь имя pupa, а другой – lupa.\n\n\n\n$pupa\n$pupa$numbers\n[1] 1 2 3 4 5\n\n$pupa$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$pupa$logic\n[1] TRUE\n\n\n$lupa\n$lupa$numbers\n[1] 1 2 3 4 5\n\n$lupa$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$lupa$logic\n[1] TRUE\n\n\n\n*Извлеките первый элемент списка list2, из него – второй подэлемент, а из него – третье значение.\n\n\n\n[1] \"c\""
  },
  {
    "objectID": "910-tasks.html#sec-task_df",
    "href": "910-tasks.html#sec-task_df",
    "title": "25  Задания",
    "section": "25.9 Датафрейм",
    "text": "25.9 Датафрейм\n\nЗапустите команду data(mtcars) чтобы загрузить встроенный датафрейм с информацией про автомобили. Каждая строчка датафрейма - модель автомобиля, каждая колонка - отдельная характеристика. Подробнее см. ?mtcars.\n\n\ndata(mtcars)\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nИзучите структуру датафрейма mtcars с помощью функции str().\n\n\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\nНайдите значение третьей строчки четвертого столбца датафрейма mtcars.\n\n\n\n[1] 93\n\n\n\nИзвлеките первые шесть строчек и первые шесть столбцов датафрейма mtcars.\n\n\n\n                   mpg cyl disp  hp drat    wt\nMazda RX4         21.0   6  160 110 3.90 2.620\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875\nDatsun 710        22.8   4  108  93 3.85 2.320\nHornet 4 Drive    21.4   6  258 110 3.08 3.215\nHornet Sportabout 18.7   8  360 175 3.15 3.440\nValiant           18.1   6  225 105 2.76 3.460\n\n\n\nИзвлеките колонку wt датафрейма mtcars - массу автомобиля в тысячах фунтов.\n\n\n\n [1] 2.620 2.875 2.320 3.215 3.440 3.460 3.570 3.190 3.150 3.440 3.440 4.070\n[13] 3.730 3.780 5.250 5.424 5.345 2.200 1.615 1.835 2.465 3.520 3.435 3.840\n[25] 3.845 1.935 2.140 1.513 3.170 2.770 3.570 2.780\n\n\n\nИзвлеките колонки из mtcars в следующем порядке: hp, mpg, cyl.\n\n\n\n                     hp  mpg cyl\nMazda RX4           110 21.0   6\nMazda RX4 Wag       110 21.0   6\nDatsun 710           93 22.8   4\nHornet 4 Drive      110 21.4   6\nHornet Sportabout   175 18.7   8\nValiant             105 18.1   6\nDuster 360          245 14.3   8\nMerc 240D            62 24.4   4\nMerc 230             95 22.8   4\nMerc 280            123 19.2   6\nMerc 280C           123 17.8   6\nMerc 450SE          180 16.4   8\nMerc 450SL          180 17.3   8\nMerc 450SLC         180 15.2   8\nCadillac Fleetwood  205 10.4   8\nLincoln Continental 215 10.4   8\nChrysler Imperial   230 14.7   8\nFiat 128             66 32.4   4\nHonda Civic          52 30.4   4\nToyota Corolla       65 33.9   4\nToyota Corona        97 21.5   4\nDodge Challenger    150 15.5   8\nAMC Javelin         150 15.2   8\nCamaro Z28          245 13.3   8\nPontiac Firebird    175 19.2   8\nFiat X1-9            66 27.3   4\nPorsche 914-2        91 26.0   4\nLotus Europa        113 30.4   4\nFord Pantera L      264 15.8   8\nFerrari Dino        175 19.7   6\nMaserati Bora       335 15.0   8\nVolvo 142E          109 21.4   4\n\n\n\nПосчитайте количество автомобилей с 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\n\n[1] 11\n\n\n\nПосчитайте долю автомобилей с 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\n\n[1] 0.34375\n\n\n\nНайдите все автомобили мощностью не менее 100 лошадиных сил (hp) в датафрейме mtcars.\n\n\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nНайдите все автомобили мощностью не менее 100 лошадиных сил (hp) и 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\n\n              mpg cyl  disp  hp drat    wt qsec vs am gear carb\nLotus Europa 30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nVolvo 142E   21.4   4 121.0 109 4.11 2.780 18.6  1  1    4    2\n\n\n\nПосчитайте максимальную массу (wt) автомобиля в выборке, воспользовавшись функцией max():\n\n\n\n[1] 5.424\n\n\n\nПосчитайте минимальную массу (wt) автомобиля в выборке, воспользовавшись функцией min():\n\n\n\n[1] 1.513\n\n\n\nНайдите строчку датафрейма mtcars с самым легким автомобилем.\n\n\n\n              mpg cyl disp  hp drat    wt qsec vs am gear carb\nLotus Europa 30.4   4 95.1 113 3.77 1.513 16.9  1  1    5    2\n\n\n\nИзвлеките строчки датафрейма mtcars с автомобилями, масса которых ниже средней массы.\n\n\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nМасса автомобиля указана в тысячах фунтов. Создайте колонку wt_kg с массой автомобиля в килограммах. Результат округлите до целых значений с помощью функции round().\n\n\n1 фунт = 0.45359237 кг.\n\n\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb wt_kg\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  1188\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  1304\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1  1052\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  1458\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  1560\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  1569\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  1619\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  1447\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  1429\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  1560\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  1560\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  1846\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  1692\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  1715\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  2381\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  2460\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  2424\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1   998\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2   733\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1   832\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  1118\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  1597\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  1558\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  1742\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  1744\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1   878\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2   971\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2   686\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  1438\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  1256\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  1619\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  1261"
  },
  {
    "objectID": "910-tasks.html#sec-task_if",
    "href": "910-tasks.html#sec-task_if",
    "title": "25  Задания",
    "section": "25.10 Условные конструкции",
    "text": "25.10 Условные конструкции\n\nСоздайте вектор vec5, скопировав следующий код:\n\n\nvec5 <- c(5, 20, 30, 0, 2, 9)\n\n\nСоздайте новый строковый вектор, где на месте чисел больше 10 в vec5 будет стоять “большое число”, а на месте остальных чисел – “маленькое число”.\n\n\n\n[1] \"маленькое число\" \"большое число\"   \"большое число\"   \"маленькое число\"\n[5] \"маленькое число\" \"маленькое число\"\n\n\n\nЗагрузите файл heroes_information.csv в переменную heroes.\n\n\nheroes <- read.csv(\"data/heroes_information.csv\", \n                   stringsAsFactors = FALSE,\n                   na.strings = c(\"-\", \"-99\"))\n\n\nСоздайте новою колонку hair в heroes, в которой будет значение \"Bold\" для тех супергероев, у которых в колонке Hair.color стоит \"No Hair\", и значение \"Hairy\" во всех остальных случаях.\n\n\n\n  X          name Gender Eye.color              Race Hair.color Height\n1 0        A-Bomb   Male    yellow             Human    No Hair    203\n2 1    Abe Sapien   Male      blue     Icthyo Sapien    No Hair    191\n3 2      Abin Sur   Male      blue           Ungaran    No Hair    185\n4 3   Abomination   Male     green Human / Radiation    No Hair    203\n5 4       Abraxas   Male      blue     Cosmic Entity      Black     NA\n6 5 Absorbing Man   Male      blue             Human    No Hair    193\n          Publisher Skin.color Alignment Weight  hair\n1     Marvel Comics       <NA>      good    441  Bold\n2 Dark Horse Comics       blue      good     65  Bold\n3         DC Comics        red      good     90  Bold\n4     Marvel Comics       <NA>       bad    441  Bold\n5     Marvel Comics       <NA>       bad     NA Hairy\n6     Marvel Comics       <NA>       bad    122  Bold\n\n\n\nСоздайте новою колонку tall в heroes, в которой будет значение \"tall\" для тех супергероев, у которых в колонке Height стоит число больше 190, значение \"short\" для тех супергероев, у которых в колонке Height стоит число меньше 170, и значение \"middle\" во всех остальных случаях."
  },
  {
    "objectID": "910-tasks.html#sec-task_function",
    "href": "910-tasks.html#sec-task_function",
    "title": "25  Задания",
    "section": "25.11 Создание функций",
    "text": "25.11 Создание функций\n\nСоздайте функцию plus_one(), которая принимает число и возвращает это же число + 1.\n\n\nПроверьте функцию plus_one() на числе 41.\n\n\nplus_one(41)\n\n[1] 42\n\n\n\nСоздайте функцию circle_area(), которая вычисляет площадь круга по радиусу согласно формуле \\(\\pi r^2\\).\n\n\nПосчитайте площадь круга с радиусом 5.\n\n\n\n[1] 78.53982\n\n\n\nСоздайте функцию cels2fahr(), которая будет превращать градусы по Цельсию в градусы по Фаренгейту.\n\n\nПроверьте на значениях -100, -40 и 0, что функция cels2fahr() работает корректно.\n\n\ncels2fahr(c(-100, -40, 0))\n\n[1] -148  -40   32\n\n\n\nНапишите функцию highlight(), которая принимает на входе строковый вектор, а возвращает тот же вектор, но дополненный значением \"***\" в начале и конце вектора. Лучше всего это рассмотреть на примере:\n\n\nhighlight(c(\"Я\", \"Бэтмен!\"))\n\n[1] \"***\"     \"Я\"       \"Бэтмен!\" \"***\"    \n\n\n\nТеперь сделайте функцию highlight более гибкой. Добавьте в нее параметр wrapper =, который по умолчанию равен \"***\". Значение параметра wrapper = и будет вставлено в начало и конец вектора.\n\n\nПроверьте написанную функцию на векторе c(\"Я\", \"Бэтмен!\").\n\n\nhighlight(c(\"Я\", \"Бэтмен!\")) \n\n[1] \"***\"     \"Я\"       \"Бэтмен!\" \"***\"    \n\nhighlight(c(\"Я\", \"Бэтмен!\"), wrapper = \"__\") \n\n[1] \"__\"      \"Я\"       \"Бэтмен!\" \"__\"     \n\n\n\nСоздайте функцию na_n(), которая будет возвращать количество NA в векторе.\n\n\nПроверьте функцию na_n() на векторе:\n\n\nna_n(c(NA, 3:5, NA, 2, NA))\n\n[1] 3\n\n\n\nНапишите функцию factors(), которая будет возвращать все делители числа в виде числового вектора.\n\n\nЗдесь может понадобиться оператор для получения остатка от деления: %%.\n\n\nПроверьте функцию factors() на простых и сложных числах:\n\n\nfactors(3)\n\n[1] 1 3\n\nfactors(161)\n\n[1]   1   7  23 161\n\nfactors(1984)\n\n [1]    1    2    4    8   16   31   32   62   64  124  248  496  992 1984\n\n\n\n*Напишите функцию is_prime(), которая проверяет, является ли число простым.\n\n\nЗдесь может пригодиться функция any() - она возвращает TRUE, если в векторе есть хотя бы один TRUE.\n\n\nПроверьте какие года были для нас простыми, а какие нет:\n\n\nis_prime(2017)\n\n[1] TRUE\n\nis_prime(2019)\n\n[1] FALSE\n\n2019/3 #2019 делится на 3 без остатка\n\n[1] 673\n\nis_prime(2020)\n\n[1] FALSE\n\nis_prime(2021)\n\n[1] FALSE\n\n\n\n*Создайте функцию monotonic(), которая возвращает TRUE, если значения в векторе не убывают (то есть каждое следующее - больше или равно предыдущему) или не возврастают.\n\n\nПолезная функция для этого – diff() – возвращает разницу соседних значений.\n\n\nmonotonic(1:7)\n\n[1] TRUE\n\nmonotonic(c(1:5,5:1))\n\n[1] FALSE\n\nmonotonic(6:-1)\n\n[1] TRUE\n\nmonotonic(c(1:5, rep(5, 10), 5:10))\n\n[1] TRUE\n\n\nБинарные операторы типа + или %in% тоже представляют собой функции. Более того, мы можем создавать свои бинарные операторы! В этом нет особой сложности – нужно все так же создавать функцию (для двух переменных), главное окружать их % и название обрамлять обратными штрихами `. Например, можно сделать свой бинарный оператор %notin%, который будет выдавать TRUE, если значения слева нет в векторе справа:\n\n`%notin%` <- function(x, y) ! (x %in% y)\n1:10 %notin% c(1, 4, 5)\n\n [1] FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\n*Создайте бинарный оператор %without%, который будет возвращать все значения вектора слева без значений вектора справа.\n\n\nc(\"а\", \"и\", \"б\", \"сидели\", \"на\", \"трубе\") %without% c(\"а\", \"б\")\n\n[1] \"и\"      \"сидели\" \"на\"     \"трубе\" \n\n\n\n*Создайте бинарный оператор %between%, который будет возвращать TRUE, если значение в векторе слева накходится в диапазоне значений вектора справа:\n\n\n1:10 %between% c(1, 4, 5)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "910-tasks.html#sec-task_sanity",
    "href": "910-tasks.html#sec-task_sanity",
    "title": "25  Задания",
    "section": "25.12 Проверка на адекватность",
    "text": "25.12 Проверка на адекватность\n\nСоздайте функцию trim(), которая будет возвращать вектор без первого и последнего значения (вне зависимости от типа данных).\n\n\nПроверьте, что функция trim() работает корректно:\n\n\ntrim(1:7)\n\n[1] 2 3 4 5 6\n\ntrim(letters)\n\n [1] \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[20] \"u\" \"v\" \"w\" \"x\" \"y\"\n\n\n\nТеперь добавьте в функцию trim() параметр n = со значением по умолчанию 1. Этот параметр будет обозначать сколько значений нужно отрезать слева и справа от вектора.\n\n\nПроверьте полученную функцию:\n\n\ntrim(letters)\n\n [1] \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[20] \"u\" \"v\" \"w\" \"x\" \"y\"\n\ntrim(letters, n = 2)\n\n [1] \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\"\n[20] \"v\" \"w\" \"x\"\n\n\n\nСделайте так, чтобы функция trim() работала корректно с n = 0, т.е. функция возвращала бы исходный вектор без изменений.\n\n\ntrim(letters, n = 0)\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n\n*Теперь добавьте проверку на адекватность входных данных: функция trim() должна выдавать ошибку, если n = меньше нуля или если n = слишком большой и отрезает все значения вектора:\n\n\n*Проверьте полученную функцию trim():\n\n\ntrim(1:6, 3)\n\nError in trim(1:6, 3): n слишком большой!\n\ntrim(1:6, -1)\n\nError in trim(1:6, -1): n не может быть меньше нуля!"
  },
  {
    "objectID": "910-tasks.html#sec-task_apply",
    "href": "910-tasks.html#sec-task_apply",
    "title": "25  Задания",
    "section": "25.13 Семейство функций apply()",
    "text": "25.13 Семейство функций apply()\n\nСоздайте матрицу M2:\n\n\nM2 <- matrix(c(20:11, 11:20), nrow = 5)\nM2\n\n     [,1] [,2] [,3] [,4]\n[1,]   20   15   11   16\n[2,]   19   14   12   17\n[3,]   18   13   13   18\n[4,]   17   12   14   19\n[5,]   16   11   15   20\n\n\n\nПосчитайте максимальное значение матрицы M2 по каждой строчке.\n\n\n\n[1] 20 19 18 19 20\n\n\n\nПосчитайте максимальное значение матрицы M2 по каждому столбцу.\n\n\n\n[1] 20 15 15 20\n\n\n\nПосчитайте среднее значение матрицы M2 по каждой строке.\n\n\n\n[1] 15.5 15.5 15.5 15.5 15.5\n\n\n\nПосчитайте среднее значение матрицы M2 по каждому столбцу.\n\n\n\n[1] 18 13 13 18\n\n\n\nСоздайте список list3:\n\n\nlist3 <- list(\n  a = 1:5,\n  b = 0:20,\n  c = 4:24,\n  d = 6:3,\n  e = 6:25\n  )\n\n\nНайдите максимальное значение каждого вектора списка list3.\n\n\n\n a  b  c  d  e \n 5 20 24  6 25 \n\n\n\nПосчитайте сумму каждого вектора списка list3.\n\n\n\n  a   b   c   d   e \n 15 210 294  18 310 \n\n\n\nПосчитайте длину каждого вектора списка list3.\n\n\n\n a  b  c  d  e \n 5 21 21  4 20 \n\n\n\nНапишите функцию max_item(), которая будет принимать на входе список, а возвращать - (первый) самый длинный его элемент.\n\n\nДля этого вам может понадобиться функция which.max(), которая возвращает индекс максимального значения (первого, если их несколько).\n\n\nПроверьте функцию max_item() на списке list3.\n\n\nmax_item(list3)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nТеперь мы сделаем сложный список list4:\n\n\nlist4 <- list(1:3, 3:40, list3)\n\n\nПосчитайте длину каждого вектора в списке, в т.ч. для списка внутри. Результат должен быть списком с такой же структорой, как и изначальный список list4.\n\n\nДля этого может понадобиться функция rapply(): recursive lapply\n\n\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 38\n\n[[3]]\n[[3]]$a\n[1] 5\n\n[[3]]$b\n[1] 21\n\n[[3]]$c\n[1] 21\n\n[[3]]$d\n[1] 4\n\n[[3]]$e\n[1] 20\n\n\n\n*Загрузите набор данных heroes и посчитайте, сколько NA в каждом из столбцов.\n\n\nДля этого удобно использовать ранее написанную функцию na_n().\n\n\n\n         X       name     Gender  Eye.color       Race Hair.color     Height \n         0          0         29        172        304        172        217 \n Publisher Skin.color  Alignment     Weight       hair       tall \n         0        662          7        239        172        217 \n\n\n\n*Используя ранее написанную функцию is_prime(), напишите функцию prime_numbers(), которая будет возвращать все простые числа до выбранного числа.\n\n\nprime_numbers(200)\n\n [1]   3   5   7  11  13  17  19  23  29  31  37  41  43  47  53  59  61  67  71\n[20]  73  79  83  89  97 101 103 107 109 113 127 131 137 139 149 151 157 163 167\n[39] 173 179 181 191 193 197 199"
  },
  {
    "objectID": "910-tasks.html#sec-task_pipe",
    "href": "910-tasks.html#sec-task_pipe",
    "title": "25  Задания",
    "section": "25.14 magrittr::%>%",
    "text": "25.14 magrittr::%>%\n\nПерепишите следующие выражения, используя %>%:\n\n\nsqrt(sum(1:10))\n\n[1] 7.416198\n\n\n\n\n[1] 7.416198\n\n\n\nabs(min(-5:5))\n\n[1] 5\n\n\n\n\n[1] 5\n\n\n\nc(\"Корень из\", 2, \"равен\", sqrt(2))\n\n[1] \"Корень из\"       \"2\"               \"равен\"           \"1.4142135623731\"\n\n\n\n\n[1] \"Корень из\"       \"2\"               \"равен\"           \"1.4142135623731\"\n\n\n\nB <- matrix(10:39, nrow = 5)\napply(B, 1, mean)\n\n[1] 22.5 23.5 24.5 25.5 26.5"
  },
  {
    "objectID": "910-tasks.html#sec-task_select",
    "href": "910-tasks.html#sec-task_select",
    "title": "25  Задания",
    "section": "25.15 Выбор столбцов: dplyr::select()",
    "text": "25.15 Выбор столбцов: dplyr::select()\nДля выполнения следующих заданий нам понадобятся датасеты heroes и powers, которые можно загрузить, используя следующие команды:\n\nlibrary(tidyverse)\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\npowers <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/super_hero_powers.csv\")\n\n\nВыберете первые 4 столбца в powers.\n\n\n\n# A tibble: 667 × 4\n   hero_names    Agility `Accelerated Healing` `Lantern Power Ring`\n   <chr>         <lgl>   <lgl>                 <lgl>               \n 1 3-D Man       TRUE    FALSE                 FALSE               \n 2 A-Bomb        FALSE   TRUE                  FALSE               \n 3 Abe Sapien    TRUE    TRUE                  FALSE               \n 4 Abin Sur      FALSE   FALSE                 TRUE                \n 5 Abomination   FALSE   TRUE                  FALSE               \n 6 Abraxas       FALSE   FALSE                 FALSE               \n 7 Absorbing Man FALSE   FALSE                 FALSE               \n 8 Adam Monroe   FALSE   TRUE                  FALSE               \n 9 Adam Strange  FALSE   FALSE                 FALSE               \n10 Agent Bob     FALSE   FALSE                 FALSE               \n# … with 657 more rows\n\n\n\nВыберите все столбцы от Reflexes до Empathy в тиббле powers:\n\n\n\n# A tibble: 667 × 7\n   Reflexes Invulnerability `Energy Constructs` Force …¹ Self-…² Anti-…³ Empathy\n   <lgl>    <lgl>           <lgl>               <lgl>    <lgl>   <lgl>   <lgl>  \n 1 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 2 FALSE    FALSE           FALSE               FALSE    TRUE    FALSE   FALSE  \n 3 TRUE     FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 4 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 5 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 6 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 7 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 8 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 9 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n10 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n# … with 657 more rows, and abbreviated variable names ¹​`Force Fields`,\n#   ²​`Self-Sustenance`, ³​`Anti-Gravity`\n\n\n\nВыберите все столбцы тиббла powers кроме первого (hero_names):\n\n\n\n# A tibble: 667 × 167\n   Agility Accelerated …¹ Lante…² Dimen…³ Cold …⁴ Durab…⁵ Stealth Energ…⁶ Flight\n   <lgl>   <lgl>          <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl> \n 1 TRUE    FALSE          FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 2 FALSE   TRUE           FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE \n 3 TRUE    TRUE           FALSE   FALSE   TRUE    TRUE    FALSE   FALSE   FALSE \n 4 FALSE   FALSE          TRUE    FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 5 FALSE   TRUE           FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 6 FALSE   FALSE          FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   TRUE  \n 7 FALSE   FALSE          FALSE   FALSE   TRUE    TRUE    FALSE   TRUE    FALSE \n 8 FALSE   TRUE           FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 9 FALSE   FALSE          FALSE   FALSE   FALSE   TRUE    TRUE    FALSE   TRUE  \n10 FALSE   FALSE          FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE \n# … with 657 more rows, 158 more variables: `Danger Sense` <lgl>,\n#   `Underwater breathing` <lgl>, Marksmanship <lgl>, `Weapons Master` <lgl>,\n#   `Power Augmentation` <lgl>, `Animal Attributes` <lgl>, Longevity <lgl>,\n#   Intelligence <lgl>, `Super Strength` <lgl>, Cryokinesis <lgl>,\n#   Telepathy <lgl>, `Energy Armor` <lgl>, `Energy Blasts` <lgl>,\n#   Duplication <lgl>, `Size Changing` <lgl>, `Density Control` <lgl>,\n#   Stamina <lgl>, `Astral Travel` <lgl>, `Audio Control` <lgl>, …"
  },
  {
    "objectID": "910-tasks.html#sec-task_filt",
    "href": "910-tasks.html#sec-task_filt",
    "title": "25  Задания",
    "section": "25.16 Выбор строк: dplyr::slice() и dplyr::filter()",
    "text": "25.16 Выбор строк: dplyr::slice() и dplyr::filter()\n\nВыберите только те строчки, в которых содержится информация о супергероях тяжелее 500 кг.\n\n\n\n# A tibble: 6 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   203 Dark… Male   red     New … No Hair  267   DC Com… grey    bad        817\n2   283 Giga… Female green   <NA>  Red       62.5 DC Com… <NA>    bad        630\n3   331 Hulk  Male   green   Huma… Green    244   Marvel… green   good       630\n4   373 Jugg… Male   blue    Human Red      287   Marvel… <NA>    neutral    855\n5   549 Red … Male   yellow  Huma… Black    213   Marvel… red     neutral    630\n6   575 Sasq… Male   red     <NA>  Orange   305   Marvel… <NA>    good       900\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nВыберите только те строчки, в которых содержится информация о женщинах-супергероях тяжелее 500 кг.\n\n\n\n# A tibble: 1 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   283 Giga… Female green   <NA>  Red       62.5 DC Com… <NA>    bad        630\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nВыберите только те строчки, в которых содержится информация о супергероях человеческой расы (\"Human\") женского пола. Из этих супергероев возьмите первые 5.\n\n\n\n# A tibble: 5 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1    38 Arac… Female blue    Human Blond      175 Marvel… <NA>    good        63\n2    63 Batg… Female green   Human Red        170 DC Com… <NA>    good        57\n3    65 Batg… Female green   Human Black      165 DC Com… <NA>    good        52\n4    72 Batw… Female green   Human Red        178 DC Com… <NA>    good        NA\n5    96 Blac… Female blue    Human Blond      165 DC Com… <NA>    good        58\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "910-tasks.html#sec-task_arr",
    "href": "910-tasks.html#sec-task_arr",
    "title": "25  Задания",
    "section": "25.17 Сортировка строк: dplyr::arrange()",
    "text": "25.17 Сортировка строк: dplyr::arrange()\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки по возрастанию Height.\n\n\n\n# A tibble: 734 × 3\n   name            Gender Height\n   <chr>           <chr>   <dbl>\n 1 Utgard-Loki     Male     15.2\n 2 Bloodwraith     Male     30.5\n 3 King Kong       Male     30.5\n 4 Anti-Monitor    Male     61  \n 5 Giganta         Female   62.5\n 6 Krypto          Male     64  \n 7 Yoda            Male     66  \n 8 Jack-Jack       Male     71  \n 9 Howard the Duck Male     79  \n10 Godzilla        <NA>    108  \n# … with 724 more rows\n\n\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки по убыванию Height.\n\n\n\n# A tibble: 734 × 3\n   name          Gender Height\n   <chr>         <chr>   <dbl>\n 1 Fin Fang Foom Male     975 \n 2 Galactus      Male     876 \n 3 Groot         Male     701 \n 4 MODOK         Male     366 \n 5 Wolfsbane     Female   366 \n 6 Onslaught     Male     305 \n 7 Sasquatch     Male     305 \n 8 Ymir          Male     305.\n 9 Rey           Female   297 \n10 Juggernaut    Male     287 \n# … with 724 more rows\n\n\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки сначала по Gender, затем по убыванию Height.\n\n\n\n# A tibble: 734 × 3\n   name      Gender Height\n   <chr>     <chr>   <dbl>\n 1 Wolfsbane Female    366\n 2 Rey       Female    297\n 3 Bloodaxe  Female    218\n 4 Thundra   Female    218\n 5 Hela      Female    213\n 6 Frenzy    Female    211\n 7 She-Hulk  Female    201\n 8 Ardina    Female    193\n 9 Starfire  Female    193\n10 Valkyrie  Female    191\n# … with 724 more rows"
  },
  {
    "objectID": "910-tasks.html#sec-task_dist",
    "href": "910-tasks.html#sec-task_dist",
    "title": "25  Задания",
    "section": "25.18 Уникальные значения: dplyr::distinct()",
    "text": "25.18 Уникальные значения: dplyr::distinct()\n\nИзвлеките уникальные значения столбца Eye color из тиббла heroes.\n\n\n\n# A tibble: 23 × 1\n   `Eye color`\n   <chr>      \n 1 yellow     \n 2 blue       \n 3 green      \n 4 brown      \n 5 <NA>       \n 6 red        \n 7 violet     \n 8 white      \n 9 purple     \n10 black      \n# … with 13 more rows\n\n\n\nИзвлеките уникальные значения столбца Hair color из тиббла heroes.\n\n\n\n# A tibble: 30 × 1\n   `Hair color`\n   <chr>       \n 1 No Hair     \n 2 Black       \n 3 Blond       \n 4 Brown       \n 5 <NA>        \n 6 White       \n 7 Purple      \n 8 Orange      \n 9 Pink        \n10 Red         \n# … with 20 more rows"
  },
  {
    "objectID": "910-tasks.html#sec-task_mutate",
    "href": "910-tasks.html#sec-task_mutate",
    "title": "25  Задания",
    "section": "25.19 Создание колонок: dplyr::mutate() и dplyr::transmute()",
    "text": "25.19 Создание колонок: dplyr::mutate() и dplyr::transmute()\n\nСоздайте колонку height_m с ростом супергероев в метрах, затем выберите только колонки name и height_m.\n\n\n\n# A tibble: 734 × 2\n   name          height_m\n   <chr>            <dbl>\n 1 A-Bomb            2.03\n 2 Abe Sapien        1.91\n 3 Abin Sur          1.85\n 4 Abomination       2.03\n 5 Abraxas          NA   \n 6 Absorbing Man     1.93\n 7 Adam Monroe      NA   \n 8 Adam Strange      1.85\n 9 Agent 13          1.73\n10 Agent Bob         1.78\n# … with 724 more rows\n\n\n\nСоздайте новою колонку hair в heroes, в которой будет значение \"Bold\" для тех супергероев, у которых в колонке Hair.color стоит \"No Hair\", и значение \"Hairy\" во всех остальных случаях. Затем выберите только колонки name, Hair color, hair.\n\n\n\n# A tibble: 734 × 3\n   name          `Hair color` hair \n   <chr>         <chr>        <chr>\n 1 A-Bomb        No Hair      Bold \n 2 Abe Sapien    No Hair      Bold \n 3 Abin Sur      No Hair      Bold \n 4 Abomination   No Hair      Bold \n 5 Abraxas       Black        Hairy\n 6 Absorbing Man No Hair      Bold \n 7 Adam Monroe   Blond        Hairy\n 8 Adam Strange  Blond        Hairy\n 9 Agent 13      Blond        Hairy\n10 Agent Bob     Brown        Hairy\n# … with 724 more rows"
  },
  {
    "objectID": "910-tasks.html#sec-task_group_by",
    "href": "910-tasks.html#sec-task_group_by",
    "title": "25  Задания",
    "section": "25.20 Агрегация: dplyr::group_by() %>% summarise()",
    "text": "25.20 Агрегация: dplyr::group_by() %>% summarise()\n\nПосчитайте количество супергероев по расам и отсортируйте по убыванию. Извлеките первые 5 строк.\n\n\n\n# A tibble: 5 × 2\n  Race              n\n  <chr>         <int>\n1 <NA>            304\n2 Human           208\n3 Mutant           63\n4 God / Eternal    14\n5 Cyborg           11\n\n\n\nПосчитайте средний пост по полу.\n\n\n\n# A tibble: 3 × 2\n  Gender height_mean\n  <chr>        <dbl>\n1 Female        175.\n2 Male          192.\n3 <NA>          177."
  },
  {
    "objectID": "910-tasks.html#sec-task_join",
    "href": "910-tasks.html#sec-task_join",
    "title": "25  Задания",
    "section": "25.21 Соединение датафреймов: *_join",
    "text": "25.21 Соединение датафреймов: *_join\n\nСоздайте тиббл web_creators, в котором будут супергерои, которые могут плести паутину, т.е. у них стоит TRUE в колонке Web Creation в тиббле powers.\n\n\n\n# A tibble: 16 × 12\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1    33 Anti-Venom  Male   blue    Symb… Blond      229 Marvel… <NA>    <NA>   \n 2    38 Arachne     Female blue    Human Blond      175 Marvel… <NA>    good   \n 3   161 Carnage     Male   green   Symb… Red        185 Marvel… <NA>    bad    \n 4   335 Hybrid      Male   brown   Symb… Black      175 Marvel… <NA>    good   \n 5   479 Mysterio    Male   brown   Human No Hair    180 Marvel… <NA>    bad    \n 6   580 Scarlet Sp… Male   brown   Clone Brown      193 Marvel… <NA>    good   \n 7   597 Silk        Female brown   Human Black       NA Marvel… <NA>    good   \n 8   620 Spider-Girl Female blue    Human Brown      170 Marvel… <NA>    good   \n 9   621 Spider-Gwen Female blue    Human Blond      165 Marvel… <NA>    good   \n10   622 Spider-Man  Male   hazel   Human Brown      178 Marvel… <NA>    good   \n11   623 Spider-Man  <NA>   red     Human Brown      178 Marvel… <NA>    good   \n12   624 Spider-Man  Male   brown   Human Black      157 Marvel… <NA>    good   \n13   673 Toxin       Male   blue    Symb… Brown      188 Marvel… <NA>    good   \n14   674 Toxin       Male   black   Symb… Blond      191 Marvel… <NA>    good   \n15   689 Venom       Male   blue    Symb… Strawb…    191 Marvel… <NA>    bad    \n16   692 Venompool   Male   <NA>    Symb… <NA>       226 Marvel… <NA>    <NA>   \n# … with 2 more variables: Weight <dbl>, `Web Creation` <lgl>, and abbreviated\n#   variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`,\n#   ⁵​Alignment\n\n\n\nНайдите всех супергероев, которые присутствуют в heroes, но отсутствуют в powers. Ответом должен быть строковый вектор с именами супергероев.\n\n\n\n [1] \"Agent 13\"          \"Alfred Pennyworth\" \"Arsenal\"          \n [4] \"Batgirl III\"       \"Batgirl V\"         \"Beetle\"           \n [7] \"Black Goliath\"     \"Black Widow II\"    \"Blaquesmith\"      \n[10] \"Bolt\"              \"Boomer\"            \"Box\"              \n[13] \"Box III\"           \"Captain Mar-vell\"  \"Cat II\"           \n[16] \"Cecilia Reyes\"     \"Clea\"              \"Clock King\"       \n[19] \"Colin Wagner\"      \"Colossal Boy\"      \"Corsair\"          \n[22] \"Cypher\"            \"Danny Cooper\"      \"Darkside\"         \n[25] \"ERG-1\"             \"Fixer\"             \"Franklin Storm\"   \n[28] \"Giant-Man\"         \"Giant-Man II\"      \"Goliath\"          \n[31] \"Goliath\"           \"Goliath\"           \"Guardian\"         \n[34] \"Hawkwoman\"         \"Hawkwoman II\"      \"Hawkwoman III\"    \n[37] \"Howard the Duck\"   \"Jack Bauer\"        \"Jesse Quick\"      \n[40] \"Jessica Sanders\"   \"Jigsaw\"            \"Jyn Erso\"         \n[43] \"Kid Flash II\"      \"Kingpin\"           \"Meteorite\"        \n[46] \"Mister Zsasz\"      \"Mogo\"              \"Moloch\"           \n[49] \"Morph\"             \"Nite Owl II\"       \"Omega Red\"        \n[52] \"Paul Blart\"        \"Penance\"           \"Penance I\"        \n[55] \"Plastic Lad\"       \"Power Man\"         \"Renata Soliz\"     \n[58] \"Ronin\"             \"Shrinking Violet\"  \"Snake-Eyes\"       \n[61] \"Spider-Carnage\"    \"Spider-Woman II\"   \"Stacy X\"          \n[64] \"Thunderbird II\"    \"Two-Face\"          \"Vagabond\"         \n[67] \"Vision II\"         \"Vulcan\"            \"Warbird\"          \n[70] \"White Queen\"       \"Wiz Kid\"           \"Wondra\"           \n[73] \"Wyatt Wingfoot\"    \"Yellow Claw\"      \n\n\n\nНайдите всех супергероев, которые присутствуют в powers, но отсутствуют в heroes. Ответом должен быть строковый вектор с именами супергероев.\n\n\n\n [1] \"3-D Man\"           \"Bananaman\"         \"Bizarro-Girl\"     \n [4] \"Black Vulcan\"      \"Blue Streak\"       \"Bradley\"          \n [7] \"Clayface\"          \"Concrete\"          \"Dementor\"         \n[10] \"Doctor Poison\"     \"Fire\"              \"Hellgramite\"      \n[13] \"Lara Croft\"        \"Little Epic\"       \"Lord Voldemort\"   \n[16] \"Orion\"             \"Peek-a-Boo\"        \"Queen Hippolyta\"  \n[19] \"Reactron\"          \"SHDB\"              \"Stretch Armstrong\"\n[22] \"TEST\"              \"Tommy Clarke\"      \"Tyrant\""
  },
  {
    "objectID": "910-tasks.html#sec-task_pivot",
    "href": "910-tasks.html#sec-task_pivot",
    "title": "25  Задания",
    "section": "25.22 Tidy data",
    "text": "25.22 Tidy data\n\nДля начала создайте тиббл heroes_weight, скопировав код:\n\n\nheroes_weight <- heroes %>%\n  filter(Publisher %in% c(\"DC Comics\", \"Marvel Comics\")) %>%\n  group_by(Gender, Publisher) %>%\n  summarise(weight_mean = mean(Weight, na.rm = TRUE)) %>%\n  drop_na()\nheroes_weight \n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Publisher     weight_mean\n  <chr>  <chr>               <dbl>\n1 Female DC Comics            76.8\n2 Female Marvel Comics        80.1\n3 Male   DC Comics           113. \n4 Male   Marvel Comics       134. \n\n\n\nФункция drop_na() позволяет выбросить все строчки, в которых встречается NA.\n\n\nПревратите тиббл heroes_weight в широкий тиббл:\n\n\n\n# A tibble: 2 × 3\n# Groups:   Gender [2]\n  Gender `DC Comics` `Marvel Comics`\n  <chr>        <dbl>           <dbl>\n1 Female        76.8            80.1\n2 Male         113.            134. \n\n\n\nЗатем превратите его обратно в длинный тиббл:\n\n\n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Publisher     weight_mean\n  <chr>  <chr>               <dbl>\n1 Female DC Comics            76.8\n2 Female Marvel Comics        80.1\n3 Male   DC Comics           113. \n4 Male   Marvel Comics       134. \n\n\n\nСделайте powers длинным тибблом с тремя колонками: hero_names, power (названгие суперсилы) и has (наличие суперсилы у данного супергероя).\n\n\n\n# A tibble: 111,389 × 3\n   hero_names power                 has  \n   <chr>      <chr>                 <lgl>\n 1 3-D Man    Agility               TRUE \n 2 3-D Man    Accelerated Healing   FALSE\n 3 3-D Man    Lantern Power Ring    FALSE\n 4 3-D Man    Dimensional Awareness FALSE\n 5 3-D Man    Cold Resistance       FALSE\n 6 3-D Man    Durability            FALSE\n 7 3-D Man    Stealth               FALSE\n 8 3-D Man    Energy Absorption     FALSE\n 9 3-D Man    Flight                FALSE\n10 3-D Man    Danger Sense          FALSE\n# … with 111,379 more rows\n\n\n\nСделайте тиббл powers обратно широким, но с новой структурой: каждая строчка означает суперсилу, а каждая колонка - супергероя (за исключением первой колонки - названия суперсилы).\n\n\n\n# A tibble: 167 × 668\n   power 3-D M…¹ A-Bom…² Abe S…³ Abin …⁴ Abomi…⁵ Abraxas Absor…⁶ Adam …⁷ Adam …⁸\n   <chr> <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>  \n 1 Agil… TRUE    FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   FALSE   FALSE  \n 2 Acce… FALSE   TRUE    TRUE    FALSE   TRUE    FALSE   FALSE   TRUE    FALSE  \n 3 Lant… FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   FALSE  \n 4 Dime… FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE  \n 5 Cold… FALSE   FALSE   TRUE    FALSE   FALSE   FALSE   TRUE    FALSE   FALSE  \n 6 Dura… FALSE   TRUE    TRUE    FALSE   FALSE   FALSE   TRUE    FALSE   TRUE   \n 7 Stea… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE   \n 8 Ener… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE  \n 9 Flig… FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   TRUE   \n10 Dang… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE  \n# … with 157 more rows, 658 more variables: `Agent Bob` <lgl>,\n#   `Agent Zero` <lgl>, `Air-Walker` <lgl>, Ajax <lgl>, `Alan Scott` <lgl>,\n#   `Alex Mercer` <lgl>, `Alex Woolsly` <lgl>, Alien <lgl>,\n#   `Allan Quatermain` <lgl>, Amazo <lgl>, Ammo <lgl>, `Ando Masahashi` <lgl>,\n#   Angel <lgl>, `Angel Dust` <lgl>, `Angel Salvadore` <lgl>, Angela <lgl>,\n#   `Animal Man` <lgl>, Annihilus <lgl>, `Ant-Man` <lgl>, `Ant-Man II` <lgl>,\n#   `Anti-Monitor` <lgl>, `Anti-Spawn` <lgl>, `Anti-Venom` <lgl>, …"
  },
  {
    "objectID": "910-tasks.html#sec-task_across",
    "href": "910-tasks.html#sec-task_across",
    "title": "25  Задания",
    "section": "25.23 Операции с несколькими колонками: across()",
    "text": "25.23 Операции с несколькими колонками: across()\n\nПосчитайте количество NA в каждой колонке, группируя по полу (Gender).\n\n\n\n# A tibble: 3 × 11\n  Gender  ...1  name Eye c…¹  Race Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <chr>  <int> <int>   <int> <int>   <int>  <int>   <int>   <int>   <int>  <int>\n1 Female     0     0      41    98      38     56       0     186       0     58\n2 Male       0     0     121   184     123    147       0     449       6    166\n3 <NA>       0     0      10    22      11     14       0      27       1     15\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nПосчитайте количество NA в каждой колонке, которая заканчивается на \"color\", группируя по полу (Gender).\n\n\n\n# A tibble: 3 × 4\n  Gender `Eye color` `Hair color` `Skin color`\n  <chr>        <int>        <int>        <int>\n1 Female          41           38          186\n2 Male           121          123          449\n3 <NA>            10           11           27\n\n\n\nНайдите (первую) самую длинную строчку для каждой колонки с character типом данных, группируя по полу (Gender).\n\n\nДля расчета количества значений в строке есть функция nchar(), для расчета индекса (первого) максимального значения есть функция which.max().\n\n\n\n# A tibble: 3 × 8\n  Gender name                      Eye c…¹ Race  Hair …² Publi…³ Skin …⁴ Align…⁵\n  <chr>  <chr>                     <chr>   <chr> <chr>   <chr>   <chr>   <chr>  \n1 Female Negasonic Teenage Warhead yellow… Huma… Strawb… Dark H… orange  neutral\n2 Male   Drax the Destroyer        yellow… Dath… Strawb… Dark H… orange… neutral\n3 <NA>   Captain Universe          yellow… God … Orange… Marvel… grey    neutral\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nСоздайте из тиббла heroes новый тиббл, в котором числовые значения Height и Weight заменены на следующие строковые значения: если у супергероя рост или вес выше среднего по колонке, то \"выше среднего\", если его/ее рост или вес ниже или равен среднему, то \"ниже среднего\".\n\n\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>   <chr>  <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair выше … Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair выше … Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair ниже … DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair выше … Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black   <NA>   Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair выше … Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond   <NA>   NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond   ниже … DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond   ниже … Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown   ниже … Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <chr>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\nСоздайте из тиббла heroes новый тиббл, в котором числовые значения Height и Weight заменены на следующие строковые значения: если у супергероя внутри соответствующей группы по полу рост или вес выше среднего по колонке, то \"выше среднего по X\", если его/ее рост или вес ниже или равен среднему внутри соответствующей группы по полу, то \"ниже среднего по X\" , где X – соответствующий пол (Gender).\n\n\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>   <chr>  <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair выше … Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair ниже … Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair ниже … DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair выше … Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black   NA по… Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair выше … Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond   NA по… NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond   ниже … DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond   ниже … Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown   ниже … Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <chr>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "910-tasks.html#sec-desc_tasks",
    "href": "910-tasks.html#sec-desc_tasks",
    "title": "25  Задания",
    "section": "25.24 Описательная статистика",
    "text": "25.24 Описательная статистика\nДля выполнения задания создайте вектор height из колонки Height датасета heroes, удалив в нем NA.\n\nПосчитайте среднее в векторе height.\n\n\n\n[1] 186.7263\n\n\n\nПосчитайте усеченное среднее в векторе height с усечением 5% значений с обоих сторон.\n\n\n\n[1] 182.5846\n\n\n\nПосчитайте медиану в векторе height.\n\n\n\n[1] 183\n\n\n\nПосчитайте стандартное отклонение в векторе height.\n\n\n\n[1] 59.25189\n\n\n\nПосчитайте межквартильный размах в векторе height.\n\n\n\n[1] 18\n\n\n\nПосчитайте ассиметрию в векторе height.\n\n\n\n[1] 8.843432\n\n\nПосчитайте эксцесс в векторе height.\n\n\n[1] 105.0297\n\n\nПримените функции для получения множественных статистик на векторе height.\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   15.2   173.0   183.0   186.7   191.0   975.0 \n\n\n   vars   n   mean    sd median trimmed   mad  min max range skew kurtosis   se\nX1    1 517 186.73 59.25    183  182.02 11.86 15.2 975 959.8 8.84   105.03 2.61\n\n\n\nData summary\n\n\nName\nheight\n\n\nNumber of rows\n517\n\n\nNumber of columns\n1\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndata\n0\n1\n186.73\n59.25\n15.2\n173\n183\n191\n975\n▇▁▁▁▁"
  },
  {
    "objectID": "910-tasks.html#sec-ggplot2_tasks",
    "href": "910-tasks.html#sec-ggplot2_tasks",
    "title": "25  Задания",
    "section": "25.25 Построение графиков в ggplot2",
    "text": "25.25 Построение графиков в ggplot2\n\nНарисуйте столбиковую диаграмму (geom_bar()), которая будет отражать количество супергероев издателей \"Marvel Comics\", \"DC Comics\" и всех остальных (отдельным столбиком) из датасета heroes.\n\n\n\n\n\n\n\nДобавьте к этой диаграме заливку цветом (fill =) в зависимости от распределения Gender внутри каждой группы.\n\n\n\n\n\n\n\nСделайте так, чтобы каждый столбик был максимальной высоты (position = \"fill\").\n\n\n\n\n\n\n\nФинализируйте график, задав ему описания осей (например, функция labs()), использовав процентную шкалу (scale_y_continuous(labels = scales::percent)) и задав тему theme_minimal().\n\n\n\n\n\n\nСоздайте диаграмму рассеяния для датасета heroes, для которой координаты по оси x будут взяты из колонки Height, а координаты по оси y – из колонки Weight.\n\n\n\n\n\n\nУдалите с графика все экстремальные значения, для которых Weight больше или равен 700 или Height больше или равен 400. (Подсказка: это можно делать как средствами ggplot2, так и функцией filter() из dplyr).\n\n\n\n\n\n\n\nРаскрасьте точки в зависимости от Gender, сделайте их полупрозрачными ( параметр alpha =).\n\n\n\n\n\n\n\nСделайте так, чтобы координатная плоскость имела соотношение 1:1 шкал по оси x и y. Этого можно добиться с помощью функции coord_fixed().\n\n\n\n\n\n\nРазделите график (facet_wrap()) на три: для \"DC Comics\",\"Marvel Comics\" и всех остальных.\n\n\n\n\n\n\nИспользуйте для графика тему theme_linedraw().\n\n\n\n\n\n\n\n\nПостройте новый график (или возьмите старый) по датасетам heroes и/или powers и сделайте его некрасивым! Чем хуже у вас получится график, тем лучше. Желательно, чтобы этот график был по-прежнему графиком, а не произведением абстрактного искусства. Разница очень тонкая, но она есть.\n\n\nВот несколько подсказок для этого задания:\n\nДля вдохновения посмотрите на вот эти графики.\nДля реально плохих графиков вам придется покопаться с настройками темы. Посмотрите подсказку по темам ?theme, попытайтесь что-то поменять в теме.\nЭкспериментируйте с разными геомами и необычными их применениями.\nПо изучайте дополнения к gpplot2.\nПопробуйте подготовить интересные данные для этого графика."
  },
  {
    "objectID": "910-tasks.html#sec-dist_tasks",
    "href": "910-tasks.html#sec-dist_tasks",
    "title": "25  Задания",
    "section": "25.26 Распределения",
    "text": "25.26 Распределения\nВыберите любое непрерывное распределение из представленных в базовом пакете stats или же в любом другом пакете. Найти все распределения пакета stats можно с помощью ?Distributions. Подберите для него какие-нибудь параметры или используйте параметры по умолчанию.\n\nЯ возьму F-распределение с параметрами df1 = 4 и df = 10, но вы можете выбрать другое распределение.\n\n\nВизуализируйте функцию плотности вероятности для выбранного распределения.\n\n\n\n\n\n\n\nВизуализируйте функцию накопленной плотности распределения для выбранной функции.\n\n\n\n\n\n\n\nВизуализируйте квантильную функцию для выбранного распределения.\n\n\n\n\n\n\n\nСделайте выборку из 100 случайных значений из выбранного распределения и постройте гистограмму (функция hist()) для полученной выборки."
  },
  {
    "objectID": "910-tasks.html#sec-one_ttest_tasks",
    "href": "910-tasks.html#sec-one_ttest_tasks",
    "title": "25  Задания",
    "section": "25.27 Одновыборочный t-test",
    "text": "25.27 Одновыборочный t-test\n\nПредставьте, что наши супергерои из набора данных heroes – это выборка из генеральной совокупности всех написанных и ненаписанных супергероев. Проведите одновыборочный t-тест для веса супергероев и числа 100 – предположительного среднего веса в генеральной совокупности всех супергероев. Проинтерпретируйте результат.\nПроведите одновыборочный t-тест для роста супергероев и числа 185 – предположительного среднего роста в генеральной совокупности всех супергероев. Проинтерпретируйте результат."
  },
  {
    "objectID": "910-tasks.html#sec-dep_ttest_tasks",
    "href": "910-tasks.html#sec-dep_ttest_tasks",
    "title": "25  Задания",
    "section": "25.28 Двухвыборочный зависимый t-test",
    "text": "25.28 Двухвыборочный зависимый t-test\nДля дальнейших заданий понадобится набор данных о результативности трех диет, который мы использовали во время занятия.\n\ndiet <- readr::read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv\")\n\n\nПосчитайте двухвыборочный зависимый т-тест для остальных диет: для диеты 2 и диеты 3. Проинтерпретируйте полученные результаты."
  },
  {
    "objectID": "910-tasks.html#sec-ind_ttest_tasks",
    "href": "910-tasks.html#sec-ind_ttest_tasks",
    "title": "25  Задания",
    "section": "25.29 Двухвыборочный независимый t-test",
    "text": "25.29 Двухвыборочный независимый t-test\n\nСделайте независимый t-тест для сравнения веса испытуемых двух групп после диеты, сравнив вторую и третью группу. Проинтерпретируйте результаты.\nСделайте независимый t-тест для сравнения веса испытуемых двух групп после диеты, сравнив первую и третью группу. Проинтерпретируйте результаты."
  },
  {
    "objectID": "910-tasks.html#sec-nonparam_ttest_tasks",
    "href": "910-tasks.html#sec-nonparam_ttest_tasks",
    "title": "25  Задания",
    "section": "25.30 Непараметрические аналоги t-теста",
    "text": "25.30 Непараметрические аналоги t-теста\n\nСравните вес первой и второй группы после диеты, используя тест Манна-Уитни. Сравните результаты теста Манна-Уитни с результатами t-теста? Проинтерпретируйте полученные результаты.\nПовторите задание для второй и третьей группы, а так же для первой и третьей группы.\nСравните вес до и после для диеты 1, используя тест Уилкоксона. Сравните с результатами применения t-теста. Проинтерпретируйте полученные результаты.\nСравните вес до и после для диеты 2 и диеты 3, используя тест Уилкоксона. Сравните с результатами применения t-теста. Проинтерпретируйте полученные результаты."
  },
  {
    "objectID": "910-tasks.html#sec-chi_sq_tasks",
    "href": "910-tasks.html#sec-chi_sq_tasks",
    "title": "25  Задания",
    "section": "25.31 Критерий хи-квадрат Пирсона",
    "text": "25.31 Критерий хи-квадрат Пирсона\n\nСоздайте в heroes новую колонку is_human логического типа, в которой будет TRUE, если супергерой принадлежит расе (Race) \"Human\", и FALSE в случае если супергерой принадлежит другой расе.\nПосчитайте долю женщин для \"Human\" и всех остальных (is_human равен TRUE и FALSE соответственно). Перед этим удалите все строчки с NA в переменных is_human и Gender.\n\n\n\n# A tibble: 2 × 2\n  is_human `mean(Gender == \"Female\")`\n  <lgl>                         <dbl>\n1 FALSE                         0.241\n2 TRUE                          0.242\n\n\n\nСравните распределения частот для переменных is_human и Gender используя хи-квадрат Пирсона. Проинтерпретируйте результаты.\nПостройте мозаичный график для переменных is_human и Gender."
  },
  {
    "objectID": "910-tasks.html#sec-backpack_tasks",
    "href": "910-tasks.html#sec-backpack_tasks",
    "title": "25  Задания",
    "section": "25.32 Исследование набора данных Backpack",
    "text": "25.32 Исследование набора данных Backpack\nДля следующих тем нам понадобится набор данных Backpack из пакета Stat2Data.\n\n#install.packages(\"Stat2Data\")\nlibrary(Stat2Data)\ndata(Backpack)\nback <- Backpack %>%\n  mutate(backpack_kg = 0.45359237 * BackpackWeight,\n         body_kg = 0.45359237 * BodyWeight)\n\n\nКак различается вес рюкзака в зависимости от пола? Кто весит больше?\n\n\n\n# A tibble: 2 × 2\n  Sex    `mean(backpack_kg)`\n  <fct>                <dbl>\n1 Female                5.01\n2 Male                  5.63\n\n\n\nЕсли допустить, что выборка репрезентативна, то можно ли сделать вывод о различии по среднему весу рюкзаков в генеральной совокупности?\nПовторите пунктs 2 и 3 для веса самих студентов.\nВизуализируйте распределение этих двух переменных в зависимости от пола (используя ggplot2)\n\n\n\n\n\n\n\nПостройте диаграмму рассеяния с помощью ggplot2. Цветом закодируйте пол респондента."
  },
  {
    "objectID": "910-tasks.html#sec-cov_tasks",
    "href": "910-tasks.html#sec-cov_tasks",
    "title": "25  Задания",
    "section": "25.33 Ковариация",
    "text": "25.33 Ковариация\n\nПосчитайте матрицу ковариаций для веса студентов и их рюкзаков в фунтах. Различаются ли результаты подсчета ковариации этих двух переменных от результатов подсчета ковариаций веса студентов и их рюкзаков в килограммах? Почему?"
  },
  {
    "objectID": "910-tasks.html#sec-cor_tasks",
    "href": "910-tasks.html#sec-cor_tasks",
    "title": "25  Задания",
    "section": "25.34 Коэффициент корреляции",
    "text": "25.34 Коэффициент корреляции\n\nПосчитайте коэффициент корреляции Пирсона для веса студентов и их рюкзаков в фунтах. Различаются ли результаты подсчета коэффициента корреляции Пирсона (сам коэффициент, p-value) этих двух переменных от результатов подсчета корреляции Пирсона веса студентов и их рюкзаков в килограммах? Почему?\nПосчитайте коэффициент корреляции Пирсона для веса и роста супергероев из датасета heroes. Проинтерпретируйте результат.\nТеперь посчитайте коэффициент корреляции Спирмена и коэффициент корреляции Кэнделла для веса и роста супергероев из датасета heroes. Различаются ли результаты по сравнению с коэффициентом корреляции Пирсона? Почему?"
  },
  {
    "objectID": "920-solutions.html#sec-solution_begin",
    "href": "920-solutions.html#sec-solution_begin",
    "title": "26  Решения заданий",
    "section": "26.1 Начало работы в R",
    "text": "26.1 Начало работы в R\n\nРазделите 9801 на 9.\n\n\n9801/9\n\n[1] 1089\n\n\n\nПосчитайте логарифм от 2176782336 по основанию 6.\n\n\nlog(2176782336, 6)\n\n[1] 12\n\n\n\nТеперь натуральный логарифм 10 и умножьте его на 5.\n\n\nlog(10)*5\n\n[1] 11.51293\n\n\n\nС помощью функции sin() посчитайте \\(\\sin (\\pi), \\sin \\left(\\frac{\\pi}{2}\\right), \\sin \\left(\\frac{\\pi}{6}\\right)\\).\n\n\nЗначение \\(\\pi\\) - зашитая в R константа (pi).\n\n\nsin(pi)\n\n[1] 1.224647e-16\n\nsin(pi/2)\n\n[1] 1\n\nsin(pi/6)\n\n[1] 0.5"
  },
  {
    "objectID": "920-solutions.html#sec-solution_new_vecs",
    "href": "920-solutions.html#sec-solution_new_vecs",
    "title": "26  Решения заданий",
    "section": "26.2 Создание векторов",
    "text": "26.2 Создание векторов\n\nСоздайте вектор из значений 2, 30 и 4000.\n\n\nc(2, 30, 4000)\n\n[1]    2   30 4000\n\n\n\nСоздайте вектор от 1 до 20.\n\n\n1:20\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nСоздайте вектор от 20 до 1.\n\n\n20:1\n\n [1] 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1\n\n\nФункция sum() возвращает сумму элементов вектора на входе. Посчитайте сумму первых 100 натуральных чисел (т.е. всех целых чисел от 1 до 100).\n\nsum(1:100)\n\n[1] 5050\n\n\n\nСоздайте вектор от 1 до 20 и снова до 1. Число 20 должно присутствовать только один раз!\n\n\nc(1:20, 19:1)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 19 18 17 16 15\n[26] 14 13 12 11 10  9  8  7  6  5  4  3  2  1\n\n\n\nСоздайте вектор значений 5, 4, 3, 2, 2, 3, 4, 5:\n\n\nc(5:2, 2:5)\n\n[1] 5 4 3 2 2 3 4 5\n\n\n\nСоздайте вектор 2, 4, 6, … , 18, 20.\n\n\nseq(2, 20, 2)\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\n\nСоздайте вектор 0.1, 0.2, 0.3, …, 0.9, 1.\n\n\nseq(0.1, 1, 0.1)\n\n [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n2020 год — високосный. Следующий високосный год через 4 года — это будет 2024 год. Составьте календарь всех високосных годов XXI века, начиная с 2020 года.\n\n\n2100 год относится к XXI веку, а не к XXII.\n\n\nseq(2020, 2100, 4)\n\n [1] 2020 2024 2028 2032 2036 2040 2044 2048 2052 2056 2060 2064 2068 2072 2076\n[16] 2080 2084 2088 2092 2096 2100\n\n\n\nСоздайте вектор, состоящий из 20 повторений “Хэй!”.\n\n\nrep(\"Хэй!\", 20)\n\n [1] \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\"\n[11] \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\" \"Хэй!\"\n\n\n\nКак я и говорил, многие функции, работающие с одним значением на входе, так же прекрасно работают и с целыми векторами. Попробуйте посчитать квадратный корень чисел от 1 до 10 с помощью функции sqrt() и сохраните результат в векторе roots. Выведите содержание вектора roots в консоль.\n\n\nroots <- sqrt(1:10)\nroots\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\n\n\n*Создайте вектор из одной единицы, двух двоек, трех троек, …. , девяти девяток.\n\n\nrep(1:9, 1:9)\n\n [1] 1 2 2 3 3 3 4 4 4 4 5 5 5 5 5 6 6 6 6 6 6 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 9 9\n[39] 9 9 9 9 9 9 9"
  },
  {
    "objectID": "920-solutions.html#sec-solution_coer",
    "href": "920-solutions.html#sec-solution_coer",
    "title": "26  Решения заданий",
    "section": "26.3 Приведение типов",
    "text": "26.3 Приведение типов\n\nСделайте вектор vec1, в котором соедините 3, а также значения \"Мой\" и \"вектор\".\n\n\nvec1 <- c(3, \"Мой\", \"вектор\")\nvec1\n\n[1] \"3\"      \"Мой\"    \"вектор\"\n\n\n\nПопробуйте вычесть TRUE из 10.\n\n\n10 - TRUE\n\n[1] 9\n\n\n\nСоедините значение 10 и TRUE в вектор vec2.\n\n\nvec2 <- c(10, TRUE)\nvec2\n\n[1] 10  1\n\n\n\nСоедините вектор vec2 и значение \"r\":\n\n\nc(vec2, \"r\")\n\n[1] \"10\" \"1\"  \"r\" \n\n\n\nСоедините значения 10, TRUE, \"r\" в вектор.\n\n\nc(10, TRUE, \"r\")\n\n[1] \"10\"   \"TRUE\" \"r\""
  },
  {
    "objectID": "920-solutions.html#sec-solution_vec_ion",
    "href": "920-solutions.html#sec-solution_vec_ion",
    "title": "26  Решения заданий",
    "section": "26.4 Векторизация",
    "text": "26.4 Векторизация\n\nСоздайте вектор p, состоящий из значений 4, 5, 6, 7, и вектор q, состоящий из 0, 1, 2, 3.\n\n\np <- 4:7\np\n\n[1] 4 5 6 7\n\nq <- 0:3\nq\n\n[1] 0 1 2 3\n\n\n\nПосчитайте поэлементную сумму векторов p и q:\n\n\np + q\n\n[1]  4  6  8 10\n\n\n\nПосчитайте поэлементную разницу p и q:\n\n\np - q\n\n[1] 4 4 4 4\n\n\n\nПоделите каждый элемент вектора p на соответствующий ему элемент вектора q:\n\n\nО, да, Вам нужно делить на 0!\n\n\np / q\n\n[1]      Inf 5.000000 3.000000 2.333333\n\n\n\nВозведите каждый элемент вектора p в степень соответствующего ему элемента вектора q:\n\n\np ^ q\n\n[1]   1   5  36 343\n\n\n\nУмножьте каждое значение вектора p на 10.\n\n\np * 10\n\n[1] 40 50 60 70\n\n\n\nСоздайте вектор квадратов чисел от 1 до 10:\n\n\n(1:10)^2\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\nСоздайте вектор 0, 2, 0, 4, … , 18, 0, 20.\n\n\n1:20 * 0:1\n\n [1]  0  2  0  4  0  6  0  8  0 10  0 12  0 14  0 16  0 18  0 20\n\n\n\nСоздайте вектор 1, 0, 3, 0, 5, …, 17, 0, 19, 0.\n\n\n1:20 * 1:0\n\n [1]  1  0  3  0  5  0  7  0  9  0 11  0 13  0 15  0 17  0 19  0\n\n\n\n*Создайте вектор, в котором будут содержаться первые 20 степеней двойки.\n\n\n2 ^ (1:20)\n\n [1]       2       4       8      16      32      64     128     256     512\n[10]    1024    2048    4096    8192   16384   32768   65536  131072  262144\n[19]  524288 1048576\n\n\n\n*Создайте вектор из чисел 1, 10, 100, 1000, 10000:\n\n\n10 ^ (0:4)\n\n[1]     1    10   100  1000 10000\n\n\n\n*Посчитать сумму последовательности \\(\\frac{1}{1 \\cdot 2}+\\frac{1}{2 \\cdot 3}+\\frac{1}{3 \\cdot 4}+\\ldots+\\frac{1}{50 \\cdot 51}\\).\n\n\nsum(1 / (1:50 * 2:51))\n\n[1] 0.9803922\n\n\n\n*Посчитать сумму последовательности \\(\\frac{1}{2^{0}}+\\frac{1}{2^{1}}+\\frac{1}{2^{2}}+\\frac{1}{2^{3}}+\\ldots \\frac{1}{2^{20}}\\).\n\n\nsum(1 / 2 ^ (0:20))\n\n[1] 1.999999\n\n\n\n*Посчитать сумму последовательности \\(1+\\frac{4}{3}+\\frac{7}{9}+\\frac{10}{27}+\\frac{13}{81}+\\ldots+\\frac{28}{19683}\\).\n\n\nsum((3 * (1:10) - 2) / 3 ^ (0:9))\n\n[1] 3.749174\n\n\n\n*Сколько чисел из последовательности \\(1+\\frac{4}{3}+\\frac{7}{9}+\\frac{10}{27}+\\frac{13}{81}+\\ldots+\\frac{28}{19683}\\) больше чем 0.5?\n\n\nsum((3 * (1:10) - 2) / 3 ^ (0:9) > 0.5)\n\n[1] 3"
  },
  {
    "objectID": "920-solutions.html#sec-solution_vec_ind",
    "href": "920-solutions.html#sec-solution_vec_ind",
    "title": "26  Решения заданий",
    "section": "26.5 Индексирование векторов",
    "text": "26.5 Индексирование векторов\n\nСоздайте вектор troiki со значениями 3, 6, 9, …, 24, 27.\n\n\ntroiki <- seq(3, 27, 3)\ntroiki\n\n[1]  3  6  9 12 15 18 21 24 27\n\n\n\nИзвлеките 2, 5 и 7 значения вектора troiki.\n\n\ntroiki[c(2, 5, 7)]\n\n[1]  6 15 21\n\n\n\nИзвлеките предпоследнее значение вектора troiki.\n\n\ntroiki[length(troiki) - 1]\n\n[1] 24\n\n\n\nИзвлеките все значения вектора troiki кроме предпоследнего:\n\n\ntroiki[-(length(troiki) - 1)]\n\n[1]  3  6  9 12 15 18 21 27\n\n\nСоздайте вектор vec3, скопировав следующий код:\n\nvec3 <- c(3, 5, 2, 1, 8, 4, 9, 10, 3, 15, 1, 11)\n\n\nНайдите второй элемент вектора vec3.\n\n\nvec3[2]\n\n[1] 5\n\n\n\nВерните второй и пятый элемент вектора vec3.\n\n\nvec3[c(2, 5)]\n\n[1] 5 8\n\n\n\nПопробуйте извлечь сотое значение вектора vec3:\n\n\nvec3[100]\n\n[1] NA\n\n\n\nВерните все элементы вектора vec3 кроме второго элемента.\n\n\nvec3[-2]\n\n [1]  3  2  1  8  4  9 10  3 15  1 11\n\n\n\nВерните все элементы вектора vec3 кроме второго и пятого элемента.\n\n\nvec3[c(-2, -5)]\n\n [1]  3  2  1  4  9 10  3 15  1 11\n\n\n\nНайдите последний элемент вектора vec3.\n\n\nvec3[length(vec3)]\n\n[1] 11\n\n\n\nВерните все значения вектора vec3 кроме первого и последнего.\n\n\nvec3[c(-1, -length(vec3))]\n\n [1]  5  2  1  8  4  9 10  3 15  1\n\n\n\nНайдите все значения вектора vec3, которые больше 4.\n\n\nvec3[vec3 > 4]\n\n[1]  5  8  9 10 15 11\n\n\n\nНайдите все значения вектора vec3, которые больше 4, но меньше 10.\n\n\nЕсли хотите сделать это в одну строчку, то вам помогут логические операторы!\n\n\nvec3[vec3 > 4 & vec3 < 10]\n\n[1] 5 8 9\n\n\n\nНайдите все значения вектора vec3, которые меньше 4 или больше 10.\n\n\nvec3[vec3 < 4 | vec3 > 10]\n\n[1]  3  2  1  3 15  1 11\n\n\n\nВозведите в квадрат каждое значение вектора vec3.\n\n\nvec3 ^ 2\n\n [1]   9  25   4   1  64  16  81 100   9 225   1 121\n\n\n\n*Возведите в квадрат каждое значение вектора на нечетной позиции и извлеките корень из каждого значения на четной позиции вектора vec3.\n\n\nИзвлечение корня - это то же самое, что и возведение в степень 0.5.\n\n\nvec3 ^ c(2, 0.5)\n\n [1]  9.000000  2.236068  4.000000  1.000000 64.000000  2.000000 81.000000\n [8]  3.162278  9.000000  3.872983  1.000000  3.316625\n\n\n\nСоздайте вектор 2, 4, 6, … , 18, 20 как минимум 2 новыми способами.\n\n\nЗнаю, это задание может показаться бессмысленным, но это очень базовая операция, с помощью которой можно, например, разделить данные на две части. Чем больше способов Вы знаете, тем лучше!\n\n\n(1:20)[c(FALSE,TRUE)]\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n#(1:10)*2"
  },
  {
    "objectID": "920-solutions.html#sec-solution_na",
    "href": "920-solutions.html#sec-solution_na",
    "title": "26  Решения заданий",
    "section": "26.6 Работа с пропущенными значениями",
    "text": "26.6 Работа с пропущенными значениями\n\nСоздайте вектор vec4 со значениями 300, 15, 8, 2, 0, 1, 110, скопировав следующий код:\n\n\nvec4 <- c(300, 15, 8, 20, 0, 1, 110)\nvec4\n\n[1] 300  15   8  20   0   1 110\n\n\n\nЗамените все значения vec4, которые больше 20 на NA.\n\n\nvec4[vec4 > 20] <- NA\n\n\nПроверьте полученный вектор vec4:\n\n\nvec4\n\n[1] NA 15  8 20  0  1 NA\n\n\n\nПосчитайте сумму vec4 с помощью функции sum(). Ответ NA не считается!\n\n\nsum(vec4, na.rm = TRUE)\n\n[1] 44"
  },
  {
    "objectID": "920-solutions.html#sec-solution_matrix",
    "href": "920-solutions.html#sec-solution_matrix",
    "title": "26  Решения заданий",
    "section": "26.7 Матрицы",
    "text": "26.7 Матрицы\n\nСоздайте матрицу 4х4, состоящую из единиц. Назовите ее M1.\n\n\nM1 <- matrix(rep(1, 16), ncol = 4)\nM1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    1    1    1\n[2,]    1    1    1    1\n[3,]    1    1    1    1\n[4,]    1    1    1    1\n\n\n\nПоменяйте все некрайние значения матрицы M1 (то есть значения на позициях [2,2], [2,3], [3,2] и [3,3]) на число 2.\n\n\nM1[2:3, 2:3] <- 2\nM1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    1    1    1\n[2,]    1    2    2    1\n[3,]    1    2    2    1\n[4,]    1    1    1    1\n\n\n\nВыделите второй и третий столбик из матрицы M1.\n\n\nM1[,2:3]\n\n     [,1] [,2]\n[1,]    1    1\n[2,]    2    2\n[3,]    2    2\n[4,]    1    1\n\n\n\nСравните (==) вторую колонку и вторую строчку матрицы M1.\n\n\nM1[,2] == M1[2,]\n\n[1] TRUE TRUE TRUE TRUE\n\n\n\n*Создайте таблицу умножения (9х9) в виде матрицы. Сохраните ее в переменную mult_tab.\n\n\nmult_tab <- matrix(rep(1:9, rep(9,9))*(1:9), nrow = 9)\nmult_tab\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n [1,]    1    2    3    4    5    6    7    8    9\n [2,]    2    4    6    8   10   12   14   16   18\n [3,]    3    6    9   12   15   18   21   24   27\n [4,]    4    8   12   16   20   24   28   32   36\n [5,]    5   10   15   20   25   30   35   40   45\n [6,]    6   12   18   24   30   36   42   48   54\n [7,]    7   14   21   28   35   42   49   56   63\n [8,]    8   16   24   32   40   48   56   64   72\n [9,]    9   18   27   36   45   54   63   72   81\n\n#Еще\n#outer(1:9, 1:9, \"*\")\n#1:9 %o% 1:9\n\n\n*Из матрицы mult_tab выделите подматрицу, включающую в себя только строчки с 6 по 8 и столбцы с 3 по 7.\n\n\nmult_tab[6:8, 3:7]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   18   24   30   36   42\n[2,]   21   28   35   42   49\n[3,]   24   32   40   48   56\n\n\n\n*Создайте матрицу с логическими значениями, где TRUE, если в этом месте в таблице умножения (mult_tab) двузначное число и FALSE, если однозначное.\n\n\nМатрица - это почти вектор. К нему можно обращаться с единственным индексом.\n\n\nmult_tab >= 10\n\n       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]\n [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [2,] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [3,] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [4,] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [5,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [6,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [7,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [8,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [9,] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\n*Создайте матрицу mult_tab2, в которой все значения tab меньше 10 заменены на 0.\n\n\nmult_tab2 <- mult_tab\nmult_tab2[mult_tab < 10] <- 0\nmult_tab2\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n [1,]    0    0    0    0    0    0    0    0    0\n [2,]    0    0    0    0   10   12   14   16   18\n [3,]    0    0    0   12   15   18   21   24   27\n [4,]    0    0   12   16   20   24   28   32   36\n [5,]    0   10   15   20   25   30   35   40   45\n [6,]    0   12   18   24   30   36   42   48   54\n [7,]    0   14   21   28   35   42   49   56   63\n [8,]    0   16   24   32   40   48   56   64   72\n [9,]    0   18   27   36   45   54   63   72   81"
  },
  {
    "objectID": "920-solutions.html#sec-solution_list",
    "href": "920-solutions.html#sec-solution_list",
    "title": "26  Решения заданий",
    "section": "26.8 Списки",
    "text": "26.8 Списки\nДан список list1:\n\nlist1 = list(numbers = 1:5, letters = letters, logic = TRUE)\nlist1\n\n$numbers\n[1] 1 2 3 4 5\n\n$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$logic\n[1] TRUE\n\n\n\nНайдите первый элемент списка list1. Ответ должен быть списком длиной один.\n\n\nlist1[1]\n\n$numbers\n[1] 1 2 3 4 5\n\n\n\nТеперь найдите содержание первого элемента списка list1 двумя разными способами. Ответ должен быть вектором.\n\n\nlist1[[1]]\n\n[1] 1 2 3 4 5\n\nlist1$numbers\n\n[1] 1 2 3 4 5\n\n\n\nТеперь возьмите первый элемент содержания первого элемента списка list1. Ответ должен быть вектором.\n\n\nlist1[[1]][1]\n\n[1] 1\n\n\n\nСоздайте список list2, содержащий в себе два списка list1. Один из них будет иметь имя pupa, а другой — lupa.\n\n\nlist2 = list(pupa = list1, lupa = list1)\nlist2\n\n$pupa\n$pupa$numbers\n[1] 1 2 3 4 5\n\n$pupa$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$pupa$logic\n[1] TRUE\n\n\n$lupa\n$lupa$numbers\n[1] 1 2 3 4 5\n\n$lupa$letters\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$lupa$logic\n[1] TRUE\n\n\n\n*Извлеките первый элемент списка list2, из него — второй подэлемент, а из него — третье значение.\n\n\nlist2[[1]][[2]][3]\n\n[1] \"c\""
  },
  {
    "objectID": "920-solutions.html#sec-solution_df",
    "href": "920-solutions.html#sec-solution_df",
    "title": "26  Решения заданий",
    "section": "26.9 Датафрейм",
    "text": "26.9 Датафрейм\n\nЗапустите команду data(mtcars) чтобы загрузить встроенный датафрейм с информацией про автомобили. Каждая строчка датафрейма - модель автомобиля, каждая колонка - отдельная характеристика. Подробнее см. ?mtcars.\n\n\ndata(mtcars)\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nИзучите структуру датафрейма mtcars с помощью функции str().\n\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\nНайдите значение третьей строчки четвертого столбца датафрейма mtcars.\n\n\nmtcars[3, 4]\n\n[1] 93\n\n\n\nИзвлеките первые шесть строчек и первые шесть столбцов датафрейма mtcars.\n\n\nmtcars[1:6, 1:6]\n\n                   mpg cyl disp  hp drat    wt\nMazda RX4         21.0   6  160 110 3.90 2.620\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875\nDatsun 710        22.8   4  108  93 3.85 2.320\nHornet 4 Drive    21.4   6  258 110 3.08 3.215\nHornet Sportabout 18.7   8  360 175 3.15 3.440\nValiant           18.1   6  225 105 2.76 3.460\n\n\n\nИзвлеките колонку wt датафрейма mtcars - массу автомобиля в тысячах фунтов.\n\n\nmtcars$wt\n\n [1] 2.620 2.875 2.320 3.215 3.440 3.460 3.570 3.190 3.150 3.440 3.440 4.070\n[13] 3.730 3.780 5.250 5.424 5.345 2.200 1.615 1.835 2.465 3.520 3.435 3.840\n[25] 3.845 1.935 2.140 1.513 3.170 2.770 3.570 2.780\n\n\n\nИзвлеките колонки из mtcars в следующем порядке: hp, mpg, cyl.\n\n\nmtcars[, c(\"hp\", \"mpg\", \"cyl\")]\n\n                     hp  mpg cyl\nMazda RX4           110 21.0   6\nMazda RX4 Wag       110 21.0   6\nDatsun 710           93 22.8   4\nHornet 4 Drive      110 21.4   6\nHornet Sportabout   175 18.7   8\nValiant             105 18.1   6\nDuster 360          245 14.3   8\nMerc 240D            62 24.4   4\nMerc 230             95 22.8   4\nMerc 280            123 19.2   6\nMerc 280C           123 17.8   6\nMerc 450SE          180 16.4   8\nMerc 450SL          180 17.3   8\nMerc 450SLC         180 15.2   8\nCadillac Fleetwood  205 10.4   8\nLincoln Continental 215 10.4   8\nChrysler Imperial   230 14.7   8\nFiat 128             66 32.4   4\nHonda Civic          52 30.4   4\nToyota Corolla       65 33.9   4\nToyota Corona        97 21.5   4\nDodge Challenger    150 15.5   8\nAMC Javelin         150 15.2   8\nCamaro Z28          245 13.3   8\nPontiac Firebird    175 19.2   8\nFiat X1-9            66 27.3   4\nPorsche 914-2        91 26.0   4\nLotus Europa        113 30.4   4\nFord Pantera L      264 15.8   8\nFerrari Dino        175 19.7   6\nMaserati Bora       335 15.0   8\nVolvo 142E          109 21.4   4\n\n\n\nПосчитайте количество автомобилей с 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\nsum(mtcars$cyl == 4)\n\n[1] 11\n\n\n\nПосчитайте долю автомобилей с 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\nmean(mtcars$cyl == 4)\n\n[1] 0.34375\n\n\n\nНайдите все автомобили мощностью не менее 100 лошадиных сил (hp) в датафрейме mtcars.\n\n\nmtcars[mtcars$hp >= 100, ]\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nНайдите все автомобили мощностью не менее 100 лошадиных сил (hp) и 4 цилиндрами (cyl) в датафрейме mtcars.\n\n\nmtcars[mtcars$hp >= 100 & mtcars$cyl == 4, ]\n\n              mpg cyl  disp  hp drat    wt qsec vs am gear carb\nLotus Europa 30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nVolvo 142E   21.4   4 121.0 109 4.11 2.780 18.6  1  1    4    2\n\n\n\nПосчитайте максимальную массу (wt) автомобиля в выборке, воспользовавшись функцией max():\n\n\nmax(mtcars$wt)\n\n[1] 5.424\n\n\n\nПосчитайте минимальную массу (wt) автомобиля в выборке, воспользовавшись функцией min():\n\n\nmin(mtcars$wt)\n\n[1] 1.513\n\n\n\nНайдите строчку датафрейма mtcars с самым легким автомобилем.\n\n\nmtcars[mtcars$wt == min(mtcars$wt), ]\n\n              mpg cyl disp  hp drat    wt qsec vs am gear carb\nLotus Europa 30.4   4 95.1 113 3.77 1.513 16.9  1  1    5    2\n\n\n\nИзвлеките строчки датафрейма mtcars с автомобилями, масса которых ниже средней массы.\n\n\nmtcars[mtcars$wt < mean(mtcars$wt), ]\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nМасса автомобиля указана в тысячах фунтов. Создайте колонку wt_kg с массой автомобиля в килограммах. Результат округлите до целых значений с помощью функции round().\n\n\n1 фунт = 0.45359237 кг.\n\n\nmtcars$wt_kg <- round(mtcars$wt * 1000 * 0.45359237)\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb wt_kg\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  1188\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  1304\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1  1052\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  1458\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  1560\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  1569\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  1619\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  1447\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  1429\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  1560\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  1560\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  1846\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  1692\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  1715\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  2381\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  2460\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  2424\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1   998\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2   733\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1   832\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  1118\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  1597\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  1558\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  1742\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  1744\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1   878\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2   971\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2   686\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  1438\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  1256\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  1619\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  1261"
  },
  {
    "objectID": "920-solutions.html#sec-solution_if",
    "href": "920-solutions.html#sec-solution_if",
    "title": "26  Решения заданий",
    "section": "26.10 Условные конструкции",
    "text": "26.10 Условные конструкции\n\nСоздайте вектор vec5, скопировав следующий код:\n\n\nvec5 <- c(5, 20, 30, 0, 2, 9)\n\n\nСоздайте новый строковый вектор, где на месте чисел больше 10 в vec5 будет стоять “большое число”, а на месте остальных чисел – “маленькое число”.\n\n\nifelse(vec5 > 10, \"большое число\", \"маленькое число\")\n\n[1] \"маленькое число\" \"большое число\"   \"большое число\"   \"маленькое число\"\n[5] \"маленькое число\" \"маленькое число\"\n\n\n\nЗагрузите файл heroes_information.csv в переменную heroes.\n\n\nheroes <- read.csv(\"data/heroes_information.csv\", \n                   stringsAsFactors = FALSE,\n                   na.strings = c(\"-\", \"-99\"))\n\n\nСоздайте новою колонку hair в heroes, в которой будет значение \"Bold\" для тех супергероев, у которых в колонке Hair.color стоит \"No Hair\", и значение \"Hairy\" во всех остальных случаях.\n\n\nheroes$hair <- ifelse(heroes$Hair.color == \"No Hair\", \"Bold\", \"Hairy\")\nhead(heroes)\n\n  X          name Gender Eye.color              Race Hair.color Height\n1 0        A-Bomb   Male    yellow             Human    No Hair    203\n2 1    Abe Sapien   Male      blue     Icthyo Sapien    No Hair    191\n3 2      Abin Sur   Male      blue           Ungaran    No Hair    185\n4 3   Abomination   Male     green Human / Radiation    No Hair    203\n5 4       Abraxas   Male      blue     Cosmic Entity      Black     NA\n6 5 Absorbing Man   Male      blue             Human    No Hair    193\n          Publisher Skin.color Alignment Weight  hair\n1     Marvel Comics       <NA>      good    441  Bold\n2 Dark Horse Comics       blue      good     65  Bold\n3         DC Comics        red      good     90  Bold\n4     Marvel Comics       <NA>       bad    441  Bold\n5     Marvel Comics       <NA>       bad     NA Hairy\n6     Marvel Comics       <NA>       bad    122  Bold\n\n\n\nСоздайте новою колонку tall в heroes, в которой будет значение \"tall\" для тех супергероев, у которых в колонке Height стоит число больше 190, значение \"short\" для тех супергероев, у которых в колонке Height стоит число меньше 170, и значение \"middle\" во всех остальных случаях.\n\n\n# heroes$tall <- dplyr::case_when(\n#   heroes$Height > 190 ~ \"tall\",\n#   heroes$Height < 170 ~ \"short\",\n#   TRUE ~ \"middle\"\n# )\nheroes$tall <- ifelse(heroes$Height > 190, \n                      \"tall\",\n                      ifelse(heroes$Height < 170,\n                             \"short\",\n                             \"middle\"))"
  },
  {
    "objectID": "920-solutions.html#sec-solution_function",
    "href": "920-solutions.html#sec-solution_function",
    "title": "26  Решения заданий",
    "section": "26.11 Создание функций",
    "text": "26.11 Создание функций\n\nСоздайте функцию plus_one(), которая принимает число и возвращает это же число + 1.\n\n\nplus_one <- function(x) x + 1\n\n\nПроверьте функцию plus_one() на числе 41.\n\n\nplus_one(41)\n\n[1] 42\n\n\n\nСоздайте функцию circle_area(), которая вычисляет площадь круга по радиусу согласно формуле \\(\\pi r^2\\).\n\n\ncircle_area <- function(r) pi * r ^ 2\n\n\nПосчитайте площадь круга с радиусом 5.\n\n\ncircle_area(5)\n\n[1] 78.53982\n\n\n\nСоздайте функцию cels2fahr(), которая будет превращать градусы по Цельсию в градусы по Фаренгейту.\n\n\ncels2fahr <- function(x) x * 9 / 5 + 32\n\n\nПроверьте на значениях -100, -40 и 0, что функция cels2fahr() работает корректно.\n\n\ncels2fahr(c(-100, -40, 0))\n\n[1] -148  -40   32\n\n\n\nНапишите функцию highlight(), которая принимает на входе строковый вектор, а возвращает тот же вектор, но дополненный значением \"***\" в начале и конце вектора. Лучше всего это рассмотреть на примере:\n\n\nhighlight <- function(x) c(\"***\", x, \"***\")\n\n\nhighlight(c(\"Я\", \"Бэтмен!\"))\n\n[1] \"***\"     \"Я\"       \"Бэтмен!\" \"***\"    \n\n\n\nТеперь сделайте функцию highlight более гибкой. Добавьте в нее параметр wrapper =, который по умолчанию равен \"***\". Значение параметра wrapper = и будет вставлено в начало и конец вектора.\n\n\nhighlight <- function(x, wrapper = \"***\") c(wrapper, x, wrapper)\n\n\nПроверьте написанную функцию на векторе c(\"Я\", \"Бэтмен!\").\n\n\nhighlight(c(\"Я\", \"Бэтмен!\")) \n\n[1] \"***\"     \"Я\"       \"Бэтмен!\" \"***\"    \n\nhighlight(c(\"Я\", \"Бэтмен!\"), wrapper = \"__\") \n\n[1] \"__\"      \"Я\"       \"Бэтмен!\" \"__\"     \n\n\n\nСоздайте функцию na_n(), которая будет возвращать количество NA в векторе.\n\n\nna_n <- function(x) sum(is.na(x))\n\n\nПроверьте функцию na_n() на векторе:\n\n\nna_n(c(NA, 3:5, NA, 2, NA))\n\n[1] 3\n\n\n\nНапишите функцию factors(), которая будет возвращать все делители числа в виде числового вектора.\n\n\nЗдесь может понадобиться оператор для получения остатка от деления: %%.\n\n\nfactors <- function(x) (1:x)[x %% (1:x) == 0]\n\n\nПроверьте функцию factors() на простых и сложных числах:\n\n\nfactors(3)\n\n[1] 1 3\n\nfactors(161)\n\n[1]   1   7  23 161\n\nfactors(1984)\n\n [1]    1    2    4    8   16   31   32   62   64  124  248  496  992 1984\n\n\n\n*Напишите функцию is_prime(), которая проверяет, является ли число простым.\n\n\nЗдесь может пригодиться функция any() - она возвращает TRUE, если в векторе есть хотя бы один TRUE.\n\n\nis_prime <- function(x) !any(x%%(2:(x-1)) == 0)\n#is_prime <- function(x) length(factors(x)) == 2 #Используя уже написанную функцию factors()\n\n\nПроверьте какие года были для нас простыми, а какие нет:\n\n\nis_prime(2017)\n\n[1] TRUE\n\nis_prime(2019)\n\n[1] FALSE\n\n2019/3 #2019 делится на 3 без остатка\n\n[1] 673\n\nis_prime(2020)\n\n[1] FALSE\n\nis_prime(2021)\n\n[1] FALSE\n\n\n\n*Создайте функцию monotonic(), которая возвращает TRUE, если значения в векторе не убывают (то есть каждое следующее - больше или равно предыдущему) или не возврастают.\n\n\nПолезная функция для этого — diff() — возвращает разницу соседних значений.\n\n\nmonotonic <- function(x) all(diff(x)>=0) | all(diff(x)<=0)\n\n\nmonotonic(1:7)\n\n[1] TRUE\n\nmonotonic(c(1:5,5:1))\n\n[1] FALSE\n\nmonotonic(6:-1)\n\n[1] TRUE\n\nmonotonic(c(1:5, rep(5, 10), 5:10))\n\n[1] TRUE\n\n\nБинарные операторы типа + или %in% тоже представляют собой функции. Более того, мы можем создавать свои бинарные операторы! В этом нет особой сложности — нужно все так же создавать функцию (для двух переменных), главное окружать их % и название обрамлять обратными штрихами `. Например, можно сделать свой бинарный оператор %notin%, который будет выдавать TRUE, если значения слева нет в векторе справа:\n\n`%notin%` <- function(x, y) ! (x %in% y)\n1:10 %notin% c(1, 4, 5)\n\n [1] FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\n*Создайте бинарный оператор %without%, который будет возвращать все значения вектора слева без значений вектора справа.\n\n\n`%without%` <- function(x, y) x[!x %in% y]\n\n\nc(\"а\", \"и\", \"б\", \"сидели\", \"на\", \"трубе\") %without% c(\"а\", \"б\")\n\n[1] \"и\"      \"сидели\" \"на\"     \"трубе\" \n\n\n\n*Создайте бинарный оператор %between%, который будет возвращать TRUE, если значение в векторе слева накходится в диапазоне значений вектора справа:\n\n\n`%between%` <- function(x, y) x >= min(y) & x <= max(y)\n\n\n1:10 %between% c(1, 4, 5)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "920-solutions.html#sec-solution_sanity",
    "href": "920-solutions.html#sec-solution_sanity",
    "title": "26  Решения заданий",
    "section": "26.12 Проверка на адекватность",
    "text": "26.12 Проверка на адекватность\n\nСоздайте функцию trim(), которая будет возвращать вектор без первого и последнего значения (вне зависимости от типа данных).\n\n\ntrim <- function(x) x[c(-1, -length(x))]\n\n\nПроверьте, что функция trim() работает корректно:\n\n\ntrim(1:7)\n\n[1] 2 3 4 5 6\n\ntrim(letters)\n\n [1] \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[20] \"u\" \"v\" \"w\" \"x\" \"y\"\n\n\n\nТеперь добавьте в функцию trim() параметр n = со значением по умолчанию 1. Этот параметр будет обозначать сколько значений нужно отрезать слева и справа от вектора.\n\n\ntrim <- function(x, n = 1) x[c(-1:-n, (-length(x)+n-1):-length(x))]\n\n\nПроверьте полученную функцию:\n\n\ntrim(letters)\n\n [1] \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[20] \"u\" \"v\" \"w\" \"x\" \"y\"\n\ntrim(letters, n = 2)\n\n [1] \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\"\n[20] \"v\" \"w\" \"x\"\n\n\n\nСделайте так, чтобы функция trim() работала корректно с n = 0, т.е. функция возвращала бы исходный вектор без изменений.\n\n\ntrim <- function(x, n = 1) {\n  if (n == 0) return(x)\n  x[c(-1:-n, (-length(x)+n-1):-length(x))]\n}\n\n\ntrim(letters, n = 0)\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n\n*Теперь добавьте проверку на адекватность входных данных: функция trim() должна выдавать ошибку, если n = меньше нуля или если n = слишком большой и отрезает все значения вектора:\n\n\ntrim <- function(x, n = 1) {\n  if (n < 0) stop(\"n не может быть меньше нуля!\")\n  l <- length(x)\n  if (n > ceiling(l/2) - 1) stop(\"n слишком большой!\")\n  if (n == 0) return(x)\n  x[c(-1:-n, (-l+n-1):-l)]\n}\n\n\n*Проверьте полученную функцию trim():\n\n\ntrim(1:6, 3)\n\nError in trim(1:6, 3): n слишком большой!\n\ntrim(1:6, -1)\n\nError in trim(1:6, -1): n не может быть меньше нуля!"
  },
  {
    "objectID": "920-solutions.html#sec-solution_apply",
    "href": "920-solutions.html#sec-solution_apply",
    "title": "26  Решения заданий",
    "section": "26.13 Семейство функций apply()",
    "text": "26.13 Семейство функций apply()\n\nСоздайте матрицу M2:\n\n\nM2 <- matrix(c(20:11, 11:20), nrow = 5)\nM2\n\n     [,1] [,2] [,3] [,4]\n[1,]   20   15   11   16\n[2,]   19   14   12   17\n[3,]   18   13   13   18\n[4,]   17   12   14   19\n[5,]   16   11   15   20\n\n\n\nПосчитайте максимальное значение матрицы M2 по каждой строчке.\n\n\napply(M2, 1, max)\n\n[1] 20 19 18 19 20\n\n\n\nПосчитайте максимальное значение матрицы M2 по каждому столбцу.\n\n\napply(M2, 2, max)\n\n[1] 20 15 15 20\n\n\n\nПосчитайте среднее значение матрицы M2 по каждой строке.\n\n\napply(M2, 1, mean)\n\n[1] 15.5 15.5 15.5 15.5 15.5\n\n\n\nПосчитайте среднее значение матрицы M2 по каждому столбцу.\n\n\napply(M2, 2, mean)\n\n[1] 18 13 13 18\n\n\n\nСоздайте список list3:\n\n\nlist3 <- list(\n  a = 1:5,\n  b = 0:20,\n  c = 4:24,\n  d = 6:3,\n  e = 6:25\n  )\n\n\nНайдите максимальное значение каждого вектора списка list3.\n\n\nsapply(list3, max)\n\n a  b  c  d  e \n 5 20 24  6 25 \n\n\n\nПосчитайте сумму каждого вектора списка list3.\n\n\nsapply(list3, sum)\n\n  a   b   c   d   e \n 15 210 294  18 310 \n\n\n\nПосчитайте длину каждого вектора списка list3.\n\n\nsapply(list3, length)\n\n a  b  c  d  e \n 5 21 21  4 20 \n\n\n\nНапишите функцию max_item(), которая будет принимать на входе список, а возвращать - (первый) самый длинный его элемент.\n\n\nДля этого вам может понадобиться функция which.max(), которая возвращает индекс максимального значения (первого, если их несколько).\n\n\nmax_item <- function (x) x[[which.max(sapply(x, length))]]\n\n\nПроверьте функцию max_item() на списке list3.\n\n\nmax_item(list3)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nТеперь мы сделаем сложный список list4:\n\n\nlist4 <- list(1:3, 3:40, list3)\n\n\nПосчитайте длину каждого вектора в списке, в т.ч. для списка внутри. Результат должен быть списком с такой же структорой, как и изначальный список list4.\n\n\nДля этого может понадобиться функция rapply(): recursive lapply\n\n\nrapply(list4, length, how = \"list\")\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 38\n\n[[3]]\n[[3]]$a\n[1] 5\n\n[[3]]$b\n[1] 21\n\n[[3]]$c\n[1] 21\n\n[[3]]$d\n[1] 4\n\n[[3]]$e\n[1] 20\n\n\n\n*Загрузите набор данных heroes и посчитайте, сколько NA в каждом из столбцов.\n\n\nДля этого удобно использовать ранее написанную функцию na_n().\n\n\nsapply(heroes, na_n)\n\n         X       name     Gender  Eye.color       Race Hair.color     Height \n         0          0         29        172        304        172        217 \n Publisher Skin.color  Alignment     Weight       hair       tall \n         0        662          7        239        172        217 \n\n\n\n*Используя ранее написанную функцию is_prime(), напишите функцию prime_numbers(), которая будет возвращать все простые числа до выбранного числа.\n\n\nis_prime <- function(x) !any(x %% (2:(x - 1)) == 0)\nprime_numbers <- function(x) (2:x)[sapply(2:x, is_prime)]\n\n\nprime_numbers(200)\n\n [1]   3   5   7  11  13  17  19  23  29  31  37  41  43  47  53  59  61  67  71\n[20]  73  79  83  89  97 101 103 107 109 113 127 131 137 139 149 151 157 163 167\n[39] 173 179 181 191 193 197 199"
  },
  {
    "objectID": "920-solutions.html#sec-solution_pipe",
    "href": "920-solutions.html#sec-solution_pipe",
    "title": "26  Решения заданий",
    "section": "26.14 magrittr::%>%",
    "text": "26.14 magrittr::%>%\n\nlibrary(tidyverse)\n\n\nПерепишите следующие выражения, используя %>%:\n\n\n1:10 %>%\n  sum() %>%\n  sqrt()\n\n[1] 7.416198\n\n\n\n-5:5 %>%\n  min() %>%\n  abs()\n\n[1] 5\n\n\n\n2 %>% c(\"Корень из\", ., \"равен\", sqrt(.))\n\n[1] \"Корень из\"       \"2\"               \"равен\"           \"1.4142135623731\"\n\n\n\n10:39 %>% \n  matrix(nrow = 5) %>%\n  apply(1, mean)\n\n[1] 22.5 23.5 24.5 25.5 26.5"
  },
  {
    "objectID": "920-solutions.html#sec-solution_select",
    "href": "920-solutions.html#sec-solution_select",
    "title": "26  Решения заданий",
    "section": "26.15 Выбор столбцов: dplyr::select()",
    "text": "26.15 Выбор столбцов: dplyr::select()\nДля выполнения следующих заданий нам понадобятся датасеты heroes и powers, которые можно загрузить, используя следующие команды:\n\nlibrary(tidyverse)\nheroes <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/heroes_information.csv\",\n                   na = c(\"-\", \"-99\"))\npowers <- read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/super_hero_powers.csv\")\n\n\nВыберете первые 4 столбца в powers.\n\n\npowers %>%\n  select(1:4)\n\n# A tibble: 667 × 4\n   hero_names    Agility `Accelerated Healing` `Lantern Power Ring`\n   <chr>         <lgl>   <lgl>                 <lgl>               \n 1 3-D Man       TRUE    FALSE                 FALSE               \n 2 A-Bomb        FALSE   TRUE                  FALSE               \n 3 Abe Sapien    TRUE    TRUE                  FALSE               \n 4 Abin Sur      FALSE   FALSE                 TRUE                \n 5 Abomination   FALSE   TRUE                  FALSE               \n 6 Abraxas       FALSE   FALSE                 FALSE               \n 7 Absorbing Man FALSE   FALSE                 FALSE               \n 8 Adam Monroe   FALSE   TRUE                  FALSE               \n 9 Adam Strange  FALSE   FALSE                 FALSE               \n10 Agent Bob     FALSE   FALSE                 FALSE               \n# … with 657 more rows\n\n\n\nВыберите все столбцы от Reflexes до Empathy в тиббле powers:\n\n\npowers %>%\n  select(Reflexes:Empathy)\n\n# A tibble: 667 × 7\n   Reflexes Invulnerability `Energy Constructs` Force …¹ Self-…² Anti-…³ Empathy\n   <lgl>    <lgl>           <lgl>               <lgl>    <lgl>   <lgl>   <lgl>  \n 1 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 2 FALSE    FALSE           FALSE               FALSE    TRUE    FALSE   FALSE  \n 3 TRUE     FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 4 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 5 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 6 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 7 FALSE    TRUE            FALSE               FALSE    FALSE   FALSE   FALSE  \n 8 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n 9 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n10 FALSE    FALSE           FALSE               FALSE    FALSE   FALSE   FALSE  \n# … with 657 more rows, and abbreviated variable names ¹​`Force Fields`,\n#   ²​`Self-Sustenance`, ³​`Anti-Gravity`\n\n\n\nВыберите все столбцы тиббла powers кроме первого (hero_names):\n\n\npowers %>%\nselect(!hero_names)\n\n# A tibble: 667 × 167\n   Agility Accelerated …¹ Lante…² Dimen…³ Cold …⁴ Durab…⁵ Stealth Energ…⁶ Flight\n   <lgl>   <lgl>          <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl> \n 1 TRUE    FALSE          FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 2 FALSE   TRUE           FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE \n 3 TRUE    TRUE           FALSE   FALSE   TRUE    TRUE    FALSE   FALSE   FALSE \n 4 FALSE   FALSE          TRUE    FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 5 FALSE   TRUE           FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 6 FALSE   FALSE          FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   TRUE  \n 7 FALSE   FALSE          FALSE   FALSE   TRUE    TRUE    FALSE   TRUE    FALSE \n 8 FALSE   TRUE           FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE \n 9 FALSE   FALSE          FALSE   FALSE   FALSE   TRUE    TRUE    FALSE   TRUE  \n10 FALSE   FALSE          FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE \n# … with 657 more rows, 158 more variables: `Danger Sense` <lgl>,\n#   `Underwater breathing` <lgl>, Marksmanship <lgl>, `Weapons Master` <lgl>,\n#   `Power Augmentation` <lgl>, `Animal Attributes` <lgl>, Longevity <lgl>,\n#   Intelligence <lgl>, `Super Strength` <lgl>, Cryokinesis <lgl>,\n#   Telepathy <lgl>, `Energy Armor` <lgl>, `Energy Blasts` <lgl>,\n#   Duplication <lgl>, `Size Changing` <lgl>, `Density Control` <lgl>,\n#   Stamina <lgl>, `Astral Travel` <lgl>, `Audio Control` <lgl>, …"
  },
  {
    "objectID": "920-solutions.html#sec-solution_filt",
    "href": "920-solutions.html#sec-solution_filt",
    "title": "26  Решения заданий",
    "section": "26.16 Выбор строк: dplyr::slice() и dplyr::filter()",
    "text": "26.16 Выбор строк: dplyr::slice() и dplyr::filter()\n\nВыберите только те строчки, в которых содержится информация о супергероях тяжелее 500 кг.\n\n\nheroes %>% \n  filter(Weight > 500)\n\n# A tibble: 6 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   203 Dark… Male   red     New … No Hair  267   DC Com… grey    bad        817\n2   283 Giga… Female green   <NA>  Red       62.5 DC Com… <NA>    bad        630\n3   331 Hulk  Male   green   Huma… Green    244   Marvel… green   good       630\n4   373 Jugg… Male   blue    Human Red      287   Marvel… <NA>    neutral    855\n5   549 Red … Male   yellow  Huma… Black    213   Marvel… red     neutral    630\n6   575 Sasq… Male   red     <NA>  Orange   305   Marvel… <NA>    good       900\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nВыберите только те строчки, в которых содержится информация о женщинах-супергероях тяжелее 500 кг.\n\n\nheroes %>% \n  filter(Weight > 500 & Gender == \"Female\")\n\n# A tibble: 1 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1   283 Giga… Female green   <NA>  Red       62.5 DC Com… <NA>    bad        630\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nВыберите только те строчки, в которых содержится информация о супергероях человеческой расы (\"Human\") женского пола. Из этих супергероев возьмите первые 5.\n\n\nheroes %>% \n  filter(Race == \"Human\" & Gender == \"Female\") %>%\n  slice(1:5)\n\n# A tibble: 5 × 11\n   ...1 name  Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <dbl> <chr> <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>    <dbl>\n1    38 Arac… Female blue    Human Blond      175 Marvel… <NA>    good        63\n2    63 Batg… Female green   Human Red        170 DC Com… <NA>    good        57\n3    65 Batg… Female green   Human Black      165 DC Com… <NA>    good        52\n4    72 Batw… Female green   Human Red        178 DC Com… <NA>    good        NA\n5    96 Blac… Female blue    Human Blond      165 DC Com… <NA>    good        58\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "920-solutions.html#sec-solution_arr",
    "href": "920-solutions.html#sec-solution_arr",
    "title": "26  Решения заданий",
    "section": "26.17 Сортировка строк: dplyr::arrange()",
    "text": "26.17 Сортировка строк: dplyr::arrange()\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки по возрастанию Height.\n\n\nheroes %>%\n  select(name, Gender, Height) %>%\n  arrange(Height)\n\n# A tibble: 734 × 3\n   name            Gender Height\n   <chr>           <chr>   <dbl>\n 1 Utgard-Loki     Male     15.2\n 2 Bloodwraith     Male     30.5\n 3 King Kong       Male     30.5\n 4 Anti-Monitor    Male     61  \n 5 Giganta         Female   62.5\n 6 Krypto          Male     64  \n 7 Yoda            Male     66  \n 8 Jack-Jack       Male     71  \n 9 Howard the Duck Male     79  \n10 Godzilla        <NA>    108  \n# … with 724 more rows\n\n\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки по убыванию Height.\n\n\nheroes %>%\n  select(name, Gender, Height) %>%\n  arrange(desc(Height))\n\n# A tibble: 734 × 3\n   name          Gender Height\n   <chr>         <chr>   <dbl>\n 1 Fin Fang Foom Male     975 \n 2 Galactus      Male     876 \n 3 Groot         Male     701 \n 4 MODOK         Male     366 \n 5 Wolfsbane     Female   366 \n 6 Onslaught     Male     305 \n 7 Sasquatch     Male     305 \n 8 Ymir          Male     305.\n 9 Rey           Female   297 \n10 Juggernaut    Male     287 \n# … with 724 more rows\n\n\n\nВыберите из тиббла heroes колонки name, Gender, Height и отсортируйте строчки сначала по Gender, затем по убыванию Height.\n\n\nheroes %>%\n  select(name, Gender, Height) %>%\n  arrange(Gender, desc(Height))\n\n# A tibble: 734 × 3\n   name      Gender Height\n   <chr>     <chr>   <dbl>\n 1 Wolfsbane Female    366\n 2 Rey       Female    297\n 3 Bloodaxe  Female    218\n 4 Thundra   Female    218\n 5 Hela      Female    213\n 6 Frenzy    Female    211\n 7 She-Hulk  Female    201\n 8 Ardina    Female    193\n 9 Starfire  Female    193\n10 Valkyrie  Female    191\n# … with 724 more rows"
  },
  {
    "objectID": "920-solutions.html#sec-solution_dist",
    "href": "920-solutions.html#sec-solution_dist",
    "title": "26  Решения заданий",
    "section": "26.18 Уникальные значения: dplyr::distinct()",
    "text": "26.18 Уникальные значения: dplyr::distinct()\n\nИзвлеките уникальные значения столбца Eye color из тиббла heroes.\n\n\nheroes %>%\n  distinct(`Eye color`)\n\n# A tibble: 23 × 1\n   `Eye color`\n   <chr>      \n 1 yellow     \n 2 blue       \n 3 green      \n 4 brown      \n 5 <NA>       \n 6 red        \n 7 violet     \n 8 white      \n 9 purple     \n10 black      \n# … with 13 more rows\n\n\n\nИзвлеките уникальные значения столбца Hair color из тиббла heroes.\n\n\nheroes %>%\n  distinct(`Hair color`)\n\n# A tibble: 30 × 1\n   `Hair color`\n   <chr>       \n 1 No Hair     \n 2 Black       \n 3 Blond       \n 4 Brown       \n 5 <NA>        \n 6 White       \n 7 Purple      \n 8 Orange      \n 9 Pink        \n10 Red         \n# … with 20 more rows"
  },
  {
    "objectID": "920-solutions.html#sec-solution_mutate",
    "href": "920-solutions.html#sec-solution_mutate",
    "title": "26  Решения заданий",
    "section": "26.19 Создание колонок: dplyr::mutate() и dplyr::transmute()",
    "text": "26.19 Создание колонок: dplyr::mutate() и dplyr::transmute()\n\nСоздайте колонку height_m с ростом супергероев в метрах, затем выберите только колонки name и height_m.\n\n\nheroes %>%\n  mutate(height_m = Height/100) %>%\n  select(name, height_m)\n\n# A tibble: 734 × 2\n   name          height_m\n   <chr>            <dbl>\n 1 A-Bomb            2.03\n 2 Abe Sapien        1.91\n 3 Abin Sur          1.85\n 4 Abomination       2.03\n 5 Abraxas          NA   \n 6 Absorbing Man     1.93\n 7 Adam Monroe      NA   \n 8 Adam Strange      1.85\n 9 Agent 13          1.73\n10 Agent Bob         1.78\n# … with 724 more rows\n\n\n\nСоздайте новою колонку hair в heroes, в которой будет значение “Bold” для тех супергероев, у которых в колонке Hair.color стоит “No Hair”, и значение “Hairy” во всех остальных случаях. Затем выберите только колонки name, Hair color, hair.\n\n\nheroes %>%\n  mutate(hair = ifelse(`Hair color` == \"No Hair\", \"Bold\", \"Hairy\")) %>%\n  select(name, `Hair color`, hair)\n\n# A tibble: 734 × 3\n   name          `Hair color` hair \n   <chr>         <chr>        <chr>\n 1 A-Bomb        No Hair      Bold \n 2 Abe Sapien    No Hair      Bold \n 3 Abin Sur      No Hair      Bold \n 4 Abomination   No Hair      Bold \n 5 Abraxas       Black        Hairy\n 6 Absorbing Man No Hair      Bold \n 7 Adam Monroe   Blond        Hairy\n 8 Adam Strange  Blond        Hairy\n 9 Agent 13      Blond        Hairy\n10 Agent Bob     Brown        Hairy\n# … with 724 more rows"
  },
  {
    "objectID": "920-solutions.html#sec-solution_group_by",
    "href": "920-solutions.html#sec-solution_group_by",
    "title": "26  Решения заданий",
    "section": "26.20 Агрегация: dplyr::group_by() %>% summarise()",
    "text": "26.20 Агрегация: dplyr::group_by() %>% summarise()\n\nПосчитайте количество супергероев по расам и отсортируйте по убыванию. Извлеките первые 5 строк.\n\n\nheroes %>%\n  count(Race, sort = TRUE) %>%\n  slice(1:5)\n\n# A tibble: 5 × 2\n  Race              n\n  <chr>         <int>\n1 <NA>            304\n2 Human           208\n3 Mutant           63\n4 God / Eternal    14\n5 Cyborg           11\n\n\n\nПосчитайте средний пост по полу.\n\n\nheroes %>%\n  group_by(Gender) %>%\n  summarise(height_mean = mean(Height, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  Gender height_mean\n  <chr>        <dbl>\n1 Female        175.\n2 Male          192.\n3 <NA>          177."
  },
  {
    "objectID": "920-solutions.html#sec-solution_join",
    "href": "920-solutions.html#sec-solution_join",
    "title": "26  Решения заданий",
    "section": "26.21 Соединение датафреймов: *_join",
    "text": "26.21 Соединение датафреймов: *_join\nСоздайте тиббл web_creators, в котором будут супергерои, которые могут плести паутину, т.е. у них стоит TRUE в колонке Web Creation в тиббле powers.\n\npowers_web <- powers %>%\n  select(hero_names, `Web Creation`)\nweb_creators <- left_join(heroes, powers_web, by = c(\"name\" = \"hero_names\")) %>%\n  filter(`Web Creation`)\nweb_creators\n\n# A tibble: 16 × 12\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1    33 Anti-Venom  Male   blue    Symb… Blond      229 Marvel… <NA>    <NA>   \n 2    38 Arachne     Female blue    Human Blond      175 Marvel… <NA>    good   \n 3   161 Carnage     Male   green   Symb… Red        185 Marvel… <NA>    bad    \n 4   335 Hybrid      Male   brown   Symb… Black      175 Marvel… <NA>    good   \n 5   479 Mysterio    Male   brown   Human No Hair    180 Marvel… <NA>    bad    \n 6   580 Scarlet Sp… Male   brown   Clone Brown      193 Marvel… <NA>    good   \n 7   597 Silk        Female brown   Human Black       NA Marvel… <NA>    good   \n 8   620 Spider-Girl Female blue    Human Brown      170 Marvel… <NA>    good   \n 9   621 Spider-Gwen Female blue    Human Blond      165 Marvel… <NA>    good   \n10   622 Spider-Man  Male   hazel   Human Brown      178 Marvel… <NA>    good   \n11   623 Spider-Man  <NA>   red     Human Brown      178 Marvel… <NA>    good   \n12   624 Spider-Man  Male   brown   Human Black      157 Marvel… <NA>    good   \n13   673 Toxin       Male   blue    Symb… Brown      188 Marvel… <NA>    good   \n14   674 Toxin       Male   black   Symb… Blond      191 Marvel… <NA>    good   \n15   689 Venom       Male   blue    Symb… Strawb…    191 Marvel… <NA>    bad    \n16   692 Venompool   Male   <NA>    Symb… <NA>       226 Marvel… <NA>    <NA>   \n# … with 2 more variables: Weight <dbl>, `Web Creation` <lgl>, and abbreviated\n#   variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`,\n#   ⁵​Alignment\n\n\n\nНайдите всех супергероев, которые присутствуют в heroes, но отсутствуют в powers. Ответом должен быть строковый вектор с именами супергероев.\n\n\nanti_join(heroes, powers, by = c(\"name\" = \"hero_names\")) %>%\n  pull(name)\n\n [1] \"Agent 13\"          \"Alfred Pennyworth\" \"Arsenal\"          \n [4] \"Batgirl III\"       \"Batgirl V\"         \"Beetle\"           \n [7] \"Black Goliath\"     \"Black Widow II\"    \"Blaquesmith\"      \n[10] \"Bolt\"              \"Boomer\"            \"Box\"              \n[13] \"Box III\"           \"Captain Mar-vell\"  \"Cat II\"           \n[16] \"Cecilia Reyes\"     \"Clea\"              \"Clock King\"       \n[19] \"Colin Wagner\"      \"Colossal Boy\"      \"Corsair\"          \n[22] \"Cypher\"            \"Danny Cooper\"      \"Darkside\"         \n[25] \"ERG-1\"             \"Fixer\"             \"Franklin Storm\"   \n[28] \"Giant-Man\"         \"Giant-Man II\"      \"Goliath\"          \n[31] \"Goliath\"           \"Goliath\"           \"Guardian\"         \n[34] \"Hawkwoman\"         \"Hawkwoman II\"      \"Hawkwoman III\"    \n[37] \"Howard the Duck\"   \"Jack Bauer\"        \"Jesse Quick\"      \n[40] \"Jessica Sanders\"   \"Jigsaw\"            \"Jyn Erso\"         \n[43] \"Kid Flash II\"      \"Kingpin\"           \"Meteorite\"        \n[46] \"Mister Zsasz\"      \"Mogo\"              \"Moloch\"           \n[49] \"Morph\"             \"Nite Owl II\"       \"Omega Red\"        \n[52] \"Paul Blart\"        \"Penance\"           \"Penance I\"        \n[55] \"Plastic Lad\"       \"Power Man\"         \"Renata Soliz\"     \n[58] \"Ronin\"             \"Shrinking Violet\"  \"Snake-Eyes\"       \n[61] \"Spider-Carnage\"    \"Spider-Woman II\"   \"Stacy X\"          \n[64] \"Thunderbird II\"    \"Two-Face\"          \"Vagabond\"         \n[67] \"Vision II\"         \"Vulcan\"            \"Warbird\"          \n[70] \"White Queen\"       \"Wiz Kid\"           \"Wondra\"           \n[73] \"Wyatt Wingfoot\"    \"Yellow Claw\"      \n\n\n\nНайдите всех супергероев, которые присутствуют в powers, но отсутствуют в heroes. Ответом должен быть строковый вектор с именами супергероев.\n\n\nanti_join(powers, heroes, by = c(\"hero_names\" = \"name\")) %>%\n  pull(hero_names)\n\n [1] \"3-D Man\"           \"Bananaman\"         \"Bizarro-Girl\"     \n [4] \"Black Vulcan\"      \"Blue Streak\"       \"Bradley\"          \n [7] \"Clayface\"          \"Concrete\"          \"Dementor\"         \n[10] \"Doctor Poison\"     \"Fire\"              \"Hellgramite\"      \n[13] \"Lara Croft\"        \"Little Epic\"       \"Lord Voldemort\"   \n[16] \"Orion\"             \"Peek-a-Boo\"        \"Queen Hippolyta\"  \n[19] \"Reactron\"          \"SHDB\"              \"Stretch Armstrong\"\n[22] \"TEST\"              \"Tommy Clarke\"      \"Tyrant\""
  },
  {
    "objectID": "920-solutions.html#sec-solution_pivot",
    "href": "920-solutions.html#sec-solution_pivot",
    "title": "26  Решения заданий",
    "section": "26.22 Tidy data",
    "text": "26.22 Tidy data\n\nДля начала создайте тиббл heroes_weight, скопировав код:\n\n\nheroes_weight <- heroes %>%\n  filter(Publisher %in% c(\"DC Comics\", \"Marvel Comics\")) %>%\n  group_by(Gender, Publisher) %>%\n  summarise(weight_mean = mean(Weight, na.rm = TRUE)) %>%\n  drop_na()\nheroes_weight \n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Publisher     weight_mean\n  <chr>  <chr>               <dbl>\n1 Female DC Comics            76.8\n2 Female Marvel Comics        80.1\n3 Male   DC Comics           113. \n4 Male   Marvel Comics       134. \n\n\n\nФункция drop_na() позволяет выбросить все строчки, в которых встречается NA.\n\n\nПревратите тиббл heroes_weight в широкий тиббл:\n\n\nheroes_weight %>%\n  pivot_wider(names_from = \"Publisher\", values_from = \"weight_mean\")\n\n# A tibble: 2 × 3\n# Groups:   Gender [2]\n  Gender `DC Comics` `Marvel Comics`\n  <chr>        <dbl>           <dbl>\n1 Female        76.8            80.1\n2 Male         113.            134. \n\n\n\nЗатем превратите его обратно в длинный тиббл:\n\n\nheroes_weight %>%\n  pivot_wider(names_from = \"Publisher\", values_from = \"weight_mean\") %>%\n  pivot_longer(cols = !Gender,\n               names_to = \"Publisher\",\n               values_to = \"weight_mean\")\n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Publisher     weight_mean\n  <chr>  <chr>               <dbl>\n1 Female DC Comics            76.8\n2 Female Marvel Comics        80.1\n3 Male   DC Comics           113. \n4 Male   Marvel Comics       134. \n\n\n\nСделайте powers длинным тибблом с тремя колонками: hero_names, power (названгие суперсилы) и has (наличие суперсилы у данного супергероя).\n\n\npowers %>%\n  pivot_longer(cols = !hero_names,\n               names_to = \"power\",\n               values_to = \"has\")\n\n# A tibble: 111,389 × 3\n   hero_names power                 has  \n   <chr>      <chr>                 <lgl>\n 1 3-D Man    Agility               TRUE \n 2 3-D Man    Accelerated Healing   FALSE\n 3 3-D Man    Lantern Power Ring    FALSE\n 4 3-D Man    Dimensional Awareness FALSE\n 5 3-D Man    Cold Resistance       FALSE\n 6 3-D Man    Durability            FALSE\n 7 3-D Man    Stealth               FALSE\n 8 3-D Man    Energy Absorption     FALSE\n 9 3-D Man    Flight                FALSE\n10 3-D Man    Danger Sense          FALSE\n# … with 111,379 more rows\n\n\n\nСделайте тиббл powers обратно широким, но с новой структурой: каждая строчка означает суперсилу, а каждая колонка - супергероя (за исключением первой колонки - названия суперсилы).\n\n\npowers %>%\n  pivot_longer(cols = !hero_names,\n               names_to = \"power\",\n               values_to = \"has\") %>%\n  pivot_wider(names_from = hero_names,\n              values_from = has)\n\n# A tibble: 167 × 668\n   power 3-D M…¹ A-Bom…² Abe S…³ Abin …⁴ Abomi…⁵ Abraxas Absor…⁶ Adam …⁷ Adam …⁸\n   <chr> <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>   <lgl>  \n 1 Agil… TRUE    FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   FALSE   FALSE  \n 2 Acce… FALSE   TRUE    TRUE    FALSE   TRUE    FALSE   FALSE   TRUE    FALSE  \n 3 Lant… FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE   FALSE   FALSE  \n 4 Dime… FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   FALSE  \n 5 Cold… FALSE   FALSE   TRUE    FALSE   FALSE   FALSE   TRUE    FALSE   FALSE  \n 6 Dura… FALSE   TRUE    TRUE    FALSE   FALSE   FALSE   TRUE    FALSE   TRUE   \n 7 Stea… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE   \n 8 Ener… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE  \n 9 Flig… FALSE   FALSE   FALSE   FALSE   FALSE   TRUE    FALSE   FALSE   TRUE   \n10 Dang… FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE  \n# … with 157 more rows, 658 more variables: `Agent Bob` <lgl>,\n#   `Agent Zero` <lgl>, `Air-Walker` <lgl>, Ajax <lgl>, `Alan Scott` <lgl>,\n#   `Alex Mercer` <lgl>, `Alex Woolsly` <lgl>, Alien <lgl>,\n#   `Allan Quatermain` <lgl>, Amazo <lgl>, Ammo <lgl>, `Ando Masahashi` <lgl>,\n#   Angel <lgl>, `Angel Dust` <lgl>, `Angel Salvadore` <lgl>, Angela <lgl>,\n#   `Animal Man` <lgl>, Annihilus <lgl>, `Ant-Man` <lgl>, `Ant-Man II` <lgl>,\n#   `Anti-Monitor` <lgl>, `Anti-Spawn` <lgl>, `Anti-Venom` <lgl>, …"
  },
  {
    "objectID": "920-solutions.html#sec-solution_across",
    "href": "920-solutions.html#sec-solution_across",
    "title": "26  Решения заданий",
    "section": "26.23 Операции с несколькими колонками: across()",
    "text": "26.23 Операции с несколькими колонками: across()\n\nПосчитайте количество NA в каждой колонке, группируя по полу (Gender).\n\n\nna_n <- function(x) sum(is.na(x))\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(everything(), na_n))\n\n# A tibble: 3 × 11\n  Gender  ...1  name Eye c…¹  Race Hair …² Height Publi…³ Skin …⁴ Align…⁵ Weight\n  <chr>  <int> <int>   <int> <int>   <int>  <int>   <int>   <int>   <int>  <int>\n1 Female     0     0      41    98      38     56       0     186       0     58\n2 Male       0     0     121   184     123    147       0     449       6    166\n3 <NA>       0     0      10    22      11     14       0      27       1     15\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nПосчитайте количество NA в каждой колонке, которая заканчивается на \"color\", группируя по полу (Gender).\n\n\nna_n <- function(x) sum(is.na(x))\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(ends_with(\"color\"), na_n))\n\n# A tibble: 3 × 4\n  Gender `Eye color` `Hair color` `Skin color`\n  <chr>        <int>        <int>        <int>\n1 Female          41           38          186\n2 Male           121          123          449\n3 <NA>            10           11           27\n\n\n\nНайдите (первую) самую длинную строчку для каждой колонки с character типом данных, группируя по полу (Gender).\n\n\nДля расчета количества значений в строке есть функция nchar(), для расчета индекса (первого) максимального значения есть функция which.max().\n\n\nlongest_char <- function(x) x[which.max(nchar(x))]\nheroes %>%\n  group_by(Gender) %>%\n  summarise(across(where(is.character), longest_char))\n\n# A tibble: 3 × 8\n  Gender name                      Eye c…¹ Race  Hair …² Publi…³ Skin …⁴ Align…⁵\n  <chr>  <chr>                     <chr>   <chr> <chr>   <chr>   <chr>   <chr>  \n1 Female Negasonic Teenage Warhead yellow… Huma… Strawb… Dark H… orange  neutral\n2 Male   Drax the Destroyer        yellow… Dath… Strawb… Dark H… orange… neutral\n3 <NA>   Captain Universe          yellow… God … Orange… Marvel… grey    neutral\n# … with abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nСоздайте из тиббла heroes новый тиббл, в котором числовые значения Height и Weight заменены на следующие строковые значения: если у супергероя рост или вес выше среднего по колонке, то \"выше среднего\", если его/ее рост или вес ниже или равен среднему, то \"ниже среднего\".\n\n\nhigher_than_average <- function(x) ifelse(x > mean(x, na.rm = TRUE),\n                                          \"выше среднего\",\n                                          \"ниже среднего\")\nheroes %>%\n  mutate(across(c(Height, Weight), \n                   higher_than_average))\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>   <chr>  <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair выше … Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair выше … Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair ниже … DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair выше … Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black   <NA>   Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair выше … Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond   <NA>   NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond   ниже … DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond   ниже … Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown   ниже … Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <chr>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment\n\n\n\nСоздайте из тиббла heroes новый тиббл, в котором числовые значения Height и Weight заменены на следующие строковые значения: если у супергероя внутри соответствующей группы по полу рост или вес выше среднего по колонке, то \"выше среднего по X\", если его/ее рост или вес ниже или равен среднему внутри соответствующей группы по полу, то \"ниже среднего по X\" , где X — соответствующий пол (Gender).\n\n\nheroes %>%\n  group_by(Gender) %>%\n  mutate(across(c(Height, Weight), \n                   higher_than_average)) %>%\n  ungroup() %>%\n  mutate(across(c(Height, Weight), \n                   ~paste(., \"по\", Gender)))\n\n# A tibble: 734 × 11\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>   <chr>  <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair выше … Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair ниже … Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair ниже … DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair выше … Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black   NA по… Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair выше … Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond   NA по… NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond   ниже … DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond   ниже … Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown   ниже … Marvel… <NA>    good   \n# … with 724 more rows, 1 more variable: Weight <chr>, and abbreviated variable\n#   names ¹​`Eye color`, ²​`Hair color`, ³​Publisher, ⁴​`Skin color`, ⁵​Alignment"
  },
  {
    "objectID": "920-solutions.html#sec-desc_solutions",
    "href": "920-solutions.html#sec-desc_solutions",
    "title": "26  Решения заданий",
    "section": "26.24 Описательная статистика",
    "text": "26.24 Описательная статистика\nДля выполнения задания создайте вектор height из колонки Height датасета heroes, удалив в нем NA.\n\nheight <- heroes %>%\n  drop_na(Height) %>%\n  pull(Height)\n\n\nПосчитайте среднее в векторе height.\n\n\nmean(height)\n\n[1] 186.7263\n\n\n\nПосчитайте усеченное среднее в векторе height с усечением 5% значений с обоих сторон.\n\n\nmean(height, trim = 0.05)\n\n[1] 182.5846\n\n\n\nПосчитайте медиану в векторе height.\n\n\nmedian(height)\n\n[1] 183\n\n\n\nПосчитайте стандартное отклонение в векторе height.\n\n\nsd(height)\n\n[1] 59.25189\n\n\n\nПосчитайте межквартильный размах в векторе height.\n\n\nIQR(height)\n\n[1] 18\n\n\n\nПосчитайте ассиметрию в векторе height.\n\n\npsych::skew(height)\n\n[1] 8.843432\n\n\nПосчитайте эксцесс в векторе height.\n\npsych::kurtosi(height)\n\n[1] 105.0297\n\n\nПримените функции для получения множественных статистик на векторе height.\n\nsummary(height)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   15.2   173.0   183.0   186.7   191.0   975.0 \n\npsych::describe(height)\n\n   vars   n   mean    sd median trimmed   mad  min max range skew kurtosis   se\nX1    1 517 186.73 59.25    183  182.02 11.86 15.2 975 959.8 8.84   105.03 2.61\n\nskimr::skim(height)\n\n\nData summary\n\n\nName\nheight\n\n\nNumber of rows\n517\n\n\nNumber of columns\n1\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndata\n0\n1\n186.73\n59.25\n15.2\n173\n183\n191\n975\n▇▁▁▁▁"
  },
  {
    "objectID": "920-solutions.html#sec-ggplot2_solutions",
    "href": "920-solutions.html#sec-ggplot2_solutions",
    "title": "26  Решения заданий",
    "section": "26.25 Построение графиков в ggplot2",
    "text": "26.25 Построение графиков в ggplot2\n\nНарисуйте столбиковую диаграмму (geom_bar()), которая будет отражать количество супергероев издателей \"Marvel Comics\", \"DC Comics\" и всех остальных (отдельным столбиком) из датасета heroes.\n\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  #mutate(Publisher = fct_lump(Publisher, 2)) %>% #Еще один способ сделать то же самое, но через forcats\n  ggplot(aes(x = Publisher)) +\n  geom_bar()\n\n\n\n\n\nДобавьте к этой диаграме заливку цветом (fill =) в зависимости от распределения Gender внутри каждой группы.\n\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  #mutate(Publisher = fct_lump(Publisher, 2)) %>% #Еще один способ сделать то же самое, но через forcats\n  ggplot(aes(x = Publisher, fill = Gender)) +\n  geom_bar()\n\n\n\n\n\nСделайте так, чтобы каждый столбик был максимальной высоты (position = \"fill\").\n\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  #mutate(Publisher = fct_lump(Publisher, 2)) %>% #Еще один способ сделать то же самое, но через forcats\n  ggplot(aes(x = Publisher, fill = Gender)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\nФинализируйте график, задав ему описания осей (например, функция labs()), использовав процентную шкалу (scale_y_continuous(labels = scales::percent)) и задав тему theme_minimal().\n\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  #mutate(Publisher = fct_lump(Publisher, 2)) %>% #Еще один способ сделать то же самое, но через forcats\n  ggplot(aes(x = Publisher, fill = Gender)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Распределение супергероев по полу у разных издателей коммиксов\",\n       x = \"Издатель\",\n       y = \"Количество супергероев\")+\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\nСоздайте диаграмму рассеяния для датасета heroes, для которой координаты по оси x будут взяты из колонки Height, а координаты по оси y — из колонки Weight.\n\nheroes %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point()\n\n\n\n\n\nУдалите с графика все экстремальные значения, для которых Weight больше или равен 700 или Height больше или равен 400. (Подсказка: это можно делать как средствами ggplot2, так и функцией filter() из dplyr).\n\n\nheroes %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point()\n\n\n\n\n\nРаскрасьте точки в зависимости от Gender, сделайте их полупрозрачными ( параметр alpha =).\n\n\nheroes %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(aes(colour = Gender), alpha = 0.5)\n\n\n\n\n\nСделайте так, чтобы координатная плоскость имела соотношение 1:1 шкал по оси x и y. Этого можно добиться с помощью функции coord_fixed().\n\n\nheroes %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(aes(colour = Gender), alpha = 0.5) +\n  coord_fixed()\n\n\n\n\nРазделите график (facet_wrap()) на три: для \"DC Comics\",\"Marvel Comics\" и всех остальных.\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(aes(colour = Gender), alpha = 0.5) +\n  coord_fixed() +\n  facet_wrap(~Publisher)\n\n\n\n\n\nИспользуйте для графика тему theme_linedraw().\n\n\nheroes %>%\n  mutate(Publisher = ifelse(Publisher %in% c(\"Marvel Comics\", \"DC Comics\"), \n                            Publisher,\n                            \"Other publishers\")) %>%\n  filter(Weight < 700 & Height < 400) %>%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(aes(colour = Gender), alpha = 0.5) +\n  coord_fixed() +\n  facet_wrap(~Publisher)+\n  theme_linedraw()\n\n\n\n\n\n\nПостройте новый график (или возьмите старый) по датасетам heroes и/или powers и сделайте его некрасивым! Чем хуже у вас получится график, тем лучше. Желательно, чтобы этот график был по-прежнему графиком, а не произведением абстрактного искусства. Разница очень тонкая, но она есть.\n\n\nВот несколько подсказок для этого задания:\n\nДля вдохновения посмотрите на вот эти графики.\nДля реально плохих графиков вам придется покопаться с настройками темы. Посмотрите подсказку по темам ?theme, попытайтесь что-то поменять в теме.\nЭкспериментируйте с разными геомами и необычными их применениями.\nПо изучайте дополнения к gpplot2.\nПопробуйте подготовить интересные данные для этого графика.\n\n\nНЕТ ПРАВИЛЬНОГО РЕШЕНИЯ, ПРОЯВИТЕ СВОЮ ФАНТАЗИЮ!"
  },
  {
    "objectID": "920-solutions.html#sec-dist_solutions",
    "href": "920-solutions.html#sec-dist_solutions",
    "title": "26  Решения заданий",
    "section": "26.26 Распределения",
    "text": "26.26 Распределения\nВыберите любое непрерывное распределение из представленных в базовом пакете stats или же в любом другом пакете. Найти все распределения пакета stats можно с помощью ?Distributions. Подберите для него какие-нибудь параметры или используйте параметры по умолчанию.\n\nЯ возьму F-распределение с параметрами df1 = 4 и df = 10, но вы можете выбрать другое распределение.\n\n\nВизуализируйте функцию плотности вероятности для выбранного распределения.\n\n\nv <- seq(0, 5, 0.01)\nplot(v, df(v, df1 = 4, df2 = 10))\n\n\n\n\n\nВизуализируйте функцию накопленной плотности распределения для выбранной функции.\n\n\nplot(v, pf(v, df1 = 4, df2 = 10))\n\n\n\n\n\nВизуализируйте квантильную функцию для выбранного распределения.\n\n\np <- seq(0, 1, .01)\nplot(p, qf(p, df1 = 4, df2 = 10))\n\n\n\n\n\nСделайте выборку из 100 случайных значений из выбранного распределения и постройте гистограмму (функция hist()) для полученной выборки.\n\n\nhist(rf(100, df1 = 4, df2 = 10))"
  },
  {
    "objectID": "920-solutions.html#sec-one_ttest_solutions",
    "href": "920-solutions.html#sec-one_ttest_solutions",
    "title": "26  Решения заданий",
    "section": "26.27 Одновыборочный t-test",
    "text": "26.27 Одновыборочный t-test\n\nПредставьте, что наши супергерои из набора данных heroes — это выборка из генеральной совокупности всех написанных и ненаписанных супергероев. Проведите одновыборочный t-тест для веса супергероев и числа 100 — предположительного среднего веса в генеральной совокупности всех супергероев. Проинтерпретируйте результат.\n\n\nt.test(heroes$Weight, mu = 100)\n\n\n    One Sample t-test\n\ndata:  heroes$Weight\nt = 2.6174, df = 494, p-value = 0.009133\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n 103.0549 121.4501\nsample estimates:\nmean of x \n 112.2525 \n\n\np-value меньше .05, поэтому мы можем отклонить нулевую гипотезу о том, что среднее для веса в генеральной совкупности, из которой вы взяли выборку супергероев, равно 100. Мы принимаем ненулевую гипотезу о том, что в генеральной совокупности средний вес не равен 100.\n\nПроведите одновыборочный t-тест для роста супергероев и числа 185 — предположительного среднего роста в генеральной совокупности всех супергероев. Проинтерпретируйте результат.\n\n\nt.test(heroes$Height, mu = 185)\n\n\n    One Sample t-test\n\ndata:  heroes$Height\nt = 0.66246, df = 516, p-value = 0.508\nalternative hypothesis: true mean is not equal to 185\n95 percent confidence interval:\n 181.6068 191.8458\nsample estimates:\nmean of x \n 186.7263 \n\n\np-value больше .05, поэтому мы не можем отклонить нулевую гипотезу о том, что среднее для роста в генеральной совкупности, из которой вы взяли выборку супергероев, равно 185."
  },
  {
    "objectID": "920-solutions.html#sec-dep_ttest_solutions",
    "href": "920-solutions.html#sec-dep_ttest_solutions",
    "title": "26  Решения заданий",
    "section": "26.28 Двухвыборочный зависимый t-test",
    "text": "26.28 Двухвыборочный зависимый t-test\n\ndiet <- readr::read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv\")\n\n\nПосчитайте двухвыборочный зависимый т-тест для остальных диет: для диеты 2 и диеты 3. Проинтерпретируйте полученные результаты.\n\n\ndiet2 <- diet %>%\n  filter(Diet == 2)\nt.test(diet2$pre.weight, diet2$weight6weeks, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  diet2$pre.weight and diet2$weight6weeks\nt = 6.231, df = 26, p-value = 1.36e-06\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.027715 4.024137\nsample estimates:\nmean difference \n       3.025926 \n\n\np-value меньше .05, поэтому мы можем отклонить нулевую гипотезу о том, что масса до и после диеты одинаковая. Мы принимаем альтернативную гипотезу о различии средних в генеральной совокупности.\n\ndiet3 <- diet %>%\n  filter(Diet == 3)\nt.test(diet3$pre.weight, diet3$weight6weeks, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  diet3$pre.weight and diet3$weight6weeks\nt = 11.167, df = 26, p-value = 2.03e-11\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.200493 6.095803\nsample estimates:\nmean difference \n       5.148148 \n\n\np-value меньше .05, поэтому мы можем отклонить нулевую гипотезу о том, что масса до и после диеты одинаковая. Мы принимаем альтернативную гипотезу о различии средних в генеральной совокупности."
  },
  {
    "objectID": "920-solutions.html#sec-ind_ttest_solutions",
    "href": "920-solutions.html#sec-ind_ttest_solutions",
    "title": "26  Решения заданий",
    "section": "26.29 Двухвыборочный независимый t-test",
    "text": "26.29 Двухвыборочный независимый t-test\n\nСделайте независимый t-тест для сравнения веса испытуемых двух групп после диеты, сравнив вторую и третью группу. Проинтерпретируйте результаты.\n\n\ndiet23 <- diet %>%\n  filter(Diet %in% 2:3)\nt.test(weight6weeks ~ Diet, data = diet23, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  weight6weeks by Diet\nt = -0.15686, df = 49.774, p-value = 0.876\nalternative hypothesis: true difference in means between group 2 and group 3 is not equal to 0\n95 percent confidence interval:\n -5.471327  4.678734\nsample estimates:\nmean in group 2 mean in group 3 \n       68.08519        68.48148 \n\n\np-value больше .05, поэтому мы не можем отклонить нулевую гипотезу о том, что масса до и после диеты одинаковая.\n\nСделайте независимый t-тест для сравнения веса испытуемых двух групп после диеты, сравнив первую и третью группу. Проинтерпретируйте результаты.\n\n\ndiet13 <- diet %>%\n  filter(Diet %in% c(1,3))\nt.test(weight6weeks ~ Diet, data = diet13, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  weight6weeks by Diet\nt = 0.46818, df = 48.072, p-value = 0.6418\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -3.602450  5.789487\nsample estimates:\nmean in group 1 mean in group 3 \n       69.57500        68.48148 \n\n\np-value больше .05, поэтому мы не можем отклонить нулевую гипотезу о том, что масса до и после диеты одинаковая."
  },
  {
    "objectID": "920-solutions.html#sec-nonparam_ttest_solutions",
    "href": "920-solutions.html#sec-nonparam_ttest_solutions",
    "title": "26  Решения заданий",
    "section": "26.30 Непараметрические аналоги t-теста",
    "text": "26.30 Непараметрические аналоги t-теста\n\nСравните вес первой и второй группы после диеты, используя тест Манна-Уитни. Сравните результаты теста Манна-Уитни с результатами t-теста? Проинтерпретируйте полученные результаты.\n\n\ndiet12 <- diet %>%\n  filter(Diet %in% c(1,2))\nwilcox.test(weight6weeks ~ Diet, data = diet12, paired = FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  weight6weeks by Diet\nW = 368, p-value = 0.4117\nalternative hypothesis: true location shift is not equal to 0\n\n\nВ обоих случаях p-value больше 0.05, мы не можем отклонить нулевую гипотезу об отсутствии различий.\n\nПовторите задание для второй и третьей группы, а так же для первой и третьей группы.\n\n\nwilcox.test(weight6weeks ~ Diet, data = diet23, paired = FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  weight6weeks by Diet\nW = 340.5, p-value = 0.6843\nalternative hypothesis: true location shift is not equal to 0\n\nwilcox.test(weight6weeks ~ Diet, data = diet13, paired = FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  weight6weeks by Diet\nW = 346, p-value = 0.6849\nalternative hypothesis: true location shift is not equal to 0\n\n\nВ обоих случаях p-value больше 0.05, как и для соответствующих t-тестов. Мы не можем отклонить нулевую гипотезу об отстутствии различий между второй и третьей диетой, между первой и третьей диетой.\n\nСравните вес до и после для диеты 1, используя тест Уилкоксона. Сравните с результатами применения t-теста. Проинтерпретируйте полученные результаты.\n\n\ndiet1 <- diet %>%\n  filter(Diet == 1)\nwilcox.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  diet1$pre.weight and diet1$weight6weeks\nV = 299, p-value = 2.203e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\nИ t-тест, и тест Уилкоксона дают p-value ниже 0.05. Мы можем отклонить нулевую гипотезу об отсутствии различий.\n\nСравните вес до и после для диеты 2 и диеты 3, используя тест Уилкоксона. Сравните с результатами применения t-теста. Проинтерпретируйте полученные результаты.\n\n\nwilcox.test(diet2$pre.weight, diet2$weight6weeks, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  diet2$pre.weight and diet2$weight6weeks\nV = 313, p-value = 5.419e-05\nalternative hypothesis: true location shift is not equal to 0\n\nwilcox.test(diet3$pre.weight, diet3$weight6weeks, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  diet3$pre.weight and diet3$weight6weeks\nV = 378, p-value = 5.912e-06\nalternative hypothesis: true location shift is not equal to 0\n\n\nВ обоих случаях и t-тест, и тест Уилкоксона дают p-value ниже 0.05. Мы можем отклонить нулевую гипотезу об отсутствии различий."
  },
  {
    "objectID": "920-solutions.html#sec-chi_sq_solutions",
    "href": "920-solutions.html#sec-chi_sq_solutions",
    "title": "26  Решения заданий",
    "section": "26.31 Критерий хи-квадрат Пирсона",
    "text": "26.31 Критерий хи-квадрат Пирсона\n\nСоздайте в heroes новую колонку is_human логического типа, в которой будет TRUE, если супергерой принадлежит расе (Race) \"Human\", и FALSE в случае если супергерой принадлежит другой расе.\n\n\nheroes %>%\n  mutate(is_human = Race == \"Human\")\n\n# A tibble: 734 × 12\n    ...1 name        Gender Eye c…¹ Race  Hair …² Height Publi…³ Skin …⁴ Align…⁵\n   <dbl> <chr>       <chr>  <chr>   <chr> <chr>    <dbl> <chr>   <chr>   <chr>  \n 1     0 A-Bomb      Male   yellow  Human No Hair    203 Marvel… <NA>    good   \n 2     1 Abe Sapien  Male   blue    Icth… No Hair    191 Dark H… blue    good   \n 3     2 Abin Sur    Male   blue    Unga… No Hair    185 DC Com… red     good   \n 4     3 Abomination Male   green   Huma… No Hair    203 Marvel… <NA>    bad    \n 5     4 Abraxas     Male   blue    Cosm… Black       NA Marvel… <NA>    bad    \n 6     5 Absorbing … Male   blue    Human No Hair    193 Marvel… <NA>    bad    \n 7     6 Adam Monroe Male   blue    <NA>  Blond       NA NBC - … <NA>    good   \n 8     7 Adam Stran… Male   blue    Human Blond      185 DC Com… <NA>    good   \n 9     8 Agent 13    Female blue    <NA>  Blond      173 Marvel… <NA>    good   \n10     9 Agent Bob   Male   brown   Human Brown      178 Marvel… <NA>    good   \n# … with 724 more rows, 2 more variables: Weight <dbl>, is_human <lgl>, and\n#   abbreviated variable names ¹​`Eye color`, ²​`Hair color`, ³​Publisher,\n#   ⁴​`Skin color`, ⁵​Alignment\n\n\n\nПосчитайте долю женщин для \"Human\" и всех остальных (is_human равен TRUE и FALSE соответственно). Перед этим удалите все строчки с NA в переменных is_human и Gender.\n\n\nheroes %>%\n  mutate(is_human = Race == \"Human\") %>%\n  drop_na(is_human, Gender) %>%\n  group_by(is_human) %>%\n  summarise(mean(Gender == \"Female\"))\n\n# A tibble: 2 × 2\n  is_human `mean(Gender == \"Female\")`\n  <lgl>                         <dbl>\n1 FALSE                         0.241\n2 TRUE                          0.242\n\n\n\nСравните распределения частот для переменных is_human и Gender используя хи-квадрат Пирсона. Проинтерпретируйте результаты.\n\n\nheroes %>%\n  mutate(is_human = Race == \"Human\") %>%\n  drop_na(is_human, Gender) %>%\n  select(is_human, Gender) %>%\n  table() %>%\n  chisq.test(correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  .\nX-squared = 0.00037447, df = 1, p-value = 0.9846\n\n\nМы не можем отвергнуть нулевую гипотезу о независимости расы (Человек/не-человек) и пола.\n\nПостройте мозаичный график для переменных is_human и Gender.\n\n\nheroes %>%\n  mutate(is_human = Race == \"Human\") %>%\n  drop_na(is_human, Gender) %>%\n  select(is_human, Gender) %>%\n  table() %>%\n  mosaicplot(shade = TRUE)"
  },
  {
    "objectID": "920-solutions.html#sec-backpack_solutions",
    "href": "920-solutions.html#sec-backpack_solutions",
    "title": "26  Решения заданий",
    "section": "26.32 Исследование набора данных Backpack",
    "text": "26.32 Исследование набора данных Backpack\nДля следующих тем нам понадобится набор данных Backpack из пакета Stat2Data.\n\n#install.packages(\"Stat2Data\")\nlibrary(Stat2Data)\ndata(Backpack)\nback <- Backpack %>%\n  mutate(backpack_kg = 0.45359237 * BackpackWeight,\n         body_kg = 0.45359237 * BodyWeight)\n\n\nКак различается вес рюкзака в зависимости от пола? Кто весит больше?\n\n\nback %>%\n  group_by(Sex) %>%\n  summarise(mean(backpack_kg))\n\n# A tibble: 2 × 2\n  Sex    `mean(backpack_kg)`\n  <fct>                <dbl>\n1 Female                5.01\n2 Male                  5.63\n\n\n\nЕсли допустить, что выборка репрезентативна, то можно ли сделать вывод о различии по среднему весу рюкзаков в генеральной совокупности?\n\n\nt.test(backpack_kg ~ Sex, data = back)\n\n\n    Welch Two Sample t-test\n\ndata:  backpack_kg by Sex\nt = -1.1782, df = 86.25, p-value = 0.242\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -1.6892365  0.4320067\nsample estimates:\nmean in group Female   mean in group Male \n            5.006010             5.634625 \n\n\np-value больше .05, поэтому мы не можем отклонить нулевую гипотезу о том, что масса до и после диеты одинаковая.\n\nПовторите пунктs 2 и 3 для веса самих студентов.\n\n\nback %>%\n  group_by(Sex) %>%\n  summarise(mean(body_kg))\n\n# A tibble: 2 × 2\n  Sex    `mean(body_kg)`\n  <fct>            <dbl>\n1 Female            62.3\n2 Male              78.1\n\nt.test(body_kg ~ Sex, data = back)\n\n\n    Welch Two Sample t-test\n\ndata:  body_kg by Sex\nt = -7.0863, df = 77.002, p-value = 5.704e-10\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -20.32511 -11.40803\nsample estimates:\nmean in group Female   mean in group Male \n            62.28236             78.14893 \n\n\np-value меньше .05, поэтому мы можем отклонить нулевую гипотезу о том, что масса студентов-мужчин и студентов-женщин одинаковая. Мы принимаем альтернативную гипотезу о различии средних в генеральной совокупности.\n\nВизуализируйте распределение этих двух переменных в зависимости от пола (используя ggplot2)\n\n\nlibrary(ggplot2)\nggplot(back)+\n  geom_histogram(aes(x = body_kg, fill = Sex), bins = 15, position = \"identity\", alpha = 0.7)\n\n\n\n\n\nПостройте диаграмму рассеяния с помощью ggplot2. Цветом закодируйте пол респондента.\n\n\nggplot(back, aes(x = body_kg, y = backpack_kg))+\n  geom_point(aes(colour = Sex), alpha = 0.5, size = 2)"
  },
  {
    "objectID": "920-solutions.html#sec-cov_solutions",
    "href": "920-solutions.html#sec-cov_solutions",
    "title": "26  Решения заданий",
    "section": "26.33 Ковариация",
    "text": "26.33 Ковариация\n\nПосчитайте матрицу ковариаций для веса студентов и их рюкзаков в фунтах. Различаются ли результаты подсчета ковариации этих двух переменных от результатов подсчета ковариаций веса студентов и их рюкзаков в килограммах? Почему?\n\n\nback %>%\n  select(BodyWeight, BackpackWeight) %>%\n  cov()\n\n               BodyWeight BackpackWeight\nBodyWeight      864.20960       32.08788\nBackpackWeight   32.08788       33.23677\n\n\nРезультаты различаются, потому что значение ковариации зависит от размерности исходных шкал."
  },
  {
    "objectID": "920-solutions.html#sec-cor_solutions",
    "href": "920-solutions.html#sec-cor_solutions",
    "title": "26  Решения заданий",
    "section": "26.34 Коэффициент корреляции",
    "text": "26.34 Коэффициент корреляции\n\nПосчитайте коэффициент корреляции Пирсона для веса студентов и их рюкзаков в фунтах. Различаются ли результаты подсчета коэффициента корреляции Пирсона (сам коэффициент, p-value) этих двух переменных от результатов подсчета корреляции Пирсона веса студентов и их рюкзаков в килограммах? Почему?\n\n\ncor.test(back$BackpackWeight, back$BodyWeight)\n\n\n    Pearson's product-moment correlation\n\ndata:  back$BackpackWeight and back$BodyWeight\nt = 1.9088, df = 98, p-value = 0.05921\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.007360697  0.371918344\nsample estimates:\n      cor \n0.1893312 \n\n\nРезультаты не различаются, потому что значение ковариации не зависит от размерности исходных шкал.\n\nПосчитайте коэффициент корреляции Пирсона для веса и роста супергероев из датасета heroes. Проинтерпретируйте результат.\n\n\ncor.test(heroes$Weight, heroes$Height)\n\n\n    Pearson's product-moment correlation\n\ndata:  heroes$Weight and heroes$Height\nt = 4.3555, df = 488, p-value = 1.619e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1066877 0.2772717\nsample estimates:\n      cor \n0.1934412 \n\n\np-value меньше 0.05, поэтому мы можем отклонить нулевую гипотезу об отсутствии линейной связи между ростом и весом и принять альтернативную гипотезу о том, что такая связь есть. Судя по знаку и размеру корреляции, чем выше рост, тем выше вес супергероя, но эта связь достаточно слабая.\n\nТеперь посчитайте коэффициент корреляции Спирмена и коэффициент корреляции Кэнделла для веса и роста супергероев из датасета heroes. Различаются ли результаты по сравнению с коэффициентом корреляции Пирсона? Почему?\n\n\ncor.test(heroes$Weight, heroes$Height, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  heroes$Weight and heroes$Height\nS = 3915061, p-value < 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8003344 \n\n\n\ncor.test(heroes$Weight, heroes$Height, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  heroes$Weight and heroes$Height\nz = 21.548, p-value < 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.6751664 \n\n\nВ обоих случаях p-value меньше 0.05, поэтому мы можем отклонить нулевую гипотезу об отсутствии связи между ростом и весом и принять альтернативную гипотезу о том, что такая связь есть. Сильное различие между коэффициентами корреляции указывает на нелинейность этой связи, либо же на наличие значительных выбросов в данных."
  },
  {
    "objectID": "950-references.html",
    "href": "950-references.html",
    "title": "27  Библиография",
    "section": "",
    "text": "Adler, Joseph. 2010. R in a Nutshell: A Desktop Quick\nReference. \" O’Reilly Media, Inc.\".\n\n\nRitchie, Stuart, and Elliot Tucker-Drob. 2018. “How Much Does\nEducation Improve Intelligence? A Meta-Analysis.”\nPsychological Science 29 (June): 095679761877425. https://doi.org/10.1177/0956797618774253.\n\n\nWickham, Hadley. 2010. “A Layered Grammar of Graphics.”\nJournal of Computational and Graphical Statistics 19 (1): 3–28.\nhttps://doi.org/10.1198/jcgs.2009.07098.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics (Statistics and\nComputing). Berlin, Heidelberg: Springer-Verlag."
  }
]